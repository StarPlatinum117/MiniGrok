[
    {
        "text": "Bidirectional encoder representations from transformers (BERT) is a language model introduced in October 2018 by researchers at Google. It learns to represent text as a sequence of vectors using self-supervised learning. It uses the encoder-only transformer architecture. BERT dramatically improved the state-of-the-art for large language models. As of 2020, BERT is a ubiquitous baseline in natural language processing (NLP) experiments. \nBERT is trained by masked token prediction and next sentence",
        "source": "bert_language_model.txt"
    },
    {
        "text": "ained by masked token prediction and next sentence prediction. As a result of this training process, BERT learns contextual, latent representations of tokens in their context, similar to ELMo and GPT-2. It found applications for many natural language processing tasks, such as coreference resolution and polysemy resolution. It is an evolutionary step over ELMo, and spawned the study of \"BERTology\", which attempts to interpret what is learned by BERT.\nBERT was originally implemented in the English",
        "source": "bert_language_model.txt"
    },
    {
        "text": "RT.\nBERT was originally implemented in the English language at two model sizes, BERTBASE (110 million parameters) and BERTLARGE (340 million parameters). Both were trained on the Toronto BookCorpus (800M words) and English Wikipedia  (2,500M words).: 5  The weights were released on GitHub. On March 11, 2020, 24 smaller models were released, the smallest being BERTTINY with just 4 million parameters.\n\n\n== Architecture ==\n\nBERT is an \"encoder-only\" transformer architecture. At a high level, BERT c",
        "source": "bert_language_model.txt"
    },
    {
        "text": "transformer architecture. At a high level, BERT consists of 4 modules: \n\nTokenizer: This module converts a piece of English text into a sequence of integers (\"tokens\").\nEmbedding: This module converts the sequence of tokens into an array of real-valued vectors representing the tokens. It represents the conversion of discrete token types into a lower-dimensional Euclidean space.\nEncoder: a stack of Transformer blocks with self-attention, but without causal masking.\nTask head: This module convert",
        "source": "bert_language_model.txt"
    },
    {
        "text": "out causal masking.\nTask head: This module converts the final representation vectors into one-hot encoded tokens again by producing a predicted probability distribution over the token types. It can be viewed as a simple decoder, decoding the latent representation into token types, or as an \"un-embedding layer\".\nThe task head is necessary for pre-training, but it is often unnecessary for so-called \"downstream tasks,\" such as question answering or sentiment classification. Instead, one removes the",
        "source": "bert_language_model.txt"
    },
    {
        "text": "sentiment classification. Instead, one removes the task head and replaces it with a newly initialized module suited for the task, and finetune the new module. The latent vector representation of the model is directly fed into this new module, allowing for sample-efficient transfer learning.\n\n\n=== Embedding ===\nThis section describes the embedding used by BERTBASE. The other one, BERTLARGE, is similar, just larger.\nThe tokenizer of BERT is WordPiece, which is a sub-word strategy like byte-pair en",
        "source": "bert_language_model.txt"
    },
    {
        "text": "ce, which is a sub-word strategy like byte-pair encoding. Its vocabulary size is 30,000, and any token not appearing in its vocabulary is replaced by [UNK] (\"unknown\"). \n\nThe first layer is the embedding layer, which contains three components: token type embeddings, position embeddings, and segment type embeddings. \n\nToken type: The token type is a standard embedding layer, translating a one-hot vector into a dense vector based on its token type.\nPosition: The position embeddings are based on a",
        "source": "bert_language_model.txt"
    },
    {
        "text": "Position: The position embeddings are based on a token's position in the sequence. BERT uses absolute position embeddings, where each position in a sequence is mapped to a real-valued vector. Each dimension of the vector consists of a sinusoidal function that takes the position in the sequence as input.\nSegment type: Using a vocabulary of just 0 or 1, this embedding layer produces a dense vector based on whether the token belongs to the first or second text segment in that input. In other words",
        "source": "bert_language_model.txt"
    },
    {
        "text": "second text segment in that input. In other words, type-1 tokens are all tokens that appear after the [SEP] special token. All prior tokens are type-0.\nThe three embedding vectors are added together representing the initial token representation as a function of these three pieces of information. After embedding, the vector representation is normalized using a LayerNorm operation, outputting a 768-dimensional vector for each input token. After this, the representation vectors are passed forward",
        "source": "bert_language_model.txt"
    },
    {
        "text": "is, the representation vectors are passed forward through 12 Transformer encoder blocks, and are decoded back to 30,000-dimensional vocabulary space using a basic affine transformation layer.\n\n\n=== Architectural family ===\nThe encoder stack of BERT has 2 free parameters: \n  \n    \n      \n        L\n      \n    \n    {\\displaystyle L}\n  \n, the number of layers, and \n  \n    \n      \n        H\n      \n    \n    {\\displaystyle H}\n  \n, the hidden size. There are always \n  \n    \n      \n        H",
        "source": "bert_language_model.txt"
    },
    {
        "text": "are always \n  \n    \n      \n        H\n        \n          /\n        \n        64\n      \n    \n    {\\displaystyle H/64}\n  \n self-attention heads, and the feed-forward/filter size is always \n  \n    \n      \n        4\n        H\n      \n    \n    {\\displaystyle 4H}\n  \n. By varying these two numbers, one obtains an entire family of BERT models.\nFor BERT\n\nthe feed-forward size and filter size are synonymous. Both of them denote the number of dimensions in the middle layer of the feed-forward network.\nthe hi",
        "source": "bert_language_model.txt"
    },
    {
        "text": "e middle layer of the feed-forward network.\nthe hidden size and embedding size are synonymous. Both of them denote the number of real numbers used to represent a token.\nThe notation for encoder stack is written as L/H. For example, BERTBASE is written as 12L/768H, BERTLARGE as 24L/1024H, and BERTTINY as 2L/128H.\n\n\n== Training ==\n\n\n=== Pre-training ===\nBERT was pre-trained simultaneously on two tasks.\n\nMasked Language Model (MLM): In this task, BERT ingests a sequence of words, where one words ma",
        "source": "bert_language_model.txt"
    },
    {
        "text": "RT ingests a sequence of words, where one words may be randomly changed (\"masked\"), and BERT tries to predict the original words that had been changed. For example, in the sentence \"The cat sat on the [MASK],\" BERT would need to predict \"mat.\" This helps BERT learn bidirectional context, meaning it understands the relationships between words not just from left to right or right to left but from both directions at the same time.\nNext Sentence Prediction (NSP): In this task, BERT is trained to pre",
        "source": "bert_language_model.txt"
    },
    {
        "text": "iction (NSP): In this task, BERT is trained to predict whether one sentence logically follows another. For example, given two sentences, \"The cat sat on the mat.\" and \"It was a sunny day,\" BERT has to decide if the second sentence is a valid continuation of the first one. This helps BERT understand relationships between sentences, which is important for tasks like question answering or document classification.\n\n\n==== Masked language modeling ====\n\nIn masked language modeling, 15% of tokens would",
        "source": "bert_language_model.txt"
    },
    {
        "text": "In masked language modeling, 15% of tokens would be randomly selected for masked-prediction task, and the training objective was to predict the masked token given its context. In more detail, the selected token is \n\nreplaced with a [MASK] token with probability 80%,\nreplaced with a random word token with probability 10%,\nnot replaced with probability 10%.\nThe reason not all selected tokens are masked is to avoid the dataset shift problem. The dataset shift problem arises when the distribution",
        "source": "bert_language_model.txt"
    },
    {
        "text": "ataset shift problem arises when the distribution of inputs seen during training differs significantly from the distribution encountered during inference. A trained BERT model might be applied to word representation (like Word2Vec), where it would be run over sentences not containing any [MASK] tokens. It is later found that more diverse training objectives are generally better.\nAs an illustrative example, consider the sentence \"my dog is cute\". It would first be divided into tokens like \"my1 do",
        "source": "bert_language_model.txt"
    },
    {
        "text": "It would first be divided into tokens like \"my1 dog2 is3 cute4\". Then a random token in the sentence would be picked. Let it be the 4th one \"cute4\". Next, there would be three possibilities:\n\nwith probability 80%, the chosen token is masked, resulting in \"my1 dog2 is3 [MASK]4\";\nwith probability 10%, the chosen token is replaced by a uniformly sampled random token, such as \"happy\", resulting in \"my1 dog2 is3 happy4\";\nwith probability 10%, nothing is done, resulting in \"my1 dog2 is3 cute4\".\nAfter",
        "source": "bert_language_model.txt"
    },
    {
        "text": "is done, resulting in \"my1 dog2 is3 cute4\".\nAfter processing the input text, the model's 4th output vector is passed to its decoder layer, which outputs a probability distribution over its 30,000-dimensional vocabulary space.\n\n\n==== Next sentence prediction ====\n\nGiven two spans of text, the model predicts if these two spans appeared sequentially in the training corpus, outputting either [IsNext] or [NotNext]. Specifically, the training algorithm would sometimes sample two spans from a single co",
        "source": "bert_language_model.txt"
    },
    {
        "text": "would sometimes sample two spans from a single continuous span in the training corpus, but other times, sample two spans from two discontinuous spans in the training corpus.\nThe first span starts with a special token [CLS] (for \"classify\"). The two spans are separated by a special token [SEP] (for \"separate\"). After processing the two spans, the 1-st output vector (the vector coding for [CLS]) is passed to a separate neural network for the binary classification into [IsNext] and [NotNext].\n\nFor",
        "source": "bert_language_model.txt"
    },
    {
        "text": "y classification into [IsNext] and [NotNext].\n\nFor example, given \"[CLS] my dog is cute [SEP] he likes playing\" the model should output token [IsNext].\nGiven \"[CLS] my dog is cute [SEP] how do magnets work\" the model should output token [NotNext].\n\n\n=== Fine-tuning ===\n\nBERT is meant as a general pretrained model for various applications in natural language processing. That is, after pre-training, BERT can be fine-tuned with fewer resources on smaller datasets to optimize its performance on spec",
        "source": "bert_language_model.txt"
    },
    {
        "text": "aller datasets to optimize its performance on specific tasks such as natural language inference and text classification, and sequence-to-sequence-based language generation tasks such as question answering and conversational response generation.\nThe original BERT paper published results demonstrating that a small amount of finetuning (for BERTLARGE, 1 hour on 1 Cloud TPU) allowed it to achieved state-of-the-art performance on a number of natural language understanding tasks:\n\nGLUE (General Langua",
        "source": "bert_language_model.txt"
    },
    {
        "text": "anguage understanding tasks:\n\nGLUE (General Language Understanding Evaluation) task set (consisting of 9 tasks);\nSQuAD (Stanford Question Answering Dataset) v1.1 and v2.0;\nSWAG (Situations With Adversarial Generations).\nIn the original paper, all parameters of BERT are finetuned, and recommended that, for downstream applications that are text classifications, the output token at the [CLS] input token is fed into a linear-softmax layer to produce the label outputs.\nThe original code base defined",
        "source": "bert_language_model.txt"
    },
    {
        "text": "the label outputs.\nThe original code base defined the final linear layer as a \"pooler layer\", in analogy with global pooling in computer vision, even though it simply discards all output tokens except the one corresponding to  [CLS] .\n\n\n=== Cost ===\nBERT was trained on the BookCorpus (800M words) and a filtered version of English Wikipedia (2,500M words) without lists, tables, and headers.\nTraining BERTBASE  on 4 cloud TPU (16 TPU chips total) took 4 days, at an estimated cost of 500 USD. Traini",
        "source": "bert_language_model.txt"
    },
    {
        "text": "ok 4 days, at an estimated cost of 500 USD. Training BERTLARGE on 16 cloud TPU (64 TPU chips total) took 4 days.\n\n\n== Interpretation ==\nLanguage models like ELMo, GPT-2, and BERT, spawned the study of \"BERTology\", which attempts to interpret what is learned by these models. Their performance on these natural language understanding tasks are not yet well understood. Several research publications in 2018 and 2019 focused on investigating the relationship behind BERT's output as a result of careful",
        "source": "bert_language_model.txt"
    },
    {
        "text": "onship behind BERT's output as a result of carefully chosen input sequences, analysis of internal vector representations through probing classifiers, and the relationships represented by attention weights.\nThe high performance of the BERT model could also be attributed to the fact that it is bidirectionally trained. This means that BERT, based on the Transformer model architecture, applies its self-attention mechanism to learn information from a text from the left and right side during training,",
        "source": "bert_language_model.txt"
    },
    {
        "text": "text from the left and right side during training, and consequently gains a deep understanding of the context. For example, the word fine can have two different meanings depending on the context (I feel fine today, She has fine blond hair). BERT considers the words surrounding the target word fine from the left and right side.\nHowever it comes at a cost: due to encoder-only architecture lacking a decoder, BERT can't be prompted and can't generate text, while bidirectional models in general do no",
        "source": "bert_language_model.txt"
    },
    {
        "text": "text, while bidirectional models in general do not work effectively without the right side, thus being difficult to prompt. As an illustrative example, if one wishes to use BERT to continue a sentence fragment \"Today, I went to\", then naively one would mask out all the tokens as \"Today, I went to  [MASK]  [MASK]  [MASK] ...  [MASK] .\" where the number of  [MASK]  is the length of the sentence one wishes to extend to. However, this constitutes a dataset shift, as during training, BERT has never",
        "source": "bert_language_model.txt"
    },
    {
        "text": "dataset shift, as during training, BERT has never seen sentences with that many tokens masked out. Consequently, its performance degrades. More sophisticated techniques allow text generation, but at a high computational cost.\n\n\n== History ==\nBERT was originally published by Google researchers Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. The design has its origins from pre-training contextual representations, including semi-supervised sequence learning, generative pre-trainin",
        "source": "bert_language_model.txt"
    },
    {
        "text": "pervised sequence learning, generative pre-training, ELMo, and ULMFit. Unlike previous models, BERT is a deeply bidirectional, unsupervised language representation, pre-trained using only a plain text corpus. Context-free models such as word2vec or GloVe generate a single word embedding representation for each word in the vocabulary, whereas BERT takes into account the context for each occurrence of a given word. For instance, whereas the vector for \"running\" will have the same word2vec vector r",
        "source": "bert_language_model.txt"
    },
    {
        "text": "for \"running\" will have the same word2vec vector representation for both of its occurrences in the sentences \"He is running a company\" and \"He is running a marathon\", BERT will provide a contextualized embedding that will be different according to the sentence.\nOn October 25, 2019, Google announced that they had started applying BERT models for English language search queries within the US. On December 9, 2019, it was reported that BERT had been adopted by Google Search for over 70 languages. In",
        "source": "bert_language_model.txt"
    },
    {
        "text": "adopted by Google Search for over 70 languages. In October 2020, almost every single English-based query was processed by a BERT model.\n\n\n== Variants ==\nThe BERT models were influential and inspired many variants.\nRoBERTa (2019) was an engineering improvement. It preserves BERT's architecture (slightly larger, at 355M parameters), but improves its training, changing key hyperparameters, removing the next-sentence prediction task, and using much larger mini-batch sizes. \nXLM-RoBERTa (2019) was a",
        "source": "bert_language_model.txt"
    },
    {
        "text": "arger mini-batch sizes. \nXLM-RoBERTa (2019) was a multilingual RoBERTa model. It was one of the first works on multilingual language modeling at scale.\nDistilBERT (2019) distills BERTBASE to a model with just 60% of its parameters (66M), while preserving 95% of its benchmark scores. Similarly, TinyBERT (2019) is a distilled model with just 28% of its parameters.\nALBERT (2019) used shared-parameter across layers, and experimented with independently varying the hidden size and the word-embedding l",
        "source": "bert_language_model.txt"
    },
    {
        "text": "y varying the hidden size and the word-embedding layer's output size as two hyperparameters. They also replaced the next sentence prediction task with the sentence-order prediction (SOP) task, where the model must distinguish the correct order of two consecutive text segments from their reversed order. \nELECTRA (2020) applied the idea of generative adversarial networks to the MLM task. Instead of masking out tokens, a small language model generates random plausible substitutions, and a larger ne",
        "source": "bert_language_model.txt"
    },
    {
        "text": "es random plausible substitutions, and a larger network identify these replaced tokens. The small model aims to fool the large model.\nDeBERTa (2020) is a significant architectural variant, with disentangled attention. Its key idea is to treat the positional and token encodings separately throughout the attention mechanism. Instead of combining the positional encoding (\n  \n    \n      \n        \n          x\n          \n            p\n            o\n            s\n            i\n            t",
        "source": "bert_language_model.txt"
    },
    {
        "text": "s\n            i\n            t\n            i\n            o\n            n\n          \n        \n      \n    \n    {\\displaystyle x_{position}}\n  \n) and token encoding (\n  \n    \n      \n        \n          x\n          \n            token\n          \n        \n      \n    \n    {\\displaystyle x_{\\text{token}}}\n  \n) into a single input vector (\n  \n    \n      \n        \n          x\n          \n            i\n            n\n            p\n            u\n            t\n          \n        \n        =",
        "source": "bert_language_model.txt"
    },
    {
        "text": "t\n          \n        \n        =\n        \n          x\n          \n            p\n            o\n            s\n            i\n            t\n            i\n            o\n            n\n          \n        \n        +\n        \n          x\n          \n            t\n            o\n            k\n            e\n            n\n          \n        \n      \n    \n    {\\displaystyle x_{input}=x_{position}+x_{token}}\n  \n), DeBERTa keeps them separate as a tuple: (\n  \n    \n      \n        (\n        \n          x",
        "source": "bert_language_model.txt"
    },
    {
        "text": "(\n        \n          x\n          \n            p\n            o\n            s\n            i\n            t\n            i\n            o\n            n\n          \n        \n        ,\n        \n          x\n          \n            t\n            o\n            k\n            e\n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{position},x_{token})}\n  \n). Then, at each self-attention layer, DeBERTa computes three distinct attention matrices, rather than the single",
        "source": "bert_language_model.txt"
    },
    {
        "text": "istinct attention matrices, rather than the single attention matrix used in BERT:\n\nThe three attention matrices are added together element-wise, then passed through a softmax layer and multiplied by a projection matrix.\nAbsolute position encoding is included in the final self-attention layer as additional input.\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==\nRogers, Anna; Kovaleva, Olga; Rumshisky, Anna (2020). \"A Primer in BERTology: What we know about how BERT works\". arXiv:2002.1232",
        "source": "bert_language_model.txt"
    },
    {
        "text": "hat we know about how BERT works\". arXiv:2002.12327 [cs.CL].\n\n\n== External links ==\nOfficial GitHub repository",
        "source": "bert_language_model.txt"
    },
    {
        "text": "In machine learning, diffusion models, also known as diffusion-based generative models or score-based generative models, are a class of latent variable generative models. A diffusion model consists of two major components: the forward diffusion process, and the reverse sampling process. The goal of diffusion models is to learn a diffusion process for a given dataset, such that the process can generate new elements that are distributed similarly as the original dataset. A diffusion model models d",
        "source": "diffusion_model.txt"
    },
    {
        "text": "s the original dataset. A diffusion model models data as generated by a diffusion process, whereby a new datum performs a random walk with drift through the space of all possible data. A trained diffusion model can be sampled in many ways, with different efficiency and quality.\nThere are various equivalent formalisms, including Markov chains, denoising diffusion probabilistic models, noise conditioned score networks, and stochastic differential equations. They are typically trained using variati",
        "source": "diffusion_model.txt"
    },
    {
        "text": "quations. They are typically trained using variational inference. The model responsible for denoising is typically called its \"backbone\". The backbone may be of any kind, but they are typically U-nets or transformers.\nAs of 2024, diffusion models are mainly used for computer vision tasks, including image denoising, inpainting, super-resolution, image generation, and video generation. These typically involve training a neural network to sequentially denoise images blurred with Gaussian noise. The",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ly denoise images blurred with Gaussian noise. The model is trained to reverse the process of adding noise to an image. After training to convergence, it can be used for image generation by starting with an image composed of random noise, and applying the network iteratively to denoise the image.\nDiffusion-based image generators have seen widespread commercial interest, such as Stable Diffusion and DALL-E. These models typically combine diffusion models with other models, such as text-encoders a",
        "source": "diffusion_model.txt"
    },
    {
        "text": "models with other models, such as text-encoders and cross-attention modules to allow text-conditioned generation.\nOther than computer vision, diffusion models have also found applications in natural language processing such as text generation and summarization, sound generation, and reinforcement learning.\n\n\n== Denoising diffusion model ==\n\n\n=== Non-equilibrium thermodynamics ===\nDiffusion models were introduced in 2015 as a method to train a model that can sample from a highly complex probabil",
        "source": "diffusion_model.txt"
    },
    {
        "text": "del that can sample from a highly complex probability distribution. They used techniques from non-equilibrium thermodynamics, especially diffusion.\nConsider, for example, how one might model the distribution of all naturally-occurring photos. Each image is a point in the space of all images, and the distribution of naturally-occurring photos is a \"cloud\" in space, which, by repeatedly adding noise to the images, diffuses out to the rest of the image space, until the cloud becomes all but indisti",
        "source": "diffusion_model.txt"
    },
    {
        "text": "age space, until the cloud becomes all but indistinguishable from a Gaussian distribution \n  \n    \n      \n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        I\n        )\n      \n    \n    {\\displaystyle {\\mathcal {N}}(0,I)}\n  \n. A model that can approximately undo the diffusion can then be used to sample from the original distribution. This is studied in \"non-equilibrium\" thermodynamics, as the starting distribution is not in equilibrium, unlike the final di",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ibution is not in equilibrium, unlike the final distribution.\nThe equilibrium distribution is the Gaussian distribution \n  \n    \n      \n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        I\n        )\n      \n    \n    {\\displaystyle {\\mathcal {N}}(0,I)}\n  \n, with pdf \n  \n    \n      \n        ρ\n        (\n        x\n        )\n        ∝\n        \n          e\n          \n            −\n            \n              \n                1\n                2",
        "source": "diffusion_model.txt"
    },
    {
        "text": "1\n                2\n              \n            \n            ‖\n            x\n            \n              ‖\n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\rho (x)\\propto e^{-{\\frac {1}{2}}\\|x\\|^{2}}}\n  \n. This is just the Maxwell–Boltzmann distribution of particles in a potential well \n  \n    \n      \n        V\n        (\n        x\n        )\n        =\n        \n          \n            1\n            2",
        "source": "diffusion_model.txt"
    },
    {
        "text": "1\n            2\n          \n        \n        ‖\n        x\n        \n          ‖\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle V(x)={\\frac {1}{2}}\\|x\\|^{2}}\n  \n at temperature 1. The initial distribution, being very much out of equilibrium, would diffuse towards the equilibrium distribution, making biased random steps that are a sum of pure randomness (like a Brownian walker) and gradient descent down the potential well. The randomness is necessary: if the part",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ial well. The randomness is necessary: if the particles were to undergo only gradient descent, then they will all fall to the origin, collapsing the distribution.\n\n\n=== Denoising Diffusion Probabilistic Model (DDPM) ===\nThe 2020 paper proposed the Denoising Diffusion Probabilistic Model (DDPM), which improves upon the previous method by variational inference.\n\n\n==== Forward diffusion ====\nTo present the model, we need some notation.\n\n  \n    \n      \n        \n          β\n          \n            1",
        "source": "diffusion_model.txt"
    },
    {
        "text": "β\n          \n            1\n          \n        \n        ,\n        .\n        .\n        .\n        ,\n        \n          β\n          \n            T\n          \n        \n        ∈\n        (\n        0\n        ,\n        1\n        )\n      \n    \n    {\\displaystyle \\beta _{1},...,\\beta _{T}\\in (0,1)}\n  \n are fixed constants.\n\n  \n    \n      \n        \n          α\n          \n            t\n          \n        \n        :=\n        1\n        −\n        \n          β\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "β\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle \\alpha _{t}:=1-\\beta _{t}}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                α\n                ¯\n              \n            \n          \n          \n            t\n          \n        \n        :=\n        \n          α\n          \n            1\n          \n        \n        ⋯\n        \n          α\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle {\\bar",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle {\\bar {\\alpha }}_{t}:=\\alpha _{1}\\cdots \\alpha _{t}}\n  \n\n  \n    \n      \n        \n          σ\n          \n            t\n          \n        \n        :=\n        \n          \n            1\n            −\n            \n              \n                \n                  \n                    α\n                    ¯\n                  \n                \n              \n              \n                t\n              \n            \n          \n        \n      \n    \n    {\\",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle \\sigma _{t}:={\\sqrt {1-{\\bar {\\alpha }}_{t}}}}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                σ\n                ~\n              \n            \n          \n          \n            t\n          \n        \n        :=\n        \n          \n            \n              σ\n              \n                t\n                −\n                1\n              \n            \n            \n              σ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "σ\n              \n                t\n              \n            \n          \n        \n        \n          \n            \n              β\n              \n                t\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\tilde {\\sigma }}_{t}:={\\frac {\\sigma _{t-1}}{\\sigma _{t}}}{\\sqrt {\\beta _{t}}}}\n  \n\n  \n    \n      \n        \n          \n            \n              \n                μ\n                ~",
        "source": "diffusion_model.txt"
    },
    {
        "text": "~\n              \n            \n          \n          \n            t\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        \n          x\n          \n            0\n          \n        \n        )\n        :=\n        \n          \n            \n              \n                \n                  \n                    α\n                    \n                      t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n              1\n              −\n              \n                \n                  \n                    \n                      α\n                      ¯\n                    \n                  \n                \n                \n                  t\n                  −\n                  1\n                \n              \n              )\n              \n                x\n                \n                  t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                \n              \n              +\n              \n                \n                  \n                    \n                      \n                        \n                          α\n                          ¯\n                        \n                      \n                    \n                    \n                      t\n                      −\n                      1\n                    \n                  \n                \n              \n              (\n              1",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n              1\n              −\n              \n                α\n                \n                  t\n                \n              \n              )\n              \n                x\n                \n                  0\n                \n              \n            \n            \n              σ\n              \n                t\n              \n              \n                2\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\tilde {\\mu",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle {\\tilde {\\mu }}_{t}(x_{t},x_{0}):={\\frac {{\\sqrt {\\alpha _{t}}}(1-{\\bar {\\alpha }}_{t-1})x_{t}+{\\sqrt {{\\bar {\\alpha }}_{t-1}}}(1-\\alpha _{t})x_{0}}{\\sigma _{t}^{2}}}}\n  \n\n  \n    \n      \n        \n          \n            N\n          \n        \n        (\n        μ\n        ,\n        Σ\n        )\n      \n    \n    {\\displaystyle {\\mathcal {N}}(\\mu ,\\Sigma )}\n  \n is the normal distribution with mean \n  \n    \n      \n        μ\n      \n    \n    {\\displaystyle \\mu }\n  \n an",
        "source": "diffusion_model.txt"
    },
    {
        "text": "μ\n      \n    \n    {\\displaystyle \\mu }\n  \n and variance \n  \n    \n      \n        Σ\n      \n    \n    {\\displaystyle \\Sigma }\n  \n, and \n  \n    \n      \n        \n          \n            N\n          \n        \n        (\n        x\n        \n          |\n        \n        μ\n        ,\n        Σ\n        )\n      \n    \n    {\\displaystyle {\\mathcal {N}}(x|\\mu ,\\Sigma )}\n  \n is the probability density at \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n.\nA vertical bar denotes conditioning.\nA for",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x}\n  \n.\nA vertical bar denotes conditioning.\nA forward diffusion process starts at some starting point \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n        ∼\n        q\n      \n    \n    {\\displaystyle x_{0}\\sim q}\n  \n, where \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n  \n is the probability distribution to be learned, then repeatedly adds noise to it by\n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        =",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        =\n        \n          \n            1\n            −\n            \n              β\n              \n                t\n              \n            \n          \n        \n        \n          x\n          \n            t\n            −\n            1\n          \n        \n        +\n        \n          \n            \n              β\n              \n                t\n              \n            \n          \n        \n        \n          z\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "z\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t}={\\sqrt {1-\\beta _{t}}}x_{t-1}+{\\sqrt {\\beta _{t}}}z_{t}}\n  \nwhere \n  \n    \n      \n        \n          z\n          \n            1\n          \n        \n        ,\n        .\n        .\n        .\n        ,\n        \n          z\n          \n            T\n          \n        \n      \n    \n    {\\displaystyle z_{1},...,z_{T}}\n  \n are IID samples from \n  \n    \n      \n        \n          \n            N",
        "source": "diffusion_model.txt"
    },
    {
        "text": "N\n          \n        \n        (\n        0\n        ,\n        I\n        )\n      \n    \n    {\\displaystyle {\\mathcal {N}}(0,I)}\n  \n. This is designed so that for any starting distribution of \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n, we have \n  \n    \n      \n        \n          lim\n          \n            t\n          \n        \n        \n          x\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n            t\n          \n        \n        \n          |\n        \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\lim _{t}x_{t}|x_{0}}\n  \n converging to \n  \n    \n      \n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        I\n        )\n      \n    \n    {\\displaystyle {\\mathcal {N}}(0,I)}\n  \n.\nThe entire diffusion process then satisfies\n  \n    \n      \n        q\n        (\n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "q\n        (\n        \n          x\n          \n            0\n            :\n            T\n          \n        \n        )\n        =\n        q\n        (\n        \n          x\n          \n            0\n          \n        \n        )\n        q\n        (\n        \n          x\n          \n            1\n          \n        \n        \n          |\n        \n        \n          x\n          \n            0\n          \n        \n        )\n        ⋯\n        q\n        (\n        \n          x\n          \n            T",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n        \n          x\n          \n            T\n          \n        \n        \n          |\n        \n        \n          x\n          \n            T\n            −\n            1\n          \n        \n        )\n        =\n        q\n        (\n        \n          x\n          \n            0\n          \n        \n        )\n        \n          \n            N\n          \n        \n        (\n        \n          x\n          \n            1\n          \n        \n        \n          |",
        "source": "diffusion_model.txt"
    },
    {
        "text": "|\n        \n        \n          \n            \n              α\n              \n                1\n              \n            \n          \n        \n        \n          x\n          \n            0\n          \n        \n        ,\n        \n          β\n          \n            1\n          \n        \n        I\n        )\n        ⋯\n        \n          \n            N\n          \n        \n        (\n        \n          x\n          \n            T\n          \n        \n        \n          |",
        "source": "diffusion_model.txt"
    },
    {
        "text": "|\n        \n        \n          \n            \n              α\n              \n                T\n              \n            \n          \n        \n        \n          x\n          \n            T\n            −\n            1\n          \n        \n        ,\n        \n          β\n          \n            T\n          \n        \n        I\n        )\n      \n    \n    {\\displaystyle q(x_{0:T})=q(x_{0})q(x_{1}|x_{0})\\cdots q(x_{T}|x_{T-1})=q(x_{0}){\\mathcal {N}}(x_{1}|{\\sqrt {\\alpha _{1}}}x_{0},\\beta",
        "source": "diffusion_model.txt"
    },
    {
        "text": "athcal {N}}(x_{1}|{\\sqrt {\\alpha _{1}}}x_{0},\\beta _{1}I)\\cdots {\\mathcal {N}}(x_{T}|{\\sqrt {\\alpha _{T}}}x_{T-1},\\beta _{T}I)}\n  \nor\n  \n    \n      \n        ln\n        ⁡\n        q\n        (\n        \n          x\n          \n            0\n            :\n            T\n          \n        \n        )\n        =\n        ln\n        ⁡\n        q\n        (\n        \n          x\n          \n            0\n          \n        \n        )\n        −\n        \n          ∑\n          \n            t\n            =",
        "source": "diffusion_model.txt"
    },
    {
        "text": "∑\n          \n            t\n            =\n            1\n          \n          \n            T\n          \n        \n        \n          \n            1\n            \n              2\n              \n                β\n                \n                  t\n                \n              \n            \n          \n        \n        ‖\n        \n          x\n          \n            t\n          \n        \n        −\n        \n          \n            1\n            −\n            \n              β",
        "source": "diffusion_model.txt"
    },
    {
        "text": "β\n              \n                t\n              \n            \n          \n        \n        \n          x\n          \n            t\n            −\n            1\n          \n        \n        \n          ‖\n          \n            2\n          \n        \n        +\n        C\n      \n    \n    {\\displaystyle \\ln q(x_{0:T})=\\ln q(x_{0})-\\sum _{t=1}^{T}{\\frac {1}{2\\beta _{t}}}\\|x_{t}-{\\sqrt {1-\\beta _{t}}}x_{t-1}\\|^{2}+C}\n  \nwhere \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}",
        "source": "diffusion_model.txt"
    },
    {
        "text": "C\n      \n    \n    {\\displaystyle C}\n  \n is a normalization constant and often omitted. In particular, we note that \n  \n    \n      \n        \n          x\n          \n            1\n            :\n            T\n          \n        \n        \n          |\n        \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{1:T}|x_{0}}\n  \n is a gaussian process, which affords us considerable freedom in reparameterization. For example, by standard manipulat",
        "source": "diffusion_model.txt"
    },
    {
        "text": "rameterization. For example, by standard manipulation with gaussian process, \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        \n          |\n        \n        \n          x\n          \n            0\n          \n        \n        ∼\n        N\n        \n          (\n          \n            \n              \n                \n                  \n                    \n                      \n                        α\n                        ¯",
        "source": "diffusion_model.txt"
    },
    {
        "text": "¯\n                      \n                    \n                  \n                  \n                    t\n                  \n                \n              \n            \n            \n              x\n              \n                0\n              \n            \n            ,\n            \n              σ\n              \n                t\n              \n              \n                2\n              \n            \n            I\n          \n          )\n        \n      \n    \n    {\\displayst",
        "source": "diffusion_model.txt"
    },
    {
        "text": ")\n        \n      \n    \n    {\\displaystyle x_{t}|x_{0}\\sim N\\left({\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0},\\sigma _{t}^{2}I\\right)}\n  \n\n  \n    \n      \n        \n          x\n          \n            t\n            −\n            1\n          \n        \n        \n          |\n        \n        \n          x\n          \n            t\n          \n        \n        ,\n        \n          x\n          \n            0\n          \n        \n        ∼\n        \n          \n            N\n          \n        \n        (",
        "source": "diffusion_model.txt"
    },
    {
        "text": "N\n          \n        \n        (\n        \n          \n            \n              \n                μ\n                ~\n              \n            \n          \n          \n            t\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        \n          x\n          \n            0\n          \n        \n        )\n        ,\n        \n          \n            \n              \n                σ\n                ~",
        "source": "diffusion_model.txt"
    },
    {
        "text": "σ\n                ~\n              \n            \n          \n          \n            t\n          \n          \n            2\n          \n        \n        I\n        )\n      \n    \n    {\\displaystyle x_{t-1}|x_{t},x_{0}\\sim {\\mathcal {N}}({\\tilde {\\mu }}_{t}(x_{t},x_{0}),{\\tilde {\\sigma }}_{t}^{2}I)}\n  \nIn particular, notice that for large \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n, the variable \n  \n    \n      \n        \n          x\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        \n          |\n        \n        \n          x\n          \n            0\n          \n        \n        ∼\n        N\n        \n          (\n          \n            \n              \n                \n                  \n                    \n                      \n                        α\n                        ¯\n                      \n                    \n                  \n                  \n                    t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                  \n                \n              \n            \n            \n              x\n              \n                0\n              \n            \n            ,\n            \n              σ\n              \n                t\n              \n              \n                2\n              \n            \n            I\n          \n          )\n        \n      \n    \n    {\\displaystyle x_{t}|x_{0}\\sim N\\left({\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0},\\sigma _{t}^{2}I\\right)}\n  \n converges to",
        "source": "diffusion_model.txt"
    },
    {
        "text": "igma _{t}^{2}I\\right)}\n  \n converges to \n  \n    \n      \n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        I\n        )\n      \n    \n    {\\displaystyle {\\mathcal {N}}(0,I)}\n  \n. That is, after a long enough diffusion process, we end up with some \n  \n    \n      \n        \n          x\n          \n            T\n          \n        \n      \n    \n    {\\displaystyle x_{T}}\n  \n that is very close to \n  \n    \n      \n        \n          \n            N",
        "source": "diffusion_model.txt"
    },
    {
        "text": "N\n          \n        \n        (\n        0\n        ,\n        I\n        )\n      \n    \n    {\\displaystyle {\\mathcal {N}}(0,I)}\n  \n, with all traces of the original \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n        ∼\n        q\n      \n    \n    {\\displaystyle x_{0}\\sim q}\n  \n gone.\nFor example, since\n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        \n          |\n        \n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "|\n        \n        \n          x\n          \n            0\n          \n        \n        ∼\n        N\n        \n          (\n          \n            \n              \n                \n                  \n                    \n                      \n                        α\n                        ¯\n                      \n                    \n                  \n                  \n                    t\n                  \n                \n              \n            \n            \n              x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n              \n                0\n              \n            \n            ,\n            \n              σ\n              \n                t\n              \n              \n                2\n              \n            \n            I\n          \n          )\n        \n      \n    \n    {\\displaystyle x_{t}|x_{0}\\sim N\\left({\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0},\\sigma _{t}^{2}I\\right)}\n  \nwe can sample \n  \n    \n      \n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n            t\n          \n        \n        \n          |\n        \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{t}|x_{0}}\n  \n directly \"in one step\", instead of going through all the intermediate steps \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n        \n        ,\n        .\n        .\n        .",
        "source": "diffusion_model.txt"
    },
    {
        "text": ",\n        .\n        .\n        .\n        ,\n        \n          x\n          \n            t\n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle x_{1},x_{2},...,x_{t-1}}\n  \n.\n\n\n==== Backward diffusion ====\nThe key idea of DDPM is to use a neural network parametrized by \n  \n    \n      \n        θ\n      \n    \n    {\\displaystyle \\theta }\n  \n. The network takes in two arguments \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        ,",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        ,\n        t\n      \n    \n    {\\displaystyle x_{t},t}\n  \n, and outputs a vector \n  \n    \n      \n        \n          μ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\mu _{\\theta }(x_{t},t)}\n  \n and a matrix \n  \n    \n      \n        \n          Σ\n          \n            θ\n          \n        \n        (\n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\Sigma _{\\theta }(x_{t},t)}\n  \n, such that each step in the forward diffusion process can be approximately undone by \n  \n    \n      \n        \n          x\n          \n            t\n            −\n            1\n          \n        \n        ∼\n        \n          \n            N\n          \n        \n        (\n        \n          μ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n        \n          μ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        ,\n        \n          Σ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        )\n      \n    \n    {\\displaystyle x_{t-1}\\sim {\\mathcal {N}}(\\mu _{\\theta }(x_{t},t),\\Sigma _{\\theta }(x_{t},t))}\n  \n. This then giv",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t),\\Sigma _{\\theta }(x_{t},t))}\n  \n. This then gives us a backward diffusion process \n  \n    \n      \n        \n          p\n          \n            θ\n          \n        \n      \n    \n    {\\displaystyle p_{\\theta }}\n  \n defined by\n  \n    \n      \n        \n          p\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            T\n          \n        \n        )\n        =\n        \n          \n            N\n          \n        \n        (\n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n        \n          x\n          \n            T\n          \n        \n        \n          |\n        \n        0\n        ,\n        I\n        )\n      \n    \n    {\\displaystyle p_{\\theta }(x_{T})={\\mathcal {N}}(x_{T}|0,I)}\n  \n\n  \n    \n      \n        \n          p\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n            −\n            1\n          \n        \n        \n          |\n        \n        \n          x\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n            t\n          \n        \n        )\n        =\n        \n          \n            N\n          \n        \n        (\n        \n          x\n          \n            t\n            −\n            1\n          \n        \n        \n          |\n        \n        \n          μ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        ,\n        \n          Σ\n          \n            θ",
        "source": "diffusion_model.txt"
    },
    {
        "text": ",\n        \n          Σ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        )\n      \n    \n    {\\displaystyle p_{\\theta }(x_{t-1}|x_{t})={\\mathcal {N}}(x_{t-1}|\\mu _{\\theta }(x_{t},t),\\Sigma _{\\theta }(x_{t},t))}\n  \nThe goal now is to learn the parameters such that \n  \n    \n      \n        \n          p\n          \n            θ\n          \n        \n        (\n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n        \n          x\n          \n            0\n          \n        \n        )\n      \n    \n    {\\displaystyle p_{\\theta }(x_{0})}\n  \n is as close to \n  \n    \n      \n        q\n        (\n        \n          x\n          \n            0\n          \n        \n        )\n      \n    \n    {\\displaystyle q(x_{0})}\n  \n as possible. To do that, we use maximum likelihood estimation with variational inference.\n\n\n==== Variational inference ====\nThe ELBO inequality states that \n  \n    \n      \n        l",
        "source": "diffusion_model.txt"
    },
    {
        "text": "O inequality states that \n  \n    \n      \n        ln\n        ⁡\n        \n          p\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            0\n          \n        \n        )\n        ≥\n        \n          E\n          \n            \n              x\n              \n                1\n                :\n                T\n              \n            \n            ∼\n            q\n            (\n            ⋅\n            \n              |",
        "source": "diffusion_model.txt"
    },
    {
        "text": "|\n            \n            \n              x\n              \n                0\n              \n            \n            )\n          \n        \n        [\n        ln\n        ⁡\n        \n          p\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            0\n            :\n            T\n          \n        \n        )\n        −\n        ln\n        ⁡\n        q\n        (\n        \n          x\n          \n            1\n            :\n            T",
        "source": "diffusion_model.txt"
    },
    {
        "text": "1\n            :\n            T\n          \n        \n        \n          |\n        \n        \n          x\n          \n            0\n          \n        \n        )\n        ]\n      \n    \n    {\\displaystyle \\ln p_{\\theta }(x_{0})\\geq E_{x_{1:T}\\sim q(\\cdot |x_{0})}[\\ln p_{\\theta }(x_{0:T})-\\ln q(x_{1:T}|x_{0})]}\n  \n, and taking one more expectation, we get\n  \n    \n      \n        \n          E\n          \n            \n              x\n              \n                0",
        "source": "diffusion_model.txt"
    },
    {
        "text": "0\n              \n            \n            ∼\n            q\n          \n        \n        [\n        ln\n        ⁡\n        \n          p\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            0\n          \n        \n        )\n        ]\n        ≥\n        \n          E\n          \n            \n              x\n              \n                0\n                :\n                T\n              \n            \n            ∼\n            q",
        "source": "diffusion_model.txt"
    },
    {
        "text": "∼\n            q\n          \n        \n        [\n        ln\n        ⁡\n        \n          p\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            0\n            :\n            T\n          \n        \n        )\n        −\n        ln\n        ⁡\n        q\n        (\n        \n          x\n          \n            1\n            :\n            T\n          \n        \n        \n          |\n        \n        \n          x\n          \n            0",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n            0\n          \n        \n        )\n        ]\n      \n    \n    {\\displaystyle E_{x_{0}\\sim q}[\\ln p_{\\theta }(x_{0})]\\geq E_{x_{0:T}\\sim q}[\\ln p_{\\theta }(x_{0:T})-\\ln q(x_{1:T}|x_{0})]}\n  \nWe see that maximizing the quantity on the right would give us a lower bound on the likelihood of observed data. This allows us to perform variational inference.\nDefine the loss function\n  \n    \n      \n        L\n        (\n        θ\n        )\n        :=\n        −",
        "source": "diffusion_model.txt"
    },
    {
        "text": ")\n        :=\n        −\n        \n          E\n          \n            \n              x\n              \n                0\n                :\n                T\n              \n            \n            ∼\n            q\n          \n        \n        [\n        ln\n        ⁡\n        \n          p\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            0\n            :\n            T\n          \n        \n        )\n        −\n        ln\n        ⁡\n        q\n        (",
        "source": "diffusion_model.txt"
    },
    {
        "text": "−\n        ln\n        ⁡\n        q\n        (\n        \n          x\n          \n            1\n            :\n            T\n          \n        \n        \n          |\n        \n        \n          x\n          \n            0\n          \n        \n        )\n        ]\n      \n    \n    {\\displaystyle L(\\theta ):=-E_{x_{0:T}\\sim q}[\\ln p_{\\theta }(x_{0:T})-\\ln q(x_{1:T}|x_{0})]}\n  \nand now the goal is to minimize the loss by stochastic gradient descent. The expression may be simplified to",
        "source": "diffusion_model.txt"
    },
    {
        "text": "expression may be simplified to\n  \n    \n      \n        L\n        (\n        θ\n        )\n        =\n        \n          ∑\n          \n            t\n            =\n            1\n          \n          \n            T\n          \n        \n        \n          E\n          \n            \n              x\n              \n                t\n                −\n                1\n              \n            \n            ,\n            \n              x\n              \n                t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n              \n            \n            ∼\n            q\n          \n        \n        [\n        −\n        ln\n        ⁡\n        \n          p\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n            −\n            1\n          \n        \n        \n          |\n        \n        \n          x\n          \n            t\n          \n        \n        )\n        ]\n        +\n        \n          E\n          \n            \n              x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n              \n                0\n              \n            \n            ∼\n            q\n          \n        \n        [\n        \n          D\n          \n            K\n            L\n          \n        \n        (\n        q\n        (\n        \n          x\n          \n            T\n          \n        \n        \n          |\n        \n        \n          x\n          \n            0\n          \n        \n        )\n        ‖\n        \n          p\n          \n            θ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "p\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            T\n          \n        \n        )\n        )\n        ]\n        +\n        C\n      \n    \n    {\\displaystyle L(\\theta )=\\sum _{t=1}^{T}E_{x_{t-1},x_{t}\\sim q}[-\\ln p_{\\theta }(x_{t-1}|x_{t})]+E_{x_{0}\\sim q}[D_{KL}(q(x_{T}|x_{0})\\|p_{\\theta }(x_{T}))]+C}\n  \nwhere \n  \n    \n      \n        C\n      \n    \n    {\\displaystyle C}\n  \n does not depend on the parameter, and thus can be ignored. Sin",
        "source": "diffusion_model.txt"
    },
    {
        "text": "end on the parameter, and thus can be ignored. Since \n  \n    \n      \n        \n          p\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            T\n          \n        \n        )\n        =\n        \n          \n            N\n          \n        \n        (\n        \n          x\n          \n            T\n          \n        \n        \n          |\n        \n        0\n        ,\n        I\n        )\n      \n    \n    {\\displaystyle p_{\\theta }(x_{T})={\\mathcal {N}}(x_{T",
        "source": "diffusion_model.txt"
    },
    {
        "text": "isplaystyle p_{\\theta }(x_{T})={\\mathcal {N}}(x_{T}|0,I)}\n  \n also does not depend on the parameter, the term \n  \n    \n      \n        \n          E\n          \n            \n              x\n              \n                0\n              \n            \n            ∼\n            q\n          \n        \n        [\n        \n          D\n          \n            K\n            L\n          \n        \n        (\n        q\n        (\n        \n          x\n          \n            T",
        "source": "diffusion_model.txt"
    },
    {
        "text": "T\n          \n        \n        \n          |\n        \n        \n          x\n          \n            0\n          \n        \n        )\n        ‖\n        \n          p\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            T\n          \n        \n        )\n        )\n        ]\n      \n    \n    {\\displaystyle E_{x_{0}\\sim q}[D_{KL}(q(x_{T}|x_{0})\\|p_{\\theta }(x_{T}))]}\n  \n can also be ignored. This leaves just \n  \n    \n      \n        L\n        (\n        θ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ust \n  \n    \n      \n        L\n        (\n        θ\n        )\n        =\n        \n          ∑\n          \n            t\n            =\n            1\n          \n          \n            T\n          \n        \n        \n          L\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle L(\\theta )=\\sum _{t=1}^{T}L_{t}}\n  \n with \n  \n    \n      \n        \n          L\n          \n            t\n          \n        \n        =\n        \n          E\n          \n            \n              x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "E\n          \n            \n              x\n              \n                t\n                −\n                1\n              \n            \n            ,\n            \n              x\n              \n                t\n              \n            \n            ∼\n            q\n          \n        \n        [\n        −\n        ln\n        ⁡\n        \n          p\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n            −\n            1",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n            −\n            1\n          \n        \n        \n          |\n        \n        \n          x\n          \n            t\n          \n        \n        )\n        ]\n      \n    \n    {\\displaystyle L_{t}=E_{x_{t-1},x_{t}\\sim q}[-\\ln p_{\\theta }(x_{t-1}|x_{t})]}\n  \n to be minimized.\n\n\n==== Noise prediction network ====\nSince \n  \n    \n      \n        \n          x\n          \n            t\n            −\n            1\n          \n        \n        \n          |\n        \n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "|\n        \n        \n          x\n          \n            t\n          \n        \n        ,\n        \n          x\n          \n            0\n          \n        \n        ∼\n        \n          \n            N\n          \n        \n        (\n        \n          \n            \n              \n                μ\n                ~\n              \n            \n          \n          \n            t\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        ,\n        \n          x\n          \n            0\n          \n        \n        )\n        ,\n        \n          \n            \n              \n                σ\n                ~\n              \n            \n          \n          \n            t\n          \n          \n            2\n          \n        \n        I\n        )\n      \n    \n    {\\displaystyle x_{t-1}|x_{t},x_{0}\\sim {\\mathcal {N}}({\\tilde {\\mu }}_{t}(x_{t},x_{0}),{\\tilde {\\sigma }}_{t}^{2}I)}\n  \n, this suggests t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\tilde {\\sigma }}_{t}^{2}I)}\n  \n, this suggests that we should use \n  \n    \n      \n        \n          μ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        =\n        \n          \n            \n              \n                μ\n                ~\n              \n            \n          \n          \n            t\n          \n        \n        (\n        \n          x\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n            t\n          \n        \n        ,\n        \n          x\n          \n            0\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu _{\\theta }(x_{t},t)={\\tilde {\\mu }}_{t}(x_{t},x_{0})}\n  \n; however, the network does not have access to \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n, and so it has to estimate it instead. Now, since \n  \n    \n      \n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "w, since \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        \n          |\n        \n        \n          x\n          \n            0\n          \n        \n        ∼\n        N\n        \n          (\n          \n            \n              \n                \n                  \n                    \n                      \n                        α\n                        ¯",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                  \n                \n              \n            \n            \n              x\n              \n                0\n              \n            \n            ,\n            \n              σ\n              \n                t\n              \n              \n                2\n              \n            \n            I\n          \n          )\n        \n      \n    \n    {\\displaystyle x_{t}|x_{0}\\sim N\\left({\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0},\\sigm",
        "source": "diffusion_model.txt"
    },
    {
        "text": "m N\\left({\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0},\\sigma _{t}^{2}I\\right)}\n  \n, we may write \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    α\n                    ¯\n                  \n                \n              \n              \n                t\n              \n            \n          \n        \n        \n          x\n          \n            0",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n            0\n          \n        \n        +\n        \n          σ\n          \n            t\n          \n        \n        z\n      \n    \n    {\\displaystyle x_{t}={\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0}+\\sigma _{t}z}\n  \n, where \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n is some unknown gaussian noise. Now we see that estimating \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n is equivalent",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle x_{0}}\n  \n is equivalent to estimating \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n.\nTherefore, let the network output a noise vector \n  \n    \n      \n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\epsilon _{\\theta }(x_{t},t)}\n  \n, and let it predict\n  \n    \n      \n        \n          μ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n  \n    \n      \n        \n          μ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        =\n        \n          \n            \n              \n                μ\n                ~\n              \n            \n          \n          \n            t\n          \n        \n        \n          (\n          \n            \n              x\n              \n                t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n              \n            \n            ,\n            \n              \n                \n                  \n                    x\n                    \n                      t\n                    \n                  \n                  −\n                  \n                    σ\n                    \n                      t\n                    \n                  \n                  \n                    ϵ\n                    \n                      θ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "θ\n                    \n                  \n                  (\n                  \n                    x\n                    \n                      t\n                    \n                  \n                  ,\n                  t\n                  )\n                \n                \n                  \n                    \n                      \n                        \n                          α\n                          ¯",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                    \n                  \n                \n              \n            \n          \n          )\n        \n        =\n        \n          \n            \n              \n                x\n                \n                  t\n                \n              \n              −\n              \n                ϵ\n                \n                  θ\n                \n              \n              (",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n              \n                x\n                \n                  t\n                \n              \n              ,\n              t\n              )\n              \n                β\n                \n                  t\n                \n              \n              \n                /\n              \n              \n                σ\n                \n                  t\n                \n              \n            \n            \n              \n                α",
        "source": "diffusion_model.txt"
    },
    {
        "text": "α\n                \n                  t\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\theta }(x_{t},t)={\\tilde {\\mu }}_{t}\\left(x_{t},{\\frac {x_{t}-\\sigma _{t}\\epsilon _{\\theta }(x_{t},t)}{\\sqrt {{\\bar {\\alpha }}_{t}}}}\\right)={\\frac {x_{t}-\\epsilon _{\\theta }(x_{t},t)\\beta _{t}/\\sigma _{t}}{\\sqrt {\\alpha _{t}}}}}\n  \nIt remains to design \n  \n    \n      \n        \n          Σ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "Σ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\Sigma _{\\theta }(x_{t},t)}\n  \n. The DDPM paper suggested not learning it (since it resulted in \"unstable training and poorer sample quality\"), but fixing it at some value \n  \n    \n      \n        \n          Σ\n          \n            θ\n          \n        \n        (\n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        =\n        \n          ζ\n          \n            t\n          \n          \n            2\n          \n        \n        I\n      \n    \n    {\\displaystyle \\Sigma _{\\theta }(x_{t},t)=\\zeta _{t}^{2}I}\n  \n, where either \n  \n    \n      \n        \n          ζ\n          \n            t\n          \n          \n            2\n          \n        \n        =\n        \n          β",
        "source": "diffusion_model.txt"
    },
    {
        "text": "=\n        \n          β\n          \n            t\n          \n        \n        \n           or \n        \n        \n          \n            \n              \n                σ\n                ~\n              \n            \n          \n          \n            t\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\zeta _{t}^{2}=\\beta _{t}{\\text{ or }}{\\tilde {\\sigma }}_{t}^{2}}\n  \n yielded similar performance.\nWith this, the loss simplifies to",
        "source": "diffusion_model.txt"
    },
    {
        "text": "With this, the loss simplifies to \n  \n    \n      \n        \n          L\n          \n            t\n          \n        \n        =\n        \n          \n            \n              β\n              \n                t\n              \n              \n                2\n              \n            \n            \n              2\n              \n                α\n                \n                  t\n                \n              \n              \n                σ\n                \n                  t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                \n                \n                  2\n                \n              \n              \n                ζ\n                \n                  t\n                \n                \n                  2\n                \n              \n            \n          \n        \n        \n          E\n          \n            \n              x\n              \n                0\n              \n            \n            ∼\n            q\n            ;\n            z",
        "source": "diffusion_model.txt"
    },
    {
        "text": "q\n            ;\n            z\n            ∼\n            \n              \n                N\n              \n            \n            (\n            0\n            ,\n            I\n            )\n          \n        \n        \n          [\n          \n            \n              ‖\n              \n                \n                  ϵ\n                  \n                    θ\n                  \n                \n                (\n                \n                  x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n                  \n                    t\n                  \n                \n                ,\n                t\n                )\n                −\n                z\n              \n              ‖\n            \n            \n              2\n            \n          \n          ]\n        \n        +\n        C\n      \n    \n    {\\displaystyle L_{t}={\\frac {\\beta _{t}^{2}}{2\\alpha _{t}\\sigma _{t}^{2}\\zeta _{t}^{2}}}E_{x_{0}\\sim q;z\\sim {\\mathcal {N}}(0,I)}\\left[\\left\\|\\epsilon _{\\theta }(x_{t},",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{N}}(0,I)}\\left[\\left\\|\\epsilon _{\\theta }(x_{t},t)-z\\right\\|^{2}\\right]+C}\n  \nwhich may be minimized by stochastic gradient descent. The paper noted empirically that an even simpler loss function\n  \n    \n      \n        \n          L\n          \n            s\n            i\n            m\n            p\n            l\n            e\n            ,\n            t\n          \n        \n        =\n        \n          E\n          \n            \n              x\n              \n                0",
        "source": "diffusion_model.txt"
    },
    {
        "text": "0\n              \n            \n            ∼\n            q\n            ;\n            z\n            ∼\n            \n              \n                N\n              \n            \n            (\n            0\n            ,\n            I\n            )\n          \n        \n        \n          [\n          \n            \n              ‖\n              \n                \n                  ϵ\n                  \n                    θ\n                  \n                \n                (",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n                \n                  x\n                  \n                    t\n                  \n                \n                ,\n                t\n                )\n                −\n                z\n              \n              ‖\n            \n            \n              2\n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle L_{simple,t}=E_{x_{0}\\sim q;z\\sim {\\mathcal {N}}(0,I)}\\left[\\left\\|\\epsilon _{\\theta }(x_{t},t)-",
        "source": "diffusion_model.txt"
    },
    {
        "text": "}}(0,I)}\\left[\\left\\|\\epsilon _{\\theta }(x_{t},t)-z\\right\\|^{2}\\right]}\n  \nresulted in better models.\n\n\n=== Backward diffusion process ===\nAfter a noise prediction network is trained, it can be used for generating data points in the original distribution in a loop as follows:\n\nCompute the noise estimate \n  \n    \n      \n        ϵ\n        ←\n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\epsilon \\leftarrow \\epsilon _{\\theta }(x_{t},t)}\n  \n\nCompute the original data estimate \n  \n    \n      \n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            0\n          \n        \n        ←\n        (\n        \n          x\n          \n            t\n          \n        \n        −\n        \n          σ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "−\n        \n          σ\n          \n            t\n          \n        \n        ϵ\n        )\n        \n          /\n        \n        \n          \n            \n              \n                \n                  \n                    α\n                    ¯\n                  \n                \n              \n              \n                t\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\tilde {x}}_{0}\\leftarrow (x_{t}-\\sigma _{t}\\epsilon )/{\\sqrt {{\\bar {\\alpha }}",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{t}-\\sigma _{t}\\epsilon )/{\\sqrt {{\\bar {\\alpha }}_{t}}}}\n  \n\nSample the previous data \n  \n    \n      \n        \n          x\n          \n            t\n            −\n            1\n          \n        \n        ∼\n        \n          \n            N\n          \n        \n        (\n        \n          \n            \n              \n                μ\n                ~\n              \n            \n          \n          \n            t\n          \n        \n        (\n        \n          x\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n            t\n          \n        \n        ,\n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            0\n          \n        \n        )\n        ,\n        \n          \n            \n              \n                σ\n                ~\n              \n            \n          \n          \n            t\n          \n          \n            2\n          \n        \n        I\n        )",
        "source": "diffusion_model.txt"
    },
    {
        "text": "I\n        )\n      \n    \n    {\\displaystyle x_{t-1}\\sim {\\mathcal {N}}({\\tilde {\\mu }}_{t}(x_{t},{\\tilde {x}}_{0}),{\\tilde {\\sigma }}_{t}^{2}I)}\n  \n\nChange time \n  \n    \n      \n        t\n        ←\n        t\n        −\n        1\n      \n    \n    {\\displaystyle t\\leftarrow t-1}\n  \n\n\n== Score-based generative model ==\nScore-based generative model is another formulation of diffusion modelling. They are also called noise conditional score network (NCSN) or score-matching with La",
        "source": "diffusion_model.txt"
    },
    {
        "text": "nal score network (NCSN) or score-matching with Langevin dynamics (SMLD).\n\n\n=== Score matching ===\n\n\n==== The idea of score functions ====\nConsider the problem of image generation. Let \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n represent an image, and let \n  \n    \n      \n        q\n        (\n        x\n        )\n      \n    \n    {\\displaystyle q(x)}\n  \n be the probability distribution over all possible images. If we have \n  \n    \n      \n        q\n        (\n        x\n        )",
        "source": "diffusion_model.txt"
    },
    {
        "text": "q\n        (\n        x\n        )\n      \n    \n    {\\displaystyle q(x)}\n  \n itself, then we can say for certain how likely a certain image is. However, this is intractable in general.\nMost often, we are uninterested in knowing the absolute probability of a certain image. Instead, we are usually only interested in knowing how likely a certain image is compared to its immediate neighbors — e.g. how much more likely is an image of cat compared to some small variants of it? Is it more",
        "source": "diffusion_model.txt"
    },
    {
        "text": "compared to some small variants of it? Is it more likely if the image contains two whiskers, or three, or with some Gaussian noise added?\nConsequently, we are actually quite uninterested in \n  \n    \n      \n        q\n        (\n        x\n        )\n      \n    \n    {\\displaystyle q(x)}\n  \n itself, but rather, \n  \n    \n      \n        \n          ∇\n          \n            x\n          \n        \n        ln\n        ⁡\n        q\n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\nabla _{x}\\ln q(x)",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle \\nabla _{x}\\ln q(x)}\n  \n. This has two major effects:\n\nOne, we no longer need to normalize \n  \n    \n      \n        q\n        (\n        x\n        )\n      \n    \n    {\\displaystyle q(x)}\n  \n, but can use any \n  \n    \n      \n        \n          \n            \n              q\n              ~\n            \n          \n        \n        (\n        x\n        )\n        =\n        C\n        q\n        (\n        x\n        )\n      \n    \n    {\\displaystyle {\\tilde {q}}(x)=Cq(x)}\n  \n, w",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle {\\tilde {q}}(x)=Cq(x)}\n  \n, where \n  \n    \n      \n        C\n        =\n        ∫\n        \n          \n            \n              q\n              ~\n            \n          \n        \n        (\n        x\n        )\n        d\n        x\n        >\n        0\n      \n    \n    {\\displaystyle C=\\int {\\tilde {q}}(x)dx>0}\n  \n is any unknown constant that is of no concern to us.\nTwo, we are comparing \n  \n    \n      \n        q\n        (\n        x\n        )\n      \n    \n    {\\displaystyle q(x)}",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n        )\n      \n    \n    {\\displaystyle q(x)}\n  \n neighbors \n  \n    \n      \n        q\n        (\n        x\n        +\n        d\n        x\n        )\n      \n    \n    {\\displaystyle q(x+dx)}\n  \n, by \n  \n    \n      \n        \n          \n            \n              q\n              (\n              x\n              )\n            \n            \n              q\n              (\n              x\n              +\n              d\n              x\n              )\n            \n          \n        \n        =",
        "source": "diffusion_model.txt"
    },
    {
        "text": "=\n        \n          e\n          \n            −\n            ⟨\n            \n              ∇\n              \n                x\n              \n            \n            ln\n            ⁡\n            q\n            ,\n            d\n            x\n            ⟩\n          \n        \n      \n    \n    {\\displaystyle {\\frac {q(x)}{q(x+dx)}}=e^{-\\langle \\nabla _{x}\\ln q,dx\\rangle }}\n  \n\nLet the score function be \n  \n    \n      \n        s\n        (\n        x\n        )",
        "source": "diffusion_model.txt"
    },
    {
        "text": "s\n        (\n        x\n        )\n        :=\n        \n          ∇\n          \n            x\n          \n        \n        ln\n        ⁡\n        q\n        (\n        x\n        )\n      \n    \n    {\\displaystyle s(x):=\\nabla _{x}\\ln q(x)}\n  \n; then consider what we can do with \n  \n    \n      \n        s\n        (\n        x\n        )\n      \n    \n    {\\displaystyle s(x)}\n  \n.\nAs it turns out, \n  \n    \n      \n        s\n        (\n        x\n        )\n      \n    \n    {\\displaystyle s(x)}\n  \n allows us",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle s(x)}\n  \n allows us to sample from \n  \n    \n      \n        q\n        (\n        x\n        )\n      \n    \n    {\\displaystyle q(x)}\n  \n using thermodynamics. Specifically, if we have a potential energy function \n  \n    \n      \n        U\n        (\n        x\n        )\n        =\n        −\n        ln\n        ⁡\n        q\n        (\n        x\n        )\n      \n    \n    {\\displaystyle U(x)=-\\ln q(x)}\n  \n, and a lot of particles in the potential well, then the distribution at th",
        "source": "diffusion_model.txt"
    },
    {
        "text": "in the potential well, then the distribution at thermodynamic equilibrium is the Boltzmann distribution \n  \n    \n      \n        \n          q\n          \n            U\n          \n        \n        (\n        x\n        )\n        ∝\n        \n          e\n          \n            −\n            U\n            (\n            x\n            )\n            \n              /\n            \n            \n              k\n              \n                B\n              \n            \n            T",
        "source": "diffusion_model.txt"
    },
    {
        "text": "T\n          \n        \n        =\n        q\n        (\n        x\n        \n          )\n          \n            1\n            \n              /\n            \n            \n              k\n              \n                B\n              \n            \n            T\n          \n        \n      \n    \n    {\\displaystyle q_{U}(x)\\propto e^{-U(x)/k_{B}T}=q(x)^{1/k_{B}T}}\n  \n. At temperature \n  \n    \n      \n        \n          k\n          \n            B\n          \n        \n        T\n        =",
        "source": "diffusion_model.txt"
    },
    {
        "text": "B\n          \n        \n        T\n        =\n        1\n      \n    \n    {\\displaystyle k_{B}T=1}\n  \n, the Boltzmann distribution is exactly \n  \n    \n      \n        q\n        (\n        x\n        )\n      \n    \n    {\\displaystyle q(x)}\n  \n.\nTherefore, to model \n  \n    \n      \n        q\n        (\n        x\n        )\n      \n    \n    {\\displaystyle q(x)}\n  \n, we may start with a particle sampled at any convenient distribution (such as the standard gaussian distribution), then simulate the motion of",
        "source": "diffusion_model.txt"
    },
    {
        "text": "aussian distribution), then simulate the motion of the particle forwards according to the Langevin equation\n\n  \n    \n      \n        d\n        \n          x\n          \n            t\n          \n        \n        =\n        −\n        \n          ∇\n          \n            \n              x\n              \n                t\n              \n            \n          \n        \n        U\n        (\n        \n          x\n          \n            t\n          \n        \n        )\n        d\n        t\n        +\n        d",
        "source": "diffusion_model.txt"
    },
    {
        "text": ")\n        d\n        t\n        +\n        d\n        \n          W\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle dx_{t}=-\\nabla _{x_{t}}U(x_{t})dt+dW_{t}}\n  \n\nand the Boltzmann distribution is, by Fokker-Planck equation, the unique thermodynamic equilibrium. So no matter what distribution \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n has, the distribution of",
        "source": "diffusion_model.txt"
    },
    {
        "text": "the distribution of \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t}}\n  \n converges in distribution to \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n  \n as \n  \n    \n      \n        t\n        →\n        ∞\n      \n    \n    {\\displaystyle t\\to \\infty }\n  \n.\n\n\n==== Learning the score function ====\nGiven a density \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n  \n, we wish to learn a score function approxim",
        "source": "diffusion_model.txt"
    },
    {
        "text": "q}\n  \n, we wish to learn a score function approximation \n  \n    \n      \n        \n          f\n          \n            θ\n          \n        \n        ≈\n        ∇\n        ln\n        ⁡\n        q\n      \n    \n    {\\displaystyle f_{\\theta }\\approx \\nabla \\ln q}\n  \n. This is score matching. Typically, score matching is formalized as minimizing Fisher divergence function \n  \n    \n      \n        \n          E\n          \n            q\n          \n        \n        [\n        ‖\n        \n          f",
        "source": "diffusion_model.txt"
    },
    {
        "text": "[\n        ‖\n        \n          f\n          \n            θ\n          \n        \n        (\n        x\n        )\n        −\n        ∇\n        ln\n        ⁡\n        q\n        (\n        x\n        )\n        \n          ‖\n          \n            2\n          \n        \n        ]\n      \n    \n    {\\displaystyle E_{q}[\\|f_{\\theta }(x)-\\nabla \\ln q(x)\\|^{2}]}\n  \n. By expanding the integral, and performing an integration by parts, \n  \n    \n      \n        \n          E\n          \n            q",
        "source": "diffusion_model.txt"
    },
    {
        "text": "E\n          \n            q\n          \n        \n        [\n        ‖\n        \n          f\n          \n            θ\n          \n        \n        (\n        x\n        )\n        −\n        ∇\n        ln\n        ⁡\n        q\n        (\n        x\n        )\n        \n          ‖\n          \n            2\n          \n        \n        ]\n        =\n        \n          E\n          \n            q\n          \n        \n        [\n        ‖\n        \n          f\n          \n            θ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "θ\n          \n        \n        \n          ‖\n          \n            2\n          \n        \n        +\n        2\n        ∇\n        ⋅\n        \n          f\n          \n            θ\n          \n        \n        ]\n        +\n        C\n      \n    \n    {\\displaystyle E_{q}[\\|f_{\\theta }(x)-\\nabla \\ln q(x)\\|^{2}]=E_{q}[\\|f_{\\theta }\\|^{2}+2\\nabla \\cdot f_{\\theta }]+C}\n  \ngiving us a loss function, also known as the Hyvärinen scoring rule, that can be minimized by stochastic gradient descent.\n\n\n==",
        "source": "diffusion_model.txt"
    },
    {
        "text": "be minimized by stochastic gradient descent.\n\n\n==== Annealing the score function ====\nSuppose we need to model the distribution of images, and we want \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n        ∼\n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        I\n        )\n      \n    \n    {\\displaystyle x_{0}\\sim {\\mathcal {N}}(0,I)}\n  \n, a white-noise image. Now, most white-noise images do not look like real images, so",
        "source": "diffusion_model.txt"
    },
    {
        "text": "e-noise images do not look like real images, so \n  \n    \n      \n        q\n        (\n        \n          x\n          \n            0\n          \n        \n        )\n        ≈\n        0\n      \n    \n    {\\displaystyle q(x_{0})\\approx 0}\n  \n for large swaths of \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n        ∼\n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        I\n        )\n      \n    \n    {\\displaystyle x_{0}\\sim {\\mathcal",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle x_{0}\\sim {\\mathcal {N}}(0,I)}\n  \n. This presents a problem for learning the score function, because if there are no samples around a certain point, then we can't learn the score function at that point. If we do not know the score function \n  \n    \n      \n        \n          ∇\n          \n            \n              x\n              \n                t\n              \n            \n          \n        \n        ln\n        ⁡\n        q\n        (\n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "q\n        (\n        \n          x\n          \n            t\n          \n        \n        )\n      \n    \n    {\\displaystyle \\nabla _{x_{t}}\\ln q(x_{t})}\n  \n at that point, then we cannot impose the time-evolution equation on a particle:\n  \n    \n      \n        d\n        \n          x\n          \n            t\n          \n        \n        =\n        \n          ∇\n          \n            \n              x\n              \n                t\n              \n            \n          \n        \n        ln",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ln\n        ⁡\n        q\n        (\n        \n          x\n          \n            t\n          \n        \n        )\n        d\n        t\n        +\n        d\n        \n          W\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle dx_{t}=\\nabla _{x_{t}}\\ln q(x_{t})dt+dW_{t}}\n  \nTo deal with this problem, we perform annealing. If \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n  \n is too different from a white-noise distribution,",
        "source": "diffusion_model.txt"
    },
    {
        "text": "is too different from a white-noise distribution, then progressively add noise until it is indistinguishable from one. That is, we perform a forward diffusion, then learn the score function, then use the score function to perform a backward diffusion.\n\n\n=== Continuous diffusion processes ===\n\n\n==== Forward diffusion process ====\nConsider again the forward diffusion process, but this time in continuous time:\n  \n    \n      \n        \n          x\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        =\n        \n          \n            1\n            −\n            \n              β\n              \n                t\n              \n            \n          \n        \n        \n          x\n          \n            t\n            −\n            1\n          \n        \n        +\n        \n          \n            \n              β\n              \n                t\n              \n            \n          \n        \n        \n          z\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "z\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t}={\\sqrt {1-\\beta _{t}}}x_{t-1}+{\\sqrt {\\beta _{t}}}z_{t}}\n  \nBy taking the \n  \n    \n      \n        \n          β\n          \n            t\n          \n        \n        →\n        β\n        (\n        t\n        )\n        d\n        t\n        ,\n        \n          \n            d\n            t\n          \n        \n        \n          z\n          \n            t\n          \n        \n        →\n        d",
        "source": "diffusion_model.txt"
    },
    {
        "text": "→\n        d\n        \n          W\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle \\beta _{t}\\to \\beta (t)dt,{\\sqrt {dt}}z_{t}\\to dW_{t}}\n  \n limit, we obtain a continuous diffusion process, in the form of a stochastic differential equation:\n  \n    \n      \n        d\n        \n          x\n          \n            t\n          \n        \n        =\n        −\n        \n          \n            1\n            2\n          \n        \n        β\n        (",
        "source": "diffusion_model.txt"
    },
    {
        "text": "2\n          \n        \n        β\n        (\n        t\n        )\n        \n          x\n          \n            t\n          \n        \n        d\n        t\n        +\n        \n          \n            β\n            (\n            t\n            )\n          \n        \n        d\n        \n          W\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle dx_{t}=-{\\frac {1}{2}}\\beta (t)x_{t}dt+{\\sqrt {\\beta (t)}}dW_{t}}\n  \nwhere \n  \n    \n      \n        \n          W\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "W\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle W_{t}}\n  \n is a Wiener process (multidimensional Brownian motion).\nNow, the equation is exactly a special case of the overdamped Langevin equation\n  \n    \n      \n        d\n        \n          x\n          \n            t\n          \n        \n        =\n        −\n        \n          \n            D\n            \n              \n                k\n                \n                  B",
        "source": "diffusion_model.txt"
    },
    {
        "text": "B\n                \n              \n              T\n            \n          \n        \n        (\n        \n          ∇\n          \n            x\n          \n        \n        U\n        )\n        d\n        t\n        +\n        \n          \n            2\n            D\n          \n        \n        d\n        \n          W\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle dx_{t}=-{\\frac {D}{k_{B}T}}(\\nabla _{x}U)dt+{\\sqrt {2D}}dW_{t}}\n  \nwhere",
        "source": "diffusion_model.txt"
    },
    {
        "text": "+{\\sqrt {2D}}dW_{t}}\n  \nwhere \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n is diffusion tensor, \n  \n    \n      \n        T\n      \n    \n    {\\displaystyle T}\n  \n is temperature, and \n  \n    \n      \n        U\n      \n    \n    {\\displaystyle U}\n  \n is potential energy field. If we substitute in \n  \n    \n      \n        D\n        =\n        \n          \n            1\n            2\n          \n        \n        β\n        (\n        t\n        )\n        I\n        ,\n        \n          k",
        "source": "diffusion_model.txt"
    },
    {
        "text": ")\n        I\n        ,\n        \n          k\n          \n            B\n          \n        \n        T\n        =\n        1\n        ,\n        U\n        =\n        \n          \n            1\n            2\n          \n        \n        ‖\n        x\n        \n          ‖\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle D={\\frac {1}{2}}\\beta (t)I,k_{B}T=1,U={\\frac {1}{2}}\\|x\\|^{2}}\n  \n, we recover the above equation. This explains why the phrase \"Langevin dynamics\" is sometimes used",
        "source": "diffusion_model.txt"
    },
    {
        "text": "y the phrase \"Langevin dynamics\" is sometimes used in diffusion models.\nNow the above equation is for the stochastic motion of a single particle. Suppose we have a cloud of particles distributed according to \n  \n    \n      \n        q\n      \n    \n    {\\displaystyle q}\n  \n at time \n  \n    \n      \n        t\n        =\n        0\n      \n    \n    {\\displaystyle t=0}\n  \n, then after a long time, the cloud of particles would settle into the stable distribution of",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ution of \n  \n    \n      \n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        I\n        )\n      \n    \n    {\\displaystyle {\\mathcal {N}}(0,I)}\n  \n. Let \n  \n    \n      \n        \n          ρ\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle \\rho _{t}}\n  \n be the density of the cloud of particles at time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n, then we have\n  \n    \n      \n        \n          ρ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ρ\n          \n            0\n          \n        \n        =\n        q\n        ;\n        \n        \n          ρ\n          \n            T\n          \n        \n        ≈\n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        I\n        )\n      \n    \n    {\\displaystyle \\rho _{0}=q;\\quad \\rho _{T}\\approx {\\mathcal {N}}(0,I)}\n  \nand the goal is to somehow reverse the process, so that we can start at the end and diffuse back to the beginning.",
        "source": "diffusion_model.txt"
    },
    {
        "text": "art at the end and diffuse back to the beginning.\nBy Fokker-Planck equation, the density of the cloud evolves according to\n  \n    \n      \n        \n          ∂\n          \n            t\n          \n        \n        ln\n        ⁡\n        \n          ρ\n          \n            t\n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        β\n        (\n        t\n        )\n        \n          (\n          \n            n\n            +\n            (\n            x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "n\n            +\n            (\n            x\n            +\n            ∇\n            ln\n            ⁡\n            \n              ρ\n              \n                t\n              \n            \n            )\n            ⋅\n            ∇\n            ln\n            ⁡\n            \n              ρ\n              \n                t\n              \n            \n            +\n            Δ\n            ln\n            ⁡\n            \n              ρ\n              \n                t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n              \n            \n          \n          )\n        \n      \n    \n    {\\displaystyle \\partial _{t}\\ln \\rho _{t}={\\frac {1}{2}}\\beta (t)\\left(n+(x+\\nabla \\ln \\rho _{t})\\cdot \\nabla \\ln \\rho _{t}+\\Delta \\ln \\rho _{t}\\right)}\n  \nwhere \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n is the dimension of space, and \n  \n    \n      \n        Δ\n      \n    \n    {\\displaystyle \\Delta }\n  \n is the Laplace operator. Equivalently,",
        "source": "diffusion_model.txt"
    },
    {
        "text": ". Equivalently,\n  \n    \n      \n        \n          ∂\n          \n            t\n          \n        \n        \n          ρ\n          \n            t\n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        β\n        (\n        t\n        )\n        (\n        ∇\n        ⋅\n        (\n        x\n        \n          ρ\n          \n            t\n          \n        \n        )\n        +\n        Δ\n        \n          ρ\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        )\n      \n    \n    {\\displaystyle \\partial _{t}\\rho _{t}={\\frac {1}{2}}\\beta (t)(\\nabla \\cdot (x\\rho _{t})+\\Delta \\rho _{t})}\n  \n\n\n==== Backward diffusion process ====\nIf we have solved \n  \n    \n      \n        \n          ρ\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle \\rho _{t}}\n  \n for time \n  \n    \n      \n        t\n        ∈\n        [\n        0\n        ,\n        T\n        ]\n      \n    \n    {\\displaystyle t\\in [0,T]",
        "source": "diffusion_model.txt"
    },
    {
        "text": "]\n      \n    \n    {\\displaystyle t\\in [0,T]}\n  \n, then we can exactly reverse the evolution of the cloud. Suppose we start with another cloud of particles with density \n  \n    \n      \n        \n          ν\n          \n            0\n          \n        \n        =\n        \n          ρ\n          \n            T\n          \n        \n      \n    \n    {\\displaystyle \\nu _{0}=\\rho _{T}}\n  \n, and let the particles in the cloud evolve according to\n\n  \n    \n      \n        d\n        \n          y",
        "source": "diffusion_model.txt"
    },
    {
        "text": "d\n        \n          y\n          \n            t\n          \n        \n        =\n        \n          \n            1\n            2\n          \n        \n        β\n        (\n        T\n        −\n        t\n        )\n        \n          y\n          \n            t\n          \n        \n        d\n        t\n        +\n        β\n        (\n        T\n        −\n        t\n        )\n        \n          \n            \n              \n                \n                  ∇",
        "source": "diffusion_model.txt"
    },
    {
        "text": "∇\n                  \n                    \n                      y\n                      \n                        t\n                      \n                    \n                  \n                \n                ln\n                ⁡\n                \n                  ρ\n                  \n                    T\n                    −\n                    t\n                  \n                \n                \n                  (\n                  \n                    y",
        "source": "diffusion_model.txt"
    },
    {
        "text": "y\n                    \n                      t\n                    \n                  \n                  )\n                \n              \n              ⏟\n            \n          \n          \n            score function \n          \n        \n        d\n        t\n        +\n        \n          \n            β\n            (\n            T\n            −\n            t\n            )\n          \n        \n        d\n        \n          W\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "W\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle dy_{t}={\\frac {1}{2}}\\beta (T-t)y_{t}dt+\\beta (T-t)\\underbrace {\\nabla _{y_{t}}\\ln \\rho _{T-t}\\left(y_{t}\\right)} _{\\text{score function }}dt+{\\sqrt {\\beta (T-t)}}dW_{t}}\n  \n\nthen by plugging into the Fokker-Planck equation, we find that \n  \n    \n      \n        \n          ∂\n          \n            t\n          \n        \n        \n          ρ\n          \n            T\n            −\n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "−\n            t\n          \n        \n        =\n        \n          ∂\n          \n            t\n          \n        \n        \n          ν\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle \\partial _{t}\\rho _{T-t}=\\partial _{t}\\nu _{t}}\n  \n. Thus this cloud of points is the original cloud, evolving backwards.\n\n\n=== Noise conditional score network (NCSN) ===\nAt the continuous limit, \n\n  \n    \n      \n        \n          \n            \n              \n                α",
        "source": "diffusion_model.txt"
    },
    {
        "text": "α\n                ¯\n              \n            \n          \n          \n            t\n          \n        \n        =\n        (\n        1\n        −\n        \n          β\n          \n            1\n          \n        \n        )\n        ⋯\n        (\n        1\n        −\n        \n          β\n          \n            t\n          \n        \n        )\n        =\n        \n          e\n          \n            \n              ∑\n              \n                i",
        "source": "diffusion_model.txt"
    },
    {
        "text": "i\n              \n            \n            ln\n            ⁡\n            (\n            1\n            −\n            \n              β\n              \n                i\n              \n            \n            )\n          \n        \n        →\n        \n          e\n          \n            −\n            \n              ∫\n              \n                0\n              \n              \n                t\n              \n            \n            β\n            (\n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "β\n            (\n            t\n            )\n            d\n            t\n          \n        \n      \n    \n    {\\displaystyle {\\bar {\\alpha }}_{t}=(1-\\beta _{1})\\cdots (1-\\beta _{t})=e^{\\sum _{i}\\ln(1-\\beta _{i})}\\to e^{-\\int _{0}^{t}\\beta (t)dt}}\n  \n\nand so \n\n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        \n          |\n        \n        \n          x\n          \n            0\n          \n        \n        ∼\n        N\n        \n          (",
        "source": "diffusion_model.txt"
    },
    {
        "text": "∼\n        N\n        \n          (\n          \n            \n              e\n              \n                −\n                \n                  \n                    1\n                    2\n                  \n                \n                \n                  ∫\n                  \n                    0\n                  \n                  \n                    t\n                  \n                \n                β\n                (\n                t\n                )\n                d",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                )\n                d\n                t\n              \n            \n            \n              x\n              \n                0\n              \n            \n            ,\n            \n              (\n              \n                1\n                −\n                \n                  e\n                  \n                    −\n                    \n                      ∫\n                      \n                        0",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                      \n                    \n                    β\n                    (\n                    t\n                    )\n                    d\n                    t\n                  \n                \n              \n              )\n            \n            I\n          \n          )\n        \n      \n    \n    {\\displaystyle x_{t}|x_{0}\\sim N\\left(e^{-{\\frac {1}{2}}\\int _{0}^{t}\\beta (t)dt}x_{0},\\left(1-e^{-\\int _{0}^{t}\\beta",
        "source": "diffusion_model.txt"
    },
    {
        "text": "}\\beta (t)dt}x_{0},\\left(1-e^{-\\int _{0}^{t}\\beta (t)dt}\\right)I\\right)}\n  \n\nIn particular, we see that we can directly sample from any point in the continuous diffusion process without going through the intermediate steps, by first sampling \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n        ∼\n        q\n        ,\n        z\n        ∼\n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        I\n        )\n      \n    \n    {\\disp",
        "source": "diffusion_model.txt"
    },
    {
        "text": ",\n        I\n        )\n      \n    \n    {\\displaystyle x_{0}\\sim q,z\\sim {\\mathcal {N}}(0,I)}\n  \n, then get \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        =\n        \n          e\n          \n            −\n            \n              \n                1\n                2\n              \n            \n            \n              ∫\n              \n                0\n              \n              \n                t\n              \n            \n            β",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n              \n            \n            β\n            (\n            t\n            )\n            d\n            t\n          \n        \n        \n          x\n          \n            0\n          \n        \n        +\n        \n          (\n          \n            1\n            −\n            \n              e\n              \n                −\n                \n                  ∫\n                  \n                    0\n                  \n                  \n                    t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                  \n                \n                β\n                (\n                t\n                )\n                d\n                t\n              \n            \n          \n          )\n        \n        z\n      \n    \n    {\\displaystyle x_{t}=e^{-{\\frac {1}{2}}\\int _{0}^{t}\\beta (t)dt}x_{0}+\\left(1-e^{-\\int _{0}^{t}\\beta (t)dt}\\right)z}\n  \n. That is, we can quickly sample \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        ∼",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        ∼\n        \n          ρ\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t}\\sim \\rho _{t}}\n  \n for any \n  \n    \n      \n        t\n        ≥\n        0\n      \n    \n    {\\displaystyle t\\geq 0}\n  \n.\nNow, define a certain probability distribution \n  \n    \n      \n        γ\n      \n    \n    {\\displaystyle \\gamma }\n  \n over \n  \n    \n      \n        [\n        0\n        ,\n        ∞\n        )\n      \n    \n    {\\displaystyle [0,\\infty )}",
        "source": "diffusion_model.txt"
    },
    {
        "text": ")\n      \n    \n    {\\displaystyle [0,\\infty )}\n  \n, then the score-matching loss function is defined as the expected Fisher divergence:\n\n  \n    \n      \n        L\n        (\n        θ\n        )\n        =\n        \n          E\n          \n            t\n            ∼\n            γ\n            ,\n            \n              x\n              \n                t\n              \n            \n            ∼\n            \n              ρ\n              \n                t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n              \n            \n          \n        \n        [\n        ‖\n        \n          f\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        \n          ‖\n          \n            2\n          \n        \n        +\n        2\n        ∇\n        ⋅\n        \n          f\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        ,\n        t\n        )\n        ]\n      \n    \n    {\\displaystyle L(\\theta )=E_{t\\sim \\gamma ,x_{t}\\sim \\rho _{t}}[\\|f_{\\theta }(x_{t},t)\\|^{2}+2\\nabla \\cdot f_{\\theta }(x_{t},t)]}\n  \n\nAfter training, \n  \n    \n      \n        \n          f\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        ≈\n        ∇\n        ln\n        ⁡\n        \n          ρ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "∇\n        ln\n        ⁡\n        \n          ρ\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle f_{\\theta }(x_{t},t)\\approx \\nabla \\ln \\rho _{t}}\n  \n, so we can perform the backwards diffusion process by first sampling \n  \n    \n      \n        \n          x\n          \n            T\n          \n        \n        ∼\n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        I\n        )\n      \n    \n    {\\displaystyle x_{T}\\sim {\\mathcal {N}",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle x_{T}\\sim {\\mathcal {N}}(0,I)}\n  \n, then integrating the SDE from \n  \n    \n      \n        t\n        =\n        T\n      \n    \n    {\\displaystyle t=T}\n  \n to \n  \n    \n      \n        t\n        =\n        0\n      \n    \n    {\\displaystyle t=0}\n  \n:\n\n  \n    \n      \n        \n          x\n          \n            t\n            −\n            d\n            t\n          \n        \n        =\n        \n          x\n          \n            t\n          \n        \n        +",
        "source": "diffusion_model.txt"
    },
    {
        "text": "+\n        \n          \n            1\n            2\n          \n        \n        β\n        (\n        t\n        )\n        \n          x\n          \n            t\n          \n        \n        d\n        t\n        +\n        β\n        (\n        t\n        )\n        \n          f\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        d\n        t\n        +",
        "source": "diffusion_model.txt"
    },
    {
        "text": "d\n        t\n        +\n        \n          \n            β\n            (\n            t\n            )\n          \n        \n        d\n        \n          W\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t-dt}=x_{t}+{\\frac {1}{2}}\\beta (t)x_{t}dt+\\beta (t)f_{\\theta }(x_{t},t)dt+{\\sqrt {\\beta (t)}}dW_{t}}\n  \n\nThis may be done by any SDE integration method, such as Euler–Maruyama method.\nThe name \"noise conditional score network\" is explained thus:\n\n\"network\", because",
        "source": "diffusion_model.txt"
    },
    {
        "text": "network\" is explained thus:\n\n\"network\", because \n  \n    \n      \n        \n          f\n          \n            θ\n          \n        \n      \n    \n    {\\displaystyle f_{\\theta }}\n  \n is implemented as a neural network.\n\"score\", because the output of the network is interpreted as approximating the score function \n  \n    \n      \n        ∇\n        ln\n        ⁡\n        \n          ρ\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle \\nabla \\ln \\rho _{t}}\n  \n.\n\"noise conditional\",",
        "source": "diffusion_model.txt"
    },
    {
        "text": "e \\nabla \\ln \\rho _{t}}\n  \n.\n\"noise conditional\", because \n  \n    \n      \n        \n          ρ\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle \\rho _{t}}\n  \n is equal to \n  \n    \n      \n        \n          ρ\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\rho _{0}}\n  \n blurred by an added gaussian noise that increases with time, and so the score function depends on the amount of noise added.\n\n\n== Their equivalence ==\nDDPM and score-based ge",
        "source": "diffusion_model.txt"
    },
    {
        "text": "== Their equivalence ==\nDDPM and score-based generative models are equivalent. This means that a network trained using DDPM can be used as a NCSN, and vice versa.\nWe know that \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        \n          |\n        \n        \n          x\n          \n            0\n          \n        \n        ∼\n        N\n        \n          (",
        "source": "diffusion_model.txt"
    },
    {
        "text": "α\n                        ¯\n                      \n                    \n                  \n                  \n                    t\n                  \n                \n              \n            \n            \n              x\n              \n                0\n              \n            \n            ,\n            \n              σ\n              \n                t\n              \n              \n                2",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n              \n              \n                2\n              \n            \n            I\n          \n          )\n        \n      \n    \n    {\\displaystyle x_{t}|x_{0}\\sim N\\left({\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0},\\sigma _{t}^{2}I\\right)}\n  \n, so by Tweedie's formula, we have\n\n  \n    \n      \n        \n          ∇\n          \n            \n              x\n              \n                t\n              \n            \n          \n        \n        ln\n        ⁡\n        q\n        (\n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "⁡\n        q\n        (\n        \n          x\n          \n            t\n          \n        \n        )\n        =\n        \n          \n            1\n            \n              σ\n              \n                t\n              \n              \n                2\n              \n            \n          \n        \n        (\n        −\n        \n          x\n          \n            t\n          \n        \n        +",
        "source": "diffusion_model.txt"
    },
    {
        "text": "α\n                    ¯\n                  \n                \n              \n              \n                t\n              \n            \n          \n        \n        \n          E\n          \n            q\n          \n        \n        [\n        \n          x\n          \n            0\n          \n        \n        \n          |\n        \n        \n          x\n          \n            t\n          \n        \n        ]\n        )\n      \n    \n    {\\displaystyle",
        "source": "diffusion_model.txt"
    },
    {
        "text": "]\n        )\n      \n    \n    {\\displaystyle \\nabla _{x_{t}}\\ln q(x_{t})={\\frac {1}{\\sigma _{t}^{2}}}(-x_{t}+{\\sqrt {{\\bar {\\alpha }}_{t}}}E_{q}[x_{0}|x_{t}])}\n  \n\nAs described previously, the DDPM loss function is \n  \n    \n      \n        \n          ∑\n          \n            t\n          \n        \n        \n          L\n          \n            s\n            i\n            m\n            p\n            l\n            e\n            ,\n            t\n          \n        \n      \n    \n    {\\displaystyle \\su",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle \\sum _{t}L_{simple,t}}\n  \n with\n\n  \n    \n      \n        \n          L\n          \n            s\n            i\n            m\n            p\n            l\n            e\n            ,\n            t\n          \n        \n        =\n        \n          E\n          \n            \n              x\n              \n                0\n              \n            \n            ∼\n            q\n            ;\n            z\n            ∼",
        "source": "diffusion_model.txt"
    },
    {
        "text": "∼\n            \n              \n                N\n              \n            \n            (\n            0\n            ,\n            I\n            )\n          \n        \n        \n          [\n          \n            \n              ‖\n              \n                \n                  ϵ\n                  \n                    θ\n                  \n                \n                (\n                \n                  x\n                  \n                    t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                  \n                \n                ,\n                t\n                )\n                −\n                z\n              \n              ‖\n            \n            \n              2\n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle L_{simple,t}=E_{x_{0}\\sim q;z\\sim {\\mathcal {N}}(0,I)}\\left[\\left\\|\\epsilon _{\\theta }(x_{t},t)-z\\right\\|^{2}\\right]}\n  \n\nwhere \n  \n    \n      \n        \n          x\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    α\n                    ¯\n                  \n                \n              \n              \n                t\n              \n            \n          \n        \n        \n          x\n          \n            0\n          \n        \n        +\n        \n          σ\n          \n            t\n          \n        \n        z\n      \n    \n    {\\displaystyle x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "z\n      \n    \n    {\\displaystyle x_{t}={\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0}+\\sigma _{t}z}\n  \n. By a change of variables,\n\n  \n    \n      \n        \n          L\n          \n            s\n            i\n            m\n            p\n            l\n            e\n            ,\n            t\n          \n        \n        =\n        \n          E\n          \n            \n              x\n              \n                0\n              \n            \n            ,\n            \n              x",
        "source": "diffusion_model.txt"
    },
    {
        "text": ",\n            \n              x\n              \n                t\n              \n            \n            ∼\n            q\n          \n        \n        \n          [\n          \n            \n              ‖\n              \n                \n                  ϵ\n                  \n                    θ\n                  \n                \n                (\n                \n                  x\n                  \n                    t\n                  \n                \n                ,",
        "source": "diffusion_model.txt"
    },
    {
        "text": ",\n                t\n                )\n                −\n                \n                  \n                    \n                      \n                        x\n                        \n                          t\n                        \n                      \n                      −",
        "source": "diffusion_model.txt"
    },
    {
        "text": "α\n                                  ¯\n                                \n                              \n                            \n                            \n                              t\n                            \n                          \n                        \n                      \n                      \n                        x\n                        \n                          0",
        "source": "diffusion_model.txt"
    },
    {
        "text": "0\n                        \n                      \n                    \n                    \n                      σ\n                      \n                        t\n                      \n                    \n                  \n                \n              \n              ‖\n            \n            \n              2\n            \n          \n          ]\n        \n        =\n        \n          E\n          \n            \n              x\n              \n                t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n              \n                t\n              \n            \n            ∼\n            q\n            ,\n            \n              x\n              \n                0\n              \n            \n            ∼\n            q\n            (\n            ⋅\n            \n              |\n            \n            \n              x\n              \n                t\n              \n            \n            )\n          \n        \n        \n          [\n          \n            \n              ‖",
        "source": "diffusion_model.txt"
    },
    {
        "text": "‖\n              \n                \n                  ϵ\n                  \n                    θ\n                  \n                \n                (\n                \n                  x\n                  \n                    t\n                  \n                \n                ,\n                t\n                )\n                −\n                \n                  \n                    \n                      \n                        x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n                        \n                          t\n                        \n                      \n                      −\n                      \n                        \n                          \n                            \n                              \n                                \n                                  α\n                                  ¯",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                            \n                          \n                        \n                      \n                      \n                        x\n                        \n                          0\n                        \n                      \n                    \n                    \n                      σ\n                      \n                        t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                      \n                    \n                  \n                \n              \n              ‖\n            \n            \n              2\n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle L_{simple,t}=E_{x_{0},x_{t}\\sim q}\\left[\\left\\|\\epsilon _{\\theta }(x_{t},t)-{\\frac {x_{t}-{\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0}}{\\sigma _{t}}}\\right\\|^{2}\\right]=E_{x_{t}\\sim q,x_{0}\\sim q(\\cdot |x_{t})}\\left[\\left\\|\\epsilon _{\\theta }(x_{t},t)-{\\frac {x_{t}-{\\sq",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\\|\\epsilon _{\\theta }(x_{t},t)-{\\frac {x_{t}-{\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0}}{\\sigma _{t}}}\\right\\|^{2}\\right]}\n  \n\nand the term inside becomes a least squares regression, so if the network actually reaches the global minimum of loss, then we have \n  \n    \n      \n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        =",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n                \n                  t\n                \n              \n              −\n              \n                \n                  \n                    \n                      \n                        \n                          α\n                          ¯\n                        \n                      \n                    \n                    \n                      t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "E\n                \n                  q\n                \n              \n              [\n              \n                x\n                \n                  0\n                \n              \n              \n                |\n              \n              \n                x\n                \n                  t\n                \n              \n              ]\n            \n            \n              σ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "σ\n              \n                t\n              \n            \n          \n        \n        =\n        −\n        \n          σ\n          \n            t\n          \n        \n        \n          ∇\n          \n            \n              x\n              \n                t\n              \n            \n          \n        \n        ln\n        ⁡\n        q\n        (\n        \n          x\n          \n            t\n          \n        \n        )\n      \n    \n    {\\displaystyle \\",
        "source": "diffusion_model.txt"
    },
    {
        "text": ")\n      \n    \n    {\\displaystyle \\epsilon _{\\theta }(x_{t},t)={\\frac {x_{t}-{\\sqrt {{\\bar {\\alpha }}_{t}}}E_{q}[x_{0}|x_{t}]}{\\sigma _{t}}}=-\\sigma _{t}\\nabla _{x_{t}}\\ln q(x_{t})}\n  \n\nThus, a score-based network predicts noise, and can be used for denoising.\nConversely, the continuous limit \n  \n    \n      \n        \n          x\n          \n            t\n            −\n            1\n          \n        \n        =\n        \n          x\n          \n            t\n            −",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n            −\n            d\n            t\n          \n        \n        ,\n        \n          β\n          \n            t\n          \n        \n        =\n        β\n        (\n        t\n        )\n        d\n        t\n        ,\n        \n          z\n          \n            t\n          \n        \n        \n          \n            d\n            t\n          \n        \n        =\n        d\n        \n          W\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t-1",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle x_{t-1}=x_{t-dt},\\beta _{t}=\\beta (t)dt,z_{t}{\\sqrt {dt}}=dW_{t}}\n  \n of the backward equation\n\n  \n    \n      \n        \n          x\n          \n            t\n            −\n            1\n          \n        \n        =\n        \n          \n            \n              x\n              \n                t\n              \n            \n            \n              \n                α\n                \n                  t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                \n              \n            \n          \n        \n        −\n        \n          \n            \n              β\n              \n                t\n              \n            \n            \n              \n                σ\n                \n                  t\n                \n              \n              \n                \n                  \n                    α\n                    \n                      t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        +\n        \n          \n            \n              β\n              \n                t\n              \n            \n          \n        \n        \n          z\n          \n            t\n          \n        \n        ;\n        \n        \n          z",
        "source": "diffusion_model.txt"
    },
    {
        "text": ";\n        \n        \n          z\n          \n            t\n          \n        \n        ∼\n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        I\n        )\n      \n    \n    {\\displaystyle x_{t-1}={\\frac {x_{t}}{\\sqrt {\\alpha _{t}}}}-{\\frac {\\beta _{t}}{\\sigma _{t}{\\sqrt {\\alpha _{t}}}}}\\epsilon _{\\theta }(x_{t},t)+{\\sqrt {\\beta _{t}}}z_{t};\\quad z_{t}\\sim {\\mathcal {N}}(0,I)}\n  \n\ngives us precisely the same equation as score-based diffusion:",
        "source": "diffusion_model.txt"
    },
    {
        "text": "same equation as score-based diffusion:\n\n  \n    \n      \n        \n          x\n          \n            t\n            −\n            d\n            t\n          \n        \n        =\n        \n          x\n          \n            t\n          \n        \n        (\n        1\n        +\n        β\n        (\n        t\n        )\n        d\n        t\n        \n          /\n        \n        2\n        )\n        +\n        β\n        (\n        t\n        )\n        \n          ∇\n          \n            \n              x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "∇\n          \n            \n              x\n              \n                t\n              \n            \n          \n        \n        ln\n        ⁡\n        q\n        (\n        \n          x\n          \n            t\n          \n        \n        )\n        d\n        t\n        +\n        \n          \n            β\n            (\n            t\n            )\n          \n        \n        d\n        \n          W\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t-dt}=x_{t}(1+\\beta (t)d",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle x_{t-dt}=x_{t}(1+\\beta (t)dt/2)+\\beta (t)\\nabla _{x_{t}}\\ln q(x_{t})dt+{\\sqrt {\\beta (t)}}dW_{t}}\n  \nThus, at infinitesimal steps of DDPM, a denoising network performs score-based diffusion.\n\n\n== Main variants ==\n\n\n=== Noise schedule ===\n\nIn DDPM, the sequence of numbers \n  \n    \n      \n        0\n        =\n        \n          σ\n          \n            0\n          \n        \n        <\n        \n          σ\n          \n            1\n          \n        \n        <\n        ⋯",
        "source": "diffusion_model.txt"
    },
    {
        "text": "1\n          \n        \n        <\n        ⋯\n        <\n        \n          σ\n          \n            T\n          \n        \n        <\n        1\n      \n    \n    {\\displaystyle 0=\\sigma _{0}<\\sigma _{1}<\\cdots <\\sigma _{T}<1}\n  \n is called a (discrete time) noise schedule. In general, consider a strictly increasing monotonic function \n  \n    \n      \n        σ\n      \n    \n    {\\displaystyle \\sigma }\n  \n of type \n  \n    \n      \n        \n          R\n        \n        →\n        (\n        0\n        ,",
        "source": "diffusion_model.txt"
    },
    {
        "text": "→\n        (\n        0\n        ,\n        1\n        )\n      \n    \n    {\\displaystyle \\mathbb {R} \\to (0,1)}\n  \n, such as the sigmoid function. In that case, a noise schedule is a sequence of real numbers \n  \n    \n      \n        \n          λ\n          \n            1\n          \n        \n        <\n        \n          λ\n          \n            2\n          \n        \n        <\n        ⋯\n        <\n        \n          λ\n          \n            T\n          \n        \n      \n    \n    {\\displaystyle \\l",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle \\lambda _{1}<\\lambda _{2}<\\cdots <\\lambda _{T}}\n  \n. It then defines a sequence of noises \n  \n    \n      \n        \n          σ\n          \n            t\n          \n        \n        :=\n        σ\n        (\n        \n          λ\n          \n            t\n          \n        \n        )\n      \n    \n    {\\displaystyle \\sigma _{t}:=\\sigma (\\lambda _{t})}\n  \n, which then derives the other quantities \n  \n    \n      \n        \n          β\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "β\n          \n            t\n          \n        \n        =\n        1\n        −\n        \n          \n            \n              1\n              −\n              \n                σ\n                \n                  t\n                \n                \n                  2\n                \n              \n            \n            \n              1\n              −\n              \n                σ\n                \n                  t\n                  −\n                  1",
        "source": "diffusion_model.txt"
    },
    {
        "text": "−\n                  1\n                \n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\beta _{t}=1-{\\frac {1-\\sigma _{t}^{2}}{1-\\sigma _{t-1}^{2}}}}\n  \n.\nIn order to use arbitrary noise schedules, instead of training a noise prediction model \n  \n    \n      \n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n            t\n          \n        \n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\epsilon _{\\theta }(x_{t},t)}\n  \n, one trains \n  \n    \n      \n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        \n          σ\n          \n            t\n          \n        \n        )\n      \n    \n    {\\displaystyle \\epsilon _{\\theta }(x_{t},\\sigma _{t})}\n  \n.\nSimilarly, for the",
        "source": "diffusion_model.txt"
    },
    {
        "text": "eta }(x_{t},\\sigma _{t})}\n  \n.\nSimilarly, for the noise conditional score network, instead of training \n  \n    \n      \n        \n          f\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n      \n    \n    {\\displaystyle f_{\\theta }(x_{t},t)}\n  \n, one trains \n  \n    \n      \n        \n          f\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n        \n          x\n          \n            t\n          \n        \n        ,\n        \n          σ\n          \n            t\n          \n        \n        )\n      \n    \n    {\\displaystyle f_{\\theta }(x_{t},\\sigma _{t})}\n  \n.\n\n\n=== Denoising Diffusion Implicit Model (DDIM) ===\nThe original DDPM method for generating images is slow, since the forward diffusion process usually takes \n  \n    \n      \n        T\n        ∼\n        1000\n      \n    \n    {\\displaystyle T\\sim 1000}\n  \n to make the distribution",
        "source": "diffusion_model.txt"
    },
    {
        "text": "playstyle T\\sim 1000}\n  \n to make the distribution of \n  \n    \n      \n        \n          x\n          \n            T\n          \n        \n      \n    \n    {\\displaystyle x_{T}}\n  \n to appear close to gaussian. However this means the backward diffusion process also take 1000 steps. Unlike the forward diffusion process, which can skip steps as \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        \n          |\n        \n        \n          x\n          \n            0",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{t}|x_{0}}\n  \n is gaussian for all \n  \n    \n      \n        t\n        ≥\n        1\n      \n    \n    {\\displaystyle t\\geq 1}\n  \n, the backward diffusion process does not allow skipping steps. For example, to sample \n  \n    \n      \n        \n          x\n          \n            t\n            −\n            2\n          \n        \n        \n          |\n        \n        \n          x\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n            t\n            −\n            1\n          \n        \n        ∼\n        \n          \n            N\n          \n        \n        (\n        \n          μ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n            −\n            1\n          \n        \n        ,\n        t\n        −\n        1\n        )\n        ,\n        \n          Σ\n          \n            θ\n          \n        \n        (\n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n        \n          x\n          \n            t\n            −\n            1\n          \n        \n        ,\n        t\n        −\n        1\n        )\n        )\n      \n    \n    {\\displaystyle x_{t-2}|x_{t-1}\\sim {\\mathcal {N}}(\\mu _{\\theta }(x_{t-1},t-1),\\Sigma _{\\theta }(x_{t-1},t-1))}\n  \n requires the model to first sample \n  \n    \n      \n        \n          x\n          \n            t\n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle x_{t-1}}",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle x_{t-1}}\n  \n. Attempting to directly sample \n  \n    \n      \n        \n          x\n          \n            t\n            −\n            2\n          \n        \n        \n          |\n        \n        \n          x\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t-2}|x_{t}}\n  \n would require us to marginalize out \n  \n    \n      \n        \n          x\n          \n            t\n            −\n            1",
        "source": "diffusion_model.txt"
    },
    {
        "text": "1\n          \n        \n      \n    \n    {\\displaystyle x_{t-1}}\n  \n, which is generally intractable.\nDDIM is a method to take any model trained on DDPM loss, and use it to sample with some steps skipped, sacrificing an adjustable amount of quality. If we generate the Markovian chain case in DDPM to non-Markovian case, DDIM corresponds to the case that the reverse process has variance equals to 0. In other words, the reverse process (and also the forward process) is deterministic. When",
        "source": "diffusion_model.txt"
    },
    {
        "text": "also the forward process) is deterministic. When using fewer sampling steps, DDIM outperforms DDPM.\nIn detail, the DDIM sampling method is as follows. Start with the forward diffusion process \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    α\n                    ¯\n                  \n                \n              \n              \n                t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n              \n            \n          \n        \n        \n          x\n          \n            0\n          \n        \n        +\n        \n          σ\n          \n            t\n          \n        \n        ϵ\n      \n    \n    {\\displaystyle x_{t}={\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0}+\\sigma _{t}\\epsilon }\n  \n. Then, during the backward denoising process, given \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        ,",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        ,\n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n      \n    \n    {\\displaystyle x_{t},\\epsilon _{\\theta }(x_{t},t)}\n  \n, the original data is estimated as \n  \n    \n      \n        \n          x\n          \n            0\n          \n          ′\n        \n        =\n        \n          \n            \n              \n                x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n                \n                  t\n                \n              \n              −\n              \n                σ\n                \n                  t\n                \n              \n              \n                ϵ\n                \n                  θ\n                \n              \n              (\n              \n                x\n                \n                  t\n                \n              \n              ,\n              t\n              )",
        "source": "diffusion_model.txt"
    },
    {
        "text": ",\n              t\n              )\n            \n            \n              \n                \n                  \n                    \n                      α\n                      ¯\n                    \n                  \n                \n                \n                  t\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle x_{0}'={\\frac {x_{t}-\\sigma _{t}\\epsilon _{\\theta }(x_{t},t)}{\\sqrt {{\\bar {\\alpha }}_{t}}}}}\n  \nthen the backward diffus",
        "source": "diffusion_model.txt"
    },
    {
        "text": "bar {\\alpha }}_{t}}}}}\n  \nthen the backward diffusion process can jump to any step \n  \n    \n      \n        0\n        ≤\n        s\n        <\n        t\n      \n    \n    {\\displaystyle 0\\leq s<t}\n  \n, and the next denoised sample is \n  \n    \n      \n        \n          x\n          \n            s\n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    α\n                    ¯",
        "source": "diffusion_model.txt"
    },
    {
        "text": "s\n              \n            \n          \n        \n        \n          x\n          \n            0\n          \n          ′\n        \n        +\n        \n          \n            \n              σ\n              \n                s\n              \n              \n                2\n              \n            \n            −\n            (\n            \n              σ\n              \n                s\n              \n              ′",
        "source": "diffusion_model.txt"
    },
    {
        "text": "s\n              \n              ′\n            \n            \n              )\n              \n                2\n              \n            \n          \n        \n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        +\n        \n          σ\n          \n            s\n          \n          ′\n        \n        ϵ\n      \n    \n    {\\displaystyle x_{s}={\\sqrt {{\\bar {\\alpha }",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle x_{s}={\\sqrt {{\\bar {\\alpha }}_{s}}}x_{0}'+{\\sqrt {\\sigma _{s}^{2}-(\\sigma '_{s})^{2}}}\\epsilon _{\\theta }(x_{t},t)+\\sigma _{s}'\\epsilon }\n  \nwhere \n  \n    \n      \n        \n          σ\n          \n            s\n          \n          ′\n        \n      \n    \n    {\\displaystyle \\sigma _{s}'}\n  \n is an arbitrary real number within the range \n  \n    \n      \n        [\n        0\n        ,\n        \n          σ\n          \n            s\n          \n        \n        ]\n      \n    \n    {\\dis",
        "source": "diffusion_model.txt"
    },
    {
        "text": "]\n      \n    \n    {\\displaystyle [0,\\sigma _{s}]}\n  \n, and \n  \n    \n      \n        ϵ\n        ∼\n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        I\n        )\n      \n    \n    {\\displaystyle \\epsilon \\sim {\\mathcal {N}}(0,I)}\n  \n is a newly sampled gaussian noise. If all \n  \n    \n      \n        \n          σ\n          \n            s\n          \n          ′\n        \n        =\n        0\n      \n    \n    {\\displaystyle \\sigma _{s}'=0}",
        "source": "diffusion_model.txt"
    },
    {
        "text": "0\n      \n    \n    {\\displaystyle \\sigma _{s}'=0}\n  \n, then the backward process becomes deterministic, and this special case of DDIM is also called \"DDIM\". The original paper noted that when the process is deterministic, samples generated with only 20 steps are already very similar to ones generated with 1000 steps on the high-level.\nThe original paper recommended defining a single \"eta value\" \n  \n    \n      \n        η\n        ∈\n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {",
        "source": "diffusion_model.txt"
    },
    {
        "text": "0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle \\eta \\in [0,1]}\n  \n, such that \n  \n    \n      \n        \n          σ\n          \n            s\n          \n          ′\n        \n        =\n        η\n        \n          \n            \n              \n                σ\n                ~\n              \n            \n          \n          \n            s\n          \n        \n      \n    \n    {\\displaystyle \\sigma _{s}'=\\eta {\\tilde {\\sigma }}_{s}}\n  \n. When \n  \n    \n      \n        η\n        =",
        "source": "diffusion_model.txt"
    },
    {
        "text": ". When \n  \n    \n      \n        η\n        =\n        1\n      \n    \n    {\\displaystyle \\eta =1}\n  \n, this is the original DDPM. When \n  \n    \n      \n        η\n        =\n        0\n      \n    \n    {\\displaystyle \\eta =0}\n  \n, this is the fully deterministic DDIM. For intermediate values, the process interpolates between them.\nBy the equivalence, the DDIM algorithm also applies for score-based diffusion models.\n\n\n=== Latent diffusion model (LDM) ===\n\nSince the diffusion model is a general method fo",
        "source": "diffusion_model.txt"
    },
    {
        "text": "Since the diffusion model is a general method for modelling probability distributions, if one wants to model a distribution over images, one can first encode the images into a lower-dimensional space by an encoder, then use a diffusion model to model the distribution over encoded images. Then to generate an image, one can sample from the diffusion model, then use a decoder to decode it into an image.\nThe encoder-decoder pair is most often a variational autoencoder (VAE).\n\n\n=== Architectural im",
        "source": "diffusion_model.txt"
    },
    {
        "text": "iational autoencoder (VAE).\n\n\n=== Architectural improvements ===\n proposed various architectural improvements. For example, they proposed log-space interpolation during backward sampling. Instead of sampling from \n  \n    \n      \n        \n          x\n          \n            t\n            −\n            1\n          \n        \n        ∼\n        \n          \n            N\n          \n        \n        (\n        \n          \n            \n              \n                μ\n                ~",
        "source": "diffusion_model.txt"
    },
    {
        "text": "μ\n                ~\n              \n            \n          \n          \n            t\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            0\n          \n        \n        )\n        ,\n        \n          \n            \n              \n                σ\n                ~",
        "source": "diffusion_model.txt"
    },
    {
        "text": "σ\n                ~\n              \n            \n          \n          \n            t\n          \n          \n            2\n          \n        \n        I\n        )\n      \n    \n    {\\displaystyle x_{t-1}\\sim {\\mathcal {N}}({\\tilde {\\mu }}_{t}(x_{t},{\\tilde {x}}_{0}),{\\tilde {\\sigma }}_{t}^{2}I)}\n  \n, they recommended sampling from \n  \n    \n      \n        \n          \n            N\n          \n        \n        (\n        \n          \n            \n              \n                μ\n                ~",
        "source": "diffusion_model.txt"
    },
    {
        "text": "μ\n                ~\n              \n            \n          \n          \n            t\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            0\n          \n        \n        )\n        ,\n        (\n        \n          σ\n          \n            t\n          \n          \n            v",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n          \n            v\n          \n        \n        \n          \n            \n              \n                σ\n                ~\n              \n            \n          \n          \n            t\n          \n          \n            1\n            −\n            v\n          \n        \n        \n          )\n          \n            2\n          \n        \n        I\n        )\n      \n    \n    {\\displaystyle {\\mathcal {N}}({\\tilde {\\mu }}_{t}(x_{t},{\\tilde {x}}_{0}),(\\sigma _{t}^{v}{\\tilde {\\s",
        "source": "diffusion_model.txt"
    },
    {
        "text": "_{t},{\\tilde {x}}_{0}),(\\sigma _{t}^{v}{\\tilde {\\sigma }}_{t}^{1-v})^{2}I)}\n  \n for a learned parameter \n  \n    \n      \n        v\n      \n    \n    {\\displaystyle v}\n  \n.\nIn the v-prediction formalism, the noising formula \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    α\n                    ¯",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n              \n            \n          \n        \n        \n          x\n          \n            0\n          \n        \n        +\n        \n          \n            1\n            −\n            \n              \n                \n                  \n                    α\n                    ¯\n                  \n                \n              \n              \n                t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ϵ\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t}={\\sqrt {{\\bar {\\alpha }}_{t}}}x_{0}+{\\sqrt {1-{\\bar {\\alpha }}_{t}}}\\epsilon _{t}}\n  \n is reparameterised by an angle \n  \n    \n      \n        \n          ϕ\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle \\phi _{t}}\n  \n such that \n  \n    \n      \n        cos\n        ⁡\n        \n          ϕ\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ϕ\n          \n            t\n          \n        \n        =\n        \n          \n            \n              \n                \n                  \n                    α\n                    ¯\n                  \n                \n              \n              \n                t\n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\cos \\phi _{t}={\\sqrt {{\\bar {\\alpha }}_{t}}}}\n  \n and a \"velocity\" defined by \n  \n    \n      \n        cos\n        ⁡\n        \n          ϕ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "cos\n        ⁡\n        \n          ϕ\n          \n            t\n          \n        \n        \n          ϵ\n          \n            t\n          \n        \n        −\n        sin\n        ⁡\n        \n          ϕ\n          \n            t\n          \n        \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\cos \\phi _{t}\\epsilon _{t}-\\sin \\phi _{t}x_{0}}\n  \n. The network is trained to predict the velocity",
        "source": "diffusion_model.txt"
    },
    {
        "text": "v\n                ^\n              \n            \n          \n          \n            θ\n          \n        \n      \n    \n    {\\displaystyle {\\hat {v}}_{\\theta }}\n  \n, and denoising is by \n  \n    \n      \n        \n          x\n          \n            \n              ϕ\n              \n                t\n              \n            \n            −\n            δ\n          \n        \n        =\n        cos\n        ⁡\n        (\n        δ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "=\n        cos\n        ⁡\n        (\n        δ\n        )\n        \n        \n          x\n          \n            \n              ϕ\n              \n                t\n              \n            \n          \n        \n        −\n        sin\n        ⁡\n        (\n        δ\n        )\n        \n          \n            \n              \n                v\n                ^\n              \n            \n          \n          \n            θ\n          \n        \n        \n        (\n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n        \n          x\n          \n            \n              ϕ\n              \n                t\n              \n            \n          \n        \n        )\n      \n    \n    {\\displaystyle x_{\\phi _{t}-\\delta }=\\cos(\\delta )\\;x_{\\phi _{t}}-\\sin(\\delta ){\\hat {v}}_{\\theta }\\;(x_{\\phi _{t}})}\n  \n. This parameterization was found to improve performance, as the model can be trained to reach total noise (i.e. \n  \n    \n      \n        \n          ϕ\n          \n            t\n          \n        \n        =",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        =\n        \n          90\n          \n            ∘\n          \n        \n      \n    \n    {\\displaystyle \\phi _{t}=90^{\\circ }}\n  \n) and then reverse it, whereas the standard parameterization never reaches total noise since \n  \n    \n      \n        \n          \n            \n              \n                \n                  \n                    α\n                    ¯\n                  \n                \n              \n              \n                t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n              \n            \n          \n        \n        >\n        0\n      \n    \n    {\\displaystyle {\\sqrt {{\\bar {\\alpha }}_{t}}}>0}\n  \n is always true.\n\n\n=== Classifier guidance ===\nClassifier guidance was proposed in 2021 to improve class-conditional generation by using a classifier. The original publication used CLIP text encoders to improve text-conditional image generation.\nSuppose we wish to sample not from the entire distribution of images, but",
        "source": "diffusion_model.txt"
    },
    {
        "text": "e not from the entire distribution of images, but conditional on the image description. We don't want to sample a generic image, but an image that fits the description \"black cat with red eyes\". Generally, we want to sample from the distribution \n  \n    \n      \n        p\n        (\n        x\n        \n          |\n        \n        y\n        )\n      \n    \n    {\\displaystyle p(x|y)}\n  \n, where \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n ranges over images, and",
        "source": "diffusion_model.txt"
    },
    {
        "text": "}\n  \n ranges over images, and \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n ranges over classes of images (a description \"black cat with red eyes\" is just a very detailed class, and a class \"cat\" is just a very vague description).\nTaking the perspective of the noisy channel model, we can understand the process as follows: To generate an image \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n conditional on description \n  \n    \n      \n        y\n      \n    \n    {\\di",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ion \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n, we imagine that the requester really had in mind an image \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n, but the image is passed through a noisy channel and came out garbled, as \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n. Image generation is then nothing but inferring which \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n the requester had in mind.\nIn other words, conditiona",
        "source": "diffusion_model.txt"
    },
    {
        "text": "requester had in mind.\nIn other words, conditional image generation is simply \"translating from a textual language into a pictorial language\". Then, as in noisy-channel model, we use Bayes theorem to get\n\n  \n    \n      \n        p\n        (\n        x\n        \n          |\n        \n        y\n        )\n        ∝\n        p\n        (\n        y\n        \n          |\n        \n        x\n        )\n        p\n        (\n        x\n        )\n      \n    \n    {\\displaystyle p(x|y)\\propto p(y|x)p(x)}\n  \n\nin other",
        "source": "diffusion_model.txt"
    },
    {
        "text": "isplaystyle p(x|y)\\propto p(y|x)p(x)}\n  \n\nin other words, if we have a good model of the space of all images, and a good image-to-class translator, we get a class-to-image translator \"for free\". In the equation for backward diffusion, the score \n  \n    \n      \n        ∇\n        ln\n        ⁡\n        p\n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\nabla \\ln p(x)}\n  \n can be replaced by\n\n  \n    \n      \n        \n          ∇\n          \n            x\n          \n        \n        ln",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n        \n        ln\n        ⁡\n        p\n        (\n        x\n        \n          |\n        \n        y\n        )\n        =\n        \n          \n            \n              \n                \n                  ∇\n                  \n                    x\n                  \n                \n                ln\n                ⁡\n                p\n                (\n                x\n                )\n              \n              ⏟\n            \n          \n          \n            score",
        "source": "diffusion_model.txt"
    },
    {
        "text": "score\n          \n        \n        +\n        \n          \n            \n              \n                \n                  ∇\n                  \n                    x\n                  \n                \n                ln\n                ⁡\n                p\n                (\n                y\n                \n                  |\n                \n                x\n                )\n              \n              ⏟",
        "source": "diffusion_model.txt"
    },
    {
        "text": "⏟\n            \n          \n          \n            classifier guidance\n          \n        \n      \n    \n    {\\displaystyle \\nabla _{x}\\ln p(x|y)=\\underbrace {\\nabla _{x}\\ln p(x)} _{\\text{score}}+\\underbrace {\\nabla _{x}\\ln p(y|x)} _{\\text{classifier guidance}}}\n  \n\nwhere \n  \n    \n      \n        \n          ∇\n          \n            x\n          \n        \n        ln\n        ⁡\n        p\n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\nabla _{x}\\ln p(x)}\n  \n is the score function, traine",
        "source": "diffusion_model.txt"
    },
    {
        "text": "la _{x}\\ln p(x)}\n  \n is the score function, trained as previously described, and \n  \n    \n      \n        \n          ∇\n          \n            x\n          \n        \n        ln\n        ⁡\n        p\n        (\n        y\n        \n          |\n        \n        x\n        )\n      \n    \n    {\\displaystyle \\nabla _{x}\\ln p(y|x)}\n  \n is found by using a differentiable image classifier.\nDuring the diffusion process, we need to condition on the time, giving\n  \n    \n      \n        \n          ∇",
        "source": "diffusion_model.txt"
    },
    {
        "text": "∇\n          \n            \n              x\n              \n                t\n              \n            \n          \n        \n        ln\n        ⁡\n        p\n        (\n        \n          x\n          \n            t\n          \n        \n        \n          |\n        \n        y\n        ,\n        t\n        )\n        =\n        \n          ∇\n          \n            \n              x\n              \n                t\n              \n            \n          \n        \n        ln",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ln\n        ⁡\n        p\n        (\n        y\n        \n          |\n        \n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        +\n        \n          ∇\n          \n            \n              x\n              \n                t\n              \n            \n          \n        \n        ln\n        ⁡\n        p\n        (\n        \n          x\n          \n            t\n          \n        \n        \n          |",
        "source": "diffusion_model.txt"
    },
    {
        "text": "|\n        \n        t\n        )\n      \n    \n    {\\displaystyle \\nabla _{x_{t}}\\ln p(x_{t}|y,t)=\\nabla _{x_{t}}\\ln p(y|x_{t},t)+\\nabla _{x_{t}}\\ln p(x_{t}|t)}\n  \nAlthough, usually the classifier model does not depend on time, in which case \n  \n    \n      \n        p\n        (\n        y\n        \n          |\n        \n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        =\n        p\n        (\n        y",
        "source": "diffusion_model.txt"
    },
    {
        "text": "=\n        p\n        (\n        y\n        \n          |\n        \n        \n          x\n          \n            t\n          \n        \n        )\n      \n    \n    {\\displaystyle p(y|x_{t},t)=p(y|x_{t})}\n  \n.\nClassifier guidance is defined for the gradient of score function, thus for score-based diffusion network, but as previously noted, score-based diffusion models are equivalent to denoising models by \n  \n    \n      \n        \n          ϵ\n          \n            θ\n          \n        \n        (",
        "source": "diffusion_model.txt"
    },
    {
        "text": "θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        =\n        −\n        \n          σ\n          \n            t\n          \n        \n        \n          ∇\n          \n            \n              x\n              \n                t\n              \n            \n          \n        \n        ln\n        ⁡\n        p\n        (\n        \n          x\n          \n            t\n          \n        \n        \n          |",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        \n          |\n        \n        t\n        )\n      \n    \n    {\\displaystyle \\epsilon _{\\theta }(x_{t},t)=-\\sigma _{t}\\nabla _{x_{t}}\\ln p(x_{t}|t)}\n  \n, and similarly, \n  \n    \n      \n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        y\n        ,\n        t\n        )\n        =\n        −\n        \n          σ\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        \n          ∇\n          \n            \n              x\n              \n                t\n              \n            \n          \n        \n        ln\n        ⁡\n        p\n        (\n        \n          x\n          \n            t\n          \n        \n        \n          |\n        \n        y\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\epsilon _{\\theta }(x_{t},y,t)=-\\sigma _{t}\\nabla _{x_{t}}\\ln p(x_{t}|y,t)}\n  \n. Therefore, classifier guid",
        "source": "diffusion_model.txt"
    },
    {
        "text": "}\\ln p(x_{t}|y,t)}\n  \n. Therefore, classifier guidance works for denoising diffusion as well, using the modified noise prediction:\n  \n    \n      \n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        y\n        ,\n        t\n        )\n        =\n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        ,\n        t\n        )\n        −\n        \n          \n            \n              \n                \n                  σ\n                  \n                    t\n                  \n                \n                \n                  ∇\n                  \n                    \n                      x\n                      \n                        t\n                      \n                    \n                  \n                \n                ln",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ln\n                ⁡\n                p\n                (\n                y\n                \n                  |\n                \n                \n                  x\n                  \n                    t\n                  \n                \n                ,\n                t\n                )\n              \n              ⏟\n            \n          \n          \n            classifier guidance\n          \n        \n      \n    \n    {\\displaystyle \\epsilon _{\\thet",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle \\epsilon _{\\theta }(x_{t},y,t)=\\epsilon _{\\theta }(x_{t},t)-\\underbrace {\\sigma _{t}\\nabla _{x_{t}}\\ln p(y|x_{t},t)} _{\\text{classifier guidance}}}\n  \n\n\n==== With temperature ====\nThe classifier-guided diffusion model samples from \n  \n    \n      \n        p\n        (\n        x\n        \n          |\n        \n        y\n        )\n      \n    \n    {\\displaystyle p(x|y)}\n  \n, which is concentrated around the maximum a posteriori estimate \n  \n    \n      \n        arg",
        "source": "diffusion_model.txt"
    },
    {
        "text": "steriori estimate \n  \n    \n      \n        arg\n        ⁡\n        \n          max\n          \n            x\n          \n        \n        p\n        (\n        x\n        \n          |\n        \n        y\n        )\n      \n    \n    {\\displaystyle \\arg \\max _{x}p(x|y)}\n  \n. If we want to force the model to move towards the maximum likelihood estimate \n  \n    \n      \n        arg\n        ⁡\n        \n          max\n          \n            x\n          \n        \n        p\n        (\n        y\n        \n          |",
        "source": "diffusion_model.txt"
    },
    {
        "text": "p\n        (\n        y\n        \n          |\n        \n        x\n        )\n      \n    \n    {\\displaystyle \\arg \\max _{x}p(y|x)}\n  \n, we can use \n\n  \n    \n      \n        \n          p\n          \n            γ\n          \n        \n        (\n        x\n        \n          |\n        \n        y\n        )\n        ∝\n        p\n        (\n        y\n        \n          |\n        \n        x\n        \n          )\n          \n            γ\n          \n        \n        p\n        (\n        x\n        )",
        "source": "diffusion_model.txt"
    },
    {
        "text": "p\n        (\n        x\n        )\n      \n    \n    {\\displaystyle p_{\\gamma }(x|y)\\propto p(y|x)^{\\gamma }p(x)}\n  \n\nwhere \n  \n    \n      \n        γ\n        >\n        0\n      \n    \n    {\\displaystyle \\gamma >0}\n  \n is interpretable as inverse temperature. In the context of diffusion models, it is usually called the guidance scale. A high \n  \n    \n      \n        γ\n      \n    \n    {\\displaystyle \\gamma }\n  \n would force the model to sample from a distribution concentrated around",
        "source": "diffusion_model.txt"
    },
    {
        "text": "tribution concentrated around \n  \n    \n      \n        arg\n        ⁡\n        \n          max\n          \n            x\n          \n        \n        p\n        (\n        y\n        \n          |\n        \n        x\n        )\n      \n    \n    {\\displaystyle \\arg \\max _{x}p(y|x)}\n  \n. This sometimes improves quality of generated images.\nThis gives a modification to the previous equation:\n  \n    \n      \n        \n          ∇\n          \n            x\n          \n        \n        ln\n        ⁡",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ln\n        ⁡\n        \n          p\n          \n            β\n          \n        \n        (\n        x\n        \n          |\n        \n        y\n        )\n        =\n        \n          ∇\n          \n            x\n          \n        \n        ln\n        ⁡\n        p\n        (\n        x\n        )\n        +\n        γ\n        \n          ∇\n          \n            x\n          \n        \n        ln\n        ⁡\n        p\n        (\n        y\n        \n          |\n        \n        x\n        )",
        "source": "diffusion_model.txt"
    },
    {
        "text": "|\n        \n        x\n        )\n      \n    \n    {\\displaystyle \\nabla _{x}\\ln p_{\\beta }(x|y)=\\nabla _{x}\\ln p(x)+\\gamma \\nabla _{x}\\ln p(y|x)}\n  \nFor denoising models, it corresponds to\n  \n    \n      \n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        y\n        ,\n        t\n        )\n        =\n        \n          ϵ\n          \n            θ\n          \n        \n        (",
        "source": "diffusion_model.txt"
    },
    {
        "text": "θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        −\n        γ\n        \n          σ\n          \n            t\n          \n        \n        \n          ∇\n          \n            \n              x\n              \n                t\n              \n            \n          \n        \n        ln\n        ⁡\n        p\n        (\n        y\n        \n          |\n        \n        \n          x\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n            t\n          \n        \n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\epsilon _{\\theta }(x_{t},y,t)=\\epsilon _{\\theta }(x_{t},t)-\\gamma \\sigma _{t}\\nabla _{x_{t}}\\ln p(y|x_{t},t)}\n  \n\n\n=== Classifier-free guidance (CFG) ===\nIf we do not have a classifier \n  \n    \n      \n        p\n        (\n        y\n        \n          |\n        \n        x\n        )\n      \n    \n    {\\displaystyle p(y|x)}\n  \n, we could still extract one out of the image model its",
        "source": "diffusion_model.txt"
    },
    {
        "text": "could still extract one out of the image model itself:\n\n  \n    \n      \n        \n          ∇\n          \n            x\n          \n        \n        ln\n        ⁡\n        \n          p\n          \n            γ\n          \n        \n        (\n        x\n        \n          |\n        \n        y\n        )\n        =\n        (\n        1\n        −\n        γ\n        )\n        \n          ∇\n          \n            x\n          \n        \n        ln\n        ⁡\n        p\n        (\n        x\n        )\n        +\n        γ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n        x\n        )\n        +\n        γ\n        \n          ∇\n          \n            x\n          \n        \n        ln\n        ⁡\n        p\n        (\n        x\n        \n          |\n        \n        y\n        )\n      \n    \n    {\\displaystyle \\nabla _{x}\\ln p_{\\gamma }(x|y)=(1-\\gamma )\\nabla _{x}\\ln p(x)+\\gamma \\nabla _{x}\\ln p(x|y)}\n  \n\nSuch a model is usually trained by presenting it with both \n  \n    \n      \n        (\n        x\n        ,\n        y\n        )\n      \n    \n    {\\displaystyl",
        "source": "diffusion_model.txt"
    },
    {
        "text": "y\n        )\n      \n    \n    {\\displaystyle (x,y)}\n  \n and \n  \n    \n      \n        (\n        x\n        ,\n        \n          \n            N\n            o\n            n\n            e\n          \n        \n        )\n      \n    \n    {\\displaystyle (x,{\\rm {None}})}\n  \n, allowing it to model both \n  \n    \n      \n        \n          ∇\n          \n            x\n          \n        \n        ln\n        ⁡\n        p\n        (\n        x\n        \n          |\n        \n        y\n        )\n      \n    \n    {\\",
        "source": "diffusion_model.txt"
    },
    {
        "text": "|\n        \n        y\n        )\n      \n    \n    {\\displaystyle \\nabla _{x}\\ln p(x|y)}\n  \n and \n  \n    \n      \n        \n          ∇\n          \n            x\n          \n        \n        ln\n        ⁡\n        p\n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\nabla _{x}\\ln p(x)}\n  \n.\nNote that for CFG, the diffusion model cannot be merely a generative model of the entire data distribution \n  \n    \n      \n        \n          ∇\n          \n            x\n          \n        \n        ln",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n        \n        ln\n        ⁡\n        p\n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\nabla _{x}\\ln p(x)}\n  \n. It must be a conditional generative model \n  \n    \n      \n        \n          ∇\n          \n            x\n          \n        \n        ln\n        ⁡\n        p\n        (\n        x\n        \n          |\n        \n        y\n        )\n      \n    \n    {\\displaystyle \\nabla _{x}\\ln p(x|y)}\n  \n. For example, in stable diffusion, the diffusion backbone takes as",
        "source": "diffusion_model.txt"
    },
    {
        "text": "stable diffusion, the diffusion backbone takes as input both a noisy model \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t}}\n  \n, a time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n, and a conditioning vector \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n (such as a vector encoding a text prompt), and produces a noise prediction \n  \n    \n      \n        \n          ϵ\n          \n            θ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        y\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\epsilon _{\\theta }(x_{t},y,t)}\n  \n.\nFor denoising models, it corresponds to\n  \n    \n      \n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        y\n        ,\n        t",
        "source": "diffusion_model.txt"
    },
    {
        "text": ",\n        y\n        ,\n        t\n        ,\n        γ\n        )\n        =\n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        +\n        γ\n        (\n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        y\n        ,\n        t\n        )\n        −",
        "source": "diffusion_model.txt"
    },
    {
        "text": "y\n        ,\n        t\n        )\n        −\n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n        )\n      \n    \n    {\\displaystyle \\epsilon _{\\theta }(x_{t},y,t,\\gamma )=\\epsilon _{\\theta }(x_{t},t)+\\gamma (\\epsilon _{\\theta }(x_{t},y,t)-\\epsilon _{\\theta }(x_{t},t))}\n  \nAs sampled by DDIM, the algorithm can be written as",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ϵ\n                  \n                    uncond\n                  \n                \n              \n              \n                \n                ←\n                \n                  ϵ\n                  \n                    θ\n                  \n                \n                (\n                \n                  x\n                  \n                    t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                  \n                \n                ,\n                t\n                )\n              \n            \n            \n              \n                \n                  ϵ\n                  \n                    cond\n                  \n                \n              \n              \n                \n                ←\n                \n                  ϵ\n                  \n                    θ\n                  \n                \n                (",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n                \n                  x\n                  \n                    t\n                  \n                \n                ,\n                t\n                ,\n                c\n                )\n              \n            \n            \n              \n                \n                  ϵ\n                  \n                    CFG\n                  \n                \n              \n              \n                \n                ←\n                \n                  ϵ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "←\n                \n                  ϵ\n                  \n                    uncond\n                  \n                \n                +\n                γ\n                (\n                \n                  ϵ\n                  \n                    cond\n                  \n                \n                −\n                \n                  ϵ\n                  \n                    uncond\n                  \n                \n                )",
        "source": "diffusion_model.txt"
    },
    {
        "text": ")\n              \n            \n            \n              \n                \n                  x\n                  \n                    0\n                  \n                \n              \n              \n                \n                ←\n                (\n                \n                  x\n                  \n                    t\n                  \n                \n                −\n                \n                  σ\n                  \n                    t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                  \n                \n                \n                  ϵ\n                  \n                    CFG\n                  \n                \n                )\n                \n                  /\n                \n                \n                  \n                    1\n                    −\n                    \n                      σ\n                      \n                        t\n                      \n                      \n                        2",
        "source": "diffusion_model.txt"
    },
    {
        "text": "2\n                      \n                    \n                  \n                \n              \n            \n            \n              \n                \n                  x\n                  \n                    s\n                  \n                \n              \n              \n                \n                ←\n                \n                  \n                    1\n                    −\n                    \n                      σ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "σ\n                      \n                        s\n                      \n                      \n                        2\n                      \n                    \n                  \n                \n                \n                  x\n                  \n                    0\n                  \n                \n                +\n                \n                  \n                    \n                      σ\n                      \n                        s",
        "source": "diffusion_model.txt"
    },
    {
        "text": "s\n                      \n                      \n                        2\n                      \n                    \n                    −\n                    (\n                    \n                      σ\n                      \n                        s\n                      \n                      ′\n                    \n                    \n                      )\n                      \n                        2",
        "source": "diffusion_model.txt"
    },
    {
        "text": "2\n                      \n                    \n                  \n                \n                \n                  ϵ\n                  \n                    uncond\n                  \n                \n                +\n                \n                  σ\n                  \n                    s\n                  \n                  ′\n                \n                ϵ\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\epsilon _{\\text{uncond}}&\\lef",
        "source": "diffusion_model.txt"
    },
    {
        "text": "yle {\\begin{aligned}\\epsilon _{\\text{uncond}}&\\leftarrow \\epsilon _{\\theta }(x_{t},t)\\\\\\epsilon _{\\text{cond}}&\\leftarrow \\epsilon _{\\theta }(x_{t},t,c)\\\\\\epsilon _{\\text{CFG}}&\\leftarrow \\epsilon _{\\text{uncond}}+\\gamma (\\epsilon _{\\text{cond}}-\\epsilon _{\\text{uncond}})\\\\x_{0}&\\leftarrow (x_{t}-\\sigma _{t}\\epsilon _{\\text{CFG}})/{\\sqrt {1-\\sigma _{t}^{2}}}\\\\x_{s}&\\leftarrow {\\sqrt {1-\\sigma _{s}^{2}}}x_{0}+{\\sqrt {\\sigma _{s}^{2}-(\\sigma _{s}')^{2}}}\\epsilon _{\\text{uncond}}+\\sigma _{s}'\\epsil",
        "source": "diffusion_model.txt"
    },
    {
        "text": "^{2}}}\\epsilon _{\\text{uncond}}+\\sigma _{s}'\\epsilon \\\\\\end{aligned}}}\n  \nA similar technique applies to language model sampling. Also, if the unconditional generation \n  \n    \n      \n        \n          ϵ\n          \n            uncond\n          \n        \n        ←\n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\epsilon _{\\text{uncond}}\\leftar",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle \\epsilon _{\\text{uncond}}\\leftarrow \\epsilon _{\\theta }(x_{t},t)}\n  \n is replaced by \n  \n    \n      \n        \n          ϵ\n          \n            neg cond\n          \n        \n        ←\n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        ,\n        \n          c\n          ′\n        \n        )\n      \n    \n    {\\displaystyle \\epsilon _{\\text{neg cond}}\\leftarrow \\epsi",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ystyle \\epsilon _{\\text{neg cond}}\\leftarrow \\epsilon _{\\theta }(x_{t},t,c')}\n  \n, then it results in negative prompting, which pushes the generation away from \n  \n    \n      \n        \n          c\n          ′\n        \n      \n    \n    {\\displaystyle c'}\n  \n condition.\n\n\n=== Samplers ===\nGiven a diffusion model, one may regard it either as a continuous process, and sample from it by integrating a SDE, or one can regard it as a discrete process, and sample from it by iterating the discrete steps. T",
        "source": "diffusion_model.txt"
    },
    {
        "text": "sample from it by iterating the discrete steps. The choice of the \"noise schedule\" \n  \n    \n      \n        \n          β\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle \\beta _{t}}\n  \n can also affect the quality of samples. A noise schedule is a function that sends a natural number to a noise level: \n  \n    \n      \n        t\n        ↦\n        \n          β\n          \n            t\n          \n        \n        ,\n        \n        t\n        ∈\n        {\n        1\n        ,",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n        ∈\n        {\n        1\n        ,\n        2\n        ,\n        …\n        }\n        ,\n        β\n        ∈\n        (\n        0\n        ,\n        1\n        )\n      \n    \n    {\\displaystyle t\\mapsto \\beta _{t},\\quad t\\in \\{1,2,\\dots \\},\\beta \\in (0,1)}\n  \nA noise schedule is more often specified by a map \n  \n    \n      \n        t\n        ↦\n        \n          σ\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle t\\mapsto \\sigma _{t}}\n  \n. The two definitions ar",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\\mapsto \\sigma _{t}}\n  \n. The two definitions are equivalent, since \n  \n    \n      \n        \n          β\n          \n            t\n          \n        \n        =\n        1\n        −\n        \n          \n            \n              1\n              −\n              \n                σ\n                \n                  t\n                \n                \n                  2\n                \n              \n            \n            \n              1\n              −\n              \n                σ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "−\n              \n                σ\n                \n                  t\n                  −\n                  1\n                \n                \n                  2\n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle \\beta _{t}=1-{\\frac {1-\\sigma _{t}^{2}}{1-\\sigma _{t-1}^{2}}}}\n  \n.\nIn the DDPM perspective, one can use the DDPM itself (with noise), or DDIM (with adjustable amount of noise). The case where one adds noise is sometimes called a",
        "source": "diffusion_model.txt"
    },
    {
        "text": "he case where one adds noise is sometimes called ancestral sampling. One can interpolate between noise and no noise. The amount of noise is denoted \n  \n    \n      \n        η\n      \n    \n    {\\displaystyle \\eta }\n  \n (\"eta value\") in the DDIM paper, with \n  \n    \n      \n        η\n        =\n        0\n      \n    \n    {\\displaystyle \\eta =0}\n  \n denoting no noise (as in deterministic DDIM), and \n  \n    \n      \n        η\n        =\n        1\n      \n    \n    {\\displaystyle \\eta =1}\n  \n denoting full no",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle \\eta =1}\n  \n denoting full noise (as in DDPM).\nIn the perspective of SDE, one can use any of the numerical integration methods, such as Euler–Maruyama method, Heun's method, linear multistep methods, etc. Just as in the discrete case, one can add an adjustable amount of noise during the integration.\nA survey and comparison of samplers in the context of image generation is in.\n\n\n=== Other examples ===\nNotable variants include Poisson flow generative model, consistency model,",
        "source": "diffusion_model.txt"
    },
    {
        "text": "Poisson flow generative model, consistency model, critically-damped Langevin diffusion, GenPhys, cold diffusion, discrete diffusion, etc.\n\n\n== Flow-based diffusion model ==\nAbstractly speaking, the idea of diffusion model is to take an unknown probability distribution (the distribution of natural-looking images), then progressively convert it to a known probability distribution (standard gaussian distribution), by building an absolutely continuous probability path connecting them. The probabilit",
        "source": "diffusion_model.txt"
    },
    {
        "text": "s probability path connecting them. The probability path is in fact defined implicitly by the score function \n  \n    \n      \n        ∇\n        ln\n        ⁡\n        \n          p\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle \\nabla \\ln p_{t}}\n  \n.\nIn denoising diffusion models, the forward process adds noise, and the backward process removes noise. Both the forward and backward processes are SDEs, though the forward process is integrable in closed-form, so it can be d",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ocess is integrable in closed-form, so it can be done at no computational cost. The backward process is not integrable in closed-form, so it must be integrated step-by-step by standard SDE solvers, which can be very expensive. The probability path in diffusions model is defined through an Itô process and one can retrieve the deterministic process by using the Probability ODE flow formulation.\nIn flow-based diffusion models, the forward process is a deterministic flow along a time-dependent vecto",
        "source": "diffusion_model.txt"
    },
    {
        "text": "a deterministic flow along a time-dependent vector field, and the backward process is also a deterministic flow along the same vector field, but going backwards. Both processes are solutions to ODEs. If the vector field is well-behaved, the ODE will also be well-behaved.\nGiven two distributions \n  \n    \n      \n        \n          π\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\pi _{0}}\n  \n and \n  \n    \n      \n        \n          π\n          \n            1",
        "source": "diffusion_model.txt"
    },
    {
        "text": "π\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\pi _{1}}\n  \n, a flow-based model is a time-dependent velocity field \n  \n    \n      \n        \n          v\n          \n            t\n          \n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle v_{t}(x)}\n  \n in \n  \n    \n      \n        [\n        0\n        ,\n        1\n        ]\n        ×\n        \n          \n            R\n          \n          \n            d",
        "source": "diffusion_model.txt"
    },
    {
        "text": "d\n          \n        \n      \n    \n    {\\displaystyle [0,1]\\times \\mathbb {R} ^{d}}\n  \n, such that if we start by sampling a point \n  \n    \n      \n        x\n        ∼\n        \n          π\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x\\sim \\pi _{0}}\n  \n, and let it move according to the velocity field:\n\n  \n    \n      \n        \n          \n            d\n            \n              d\n              t\n            \n          \n        \n        \n          ϕ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ϕ\n          \n            t\n          \n        \n        (\n        x\n        )\n        =\n        \n          v\n          \n            t\n          \n        \n        (\n        \n          ϕ\n          \n            t\n          \n        \n        (\n        x\n        )\n        )\n        \n        t\n        ∈\n        [\n        0\n        ,\n        1\n        ]\n        ,\n        \n        \n          starting from \n        \n        \n          ϕ\n          \n            0",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ϕ\n          \n            0\n          \n        \n        (\n        x\n        )\n        =\n        x\n      \n    \n    {\\displaystyle {\\frac {d}{dt}}\\phi _{t}(x)=v_{t}(\\phi _{t}(x))\\quad t\\in [0,1],\\quad {\\text{starting from }}\\phi _{0}(x)=x}\n  \n\nwe end up with a point \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        ∼\n        \n          π\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle x_{1}\\sim \\pi _{1}}\n  \n.",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle x_{1}\\sim \\pi _{1}}\n  \n. The solution \n  \n    \n      \n        \n          ϕ\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle \\phi _{t}}\n  \n of the above ODE define a probability path \n  \n    \n      \n        \n          p\n          \n            t\n          \n        \n        =\n        [\n        \n          ϕ\n          \n            t\n          \n        \n        \n          ]\n          \n            #\n          \n        \n        \n          π",
        "source": "diffusion_model.txt"
    },
    {
        "text": "π\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle p_{t}=[\\phi _{t}]_{\\#}\\pi _{0}}\n  \n by the pushforward measure operator. In particular, \n  \n    \n      \n        [\n        \n          ϕ\n          \n            1\n          \n        \n        \n          ]\n          \n            #\n          \n        \n        \n          π\n          \n            0\n          \n        \n        =\n        \n          π\n          \n            1",
        "source": "diffusion_model.txt"
    },
    {
        "text": "π\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle [\\phi _{1}]_{\\#}\\pi _{0}=\\pi _{1}}\n  \n.\nThe probability path and the velocity field also satisfy the continuity equation, in the sense of probability distribution:\n\n  \n    \n      \n        \n          ∂\n          \n            t\n          \n        \n        \n          p\n          \n            t\n          \n        \n        +\n        ∇\n        ⋅\n        (\n        \n          v\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "v\n          \n            t\n          \n        \n        \n          p\n          \n            t\n          \n        \n        )\n        =\n        0\n      \n    \n    {\\displaystyle \\partial _{t}p_{t}+\\nabla \\cdot (v_{t}p_{t})=0}\n  \n\nTo construct a probability path, we start by construct a conditional probability path \n  \n    \n      \n        \n          p\n          \n            t\n          \n        \n        (\n        x\n        |\n        z\n        )\n      \n    \n    {\\displaystyle p_{t}(x\\vert z)}",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle p_{t}(x\\vert z)}\n  \n and the corresponding conditional velocity field \n  \n    \n      \n        \n          v\n          \n            t\n          \n        \n        (\n        x\n        |\n        z\n        )\n      \n    \n    {\\displaystyle v_{t}(x\\vert z)}\n  \n on some conditional distribution \n  \n    \n      \n        q\n        (\n        z\n        )\n      \n    \n    {\\displaystyle q(z)}\n  \n. A natural choice is the Gaussian conditional probability path:",
        "source": "diffusion_model.txt"
    },
    {
        "text": "onditional probability path:\n\n  \n    \n      \n        \n          p\n          \n            t\n          \n        \n        (\n        x\n        |\n        z\n        )\n        =\n        \n          \n            N\n          \n        \n        \n          (\n          \n            \n              m\n              \n                t\n              \n            \n            (\n            z\n            )\n            ,\n            \n              ζ\n              \n                t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n              \n              \n                2\n              \n            \n            I\n          \n          )\n        \n      \n    \n    {\\displaystyle p_{t}(x\\vert z)={\\mathcal {N}}\\left(m_{t}(z),\\zeta _{t}^{2}I\\right)}\n  \n\nThe conditional velocity field which corresponds to the geodesic path between conditional Gaussian path is \n\n  \n    \n      \n        \n          v\n          \n            t\n          \n        \n        (\n        x\n        |\n        z\n        )\n        =",
        "source": "diffusion_model.txt"
    },
    {
        "text": "|\n        z\n        )\n        =\n        \n          \n            \n              ζ\n              \n                t\n              \n              ′\n            \n            \n              ζ\n              \n                t\n              \n            \n          \n        \n        (\n        x\n        −\n        \n          m\n          \n            t\n          \n        \n        (\n        z\n        )\n        )\n        +\n        \n          m\n          \n            t\n          \n          ′",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n          ′\n        \n        (\n        z\n        )\n      \n    \n    {\\displaystyle v_{t}(x\\vert z)={\\frac {\\zeta _{t}'}{\\zeta _{t}}}(x-m_{t}(z))+m_{t}'(z)}\n  \n\nThe probability path and velocity field are then computed by marginalizing\n\n  \n    \n      \n        \n          p\n          \n            t\n          \n        \n        (\n        x\n        )\n        =\n        ∫\n        \n          p\n          \n            t\n          \n        \n        (\n        x\n        |",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n        x\n        |\n        z\n        )\n        q\n        (\n        z\n        )\n        d\n        z\n        \n        \n           and \n        \n        \n        \n          v\n          \n            t\n          \n        \n        (\n        x\n        )\n        =\n        \n          \n            E\n          \n          \n            q\n            (\n            z\n            )\n          \n        \n        \n          [",
        "source": "diffusion_model.txt"
    },
    {
        "text": "v\n                  \n                    t\n                  \n                \n                (\n                x\n                |\n                z\n                )\n                \n                  p\n                  \n                    t\n                  \n                \n                (\n                x\n                |\n                z\n                )\n              \n              \n                \n                  p",
        "source": "diffusion_model.txt"
    },
    {
        "text": "p\n                  \n                    t\n                  \n                \n                (\n                x\n                )\n              \n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle p_{t}(x)=\\int p_{t}(x\\vert z)q(z)dz\\qquad {\\text{ and }}\\qquad v_{t}(x)=\\mathbb {E} _{q(z)}\\left[{\\frac {v_{t}(x\\vert z)p_{t}(x\\vert z)}{p_{t}(x)}}\\right]}\n  \n\n\n=== Optimal transport flow ===\nThe idea of optimal transport flow  is",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t flow ===\nThe idea of optimal transport flow  is to construct a probability path minimizing the Wasserstein metric. The distribution on which we condition is an approximation of the optimal transport plan between \n  \n    \n      \n        \n          π\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\pi _{0}}\n  \n and \n  \n    \n      \n        \n          π\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\pi _{1}}\n  \n: \n  \n    \n      \n        z",
        "source": "diffusion_model.txt"
    },
    {
        "text": "aystyle \\pi _{1}}\n  \n: \n  \n    \n      \n        z\n        =\n        (\n        \n          x\n          \n            0\n          \n        \n        ,\n        \n          x\n          \n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle z=(x_{0},x_{1})}\n  \n and \n  \n    \n      \n        q\n        (\n        z\n        )\n        =\n        Γ\n        (\n        \n          π\n          \n            0\n          \n        \n        ,\n        \n          π\n          \n            1",
        "source": "diffusion_model.txt"
    },
    {
        "text": "π\n          \n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle q(z)=\\Gamma (\\pi _{0},\\pi _{1})}\n  \n, where \n  \n    \n      \n        Γ\n      \n    \n    {\\displaystyle \\Gamma }\n  \n is the optimal transport plan, which can be approximated by mini-batch optimal transport. If the batch size is not large, then the transport it computes can be very far from the true optimal transport.\n\n\n=== Rectified flow ===\nThe idea of rectified flow is to learn a flow model such that t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ectified flow is to learn a flow model such that the velocity is nearly constant along each flow path. This is beneficial, because we can integrate along such a vector field with very few steps. For example, if an ODE \n  \n    \n      \n        \n          \n            \n              \n                ϕ\n                \n                  t\n                \n              \n              ˙\n            \n          \n        \n        (\n        x\n        )\n        =\n        \n          v",
        "source": "diffusion_model.txt"
    },
    {
        "text": "=\n        \n          v\n          \n            t\n          \n        \n        (\n        \n          ϕ\n          \n            t\n          \n        \n        (\n        x\n        )\n        )\n      \n    \n    {\\displaystyle {\\dot {\\phi _{t}}}(x)=v_{t}(\\phi _{t}(x))}\n  \n follows perfectly straight paths, it simplifies to \n  \n    \n      \n        \n          ϕ\n          \n            t\n          \n        \n        (\n        x\n        )\n        =\n        \n          x\n          \n            0",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n            0\n          \n        \n        +\n        t\n        ⋅\n        \n          v\n          \n            0\n          \n        \n        (\n        \n          x\n          \n            0\n          \n        \n        )\n      \n    \n    {\\displaystyle \\phi _{t}(x)=x_{0}+t\\cdot v_{0}(x_{0})}\n  \n, allowing for exact solutions in one step. In practice, we cannot reach such perfection, but when the flow field is nearly so, we can take a few large steps instead of many little steps.",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ke a few large steps instead of many little steps.  \n\nThe general idea is to start with two distributions \n  \n    \n      \n        \n          π\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\pi _{0}}\n  \n and \n  \n    \n      \n        \n          π\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\pi _{1}}\n  \n, then construct a flow field \n  \n    \n      \n        \n          ϕ\n          \n            0\n          \n        \n        =\n        {",
        "source": "diffusion_model.txt"
    },
    {
        "text": "0\n          \n        \n        =\n        {\n        \n          ϕ\n          \n            t\n          \n        \n        :\n        t\n        ∈\n        [\n        0\n        ,\n        1\n        ]\n        }\n      \n    \n    {\\displaystyle \\phi ^{0}=\\{\\phi _{t}:t\\in [0,1]\\}}\n  \n from it, then repeatedly apply a \"reflow\" operation to obtain successive flow fields \n  \n    \n      \n        \n          ϕ\n          \n            1\n          \n        \n        ,\n        \n          ϕ\n          \n            2",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ϕ\n          \n            2\n          \n        \n        ,\n        …\n      \n    \n    {\\displaystyle \\phi ^{1},\\phi ^{2},\\dots }\n  \n, each straighter than the previous one. When the flow field is straight enough for the application, we stop.\nGenerally, for any time-differentiable process \n  \n    \n      \n        \n          ϕ\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle \\phi _{t}}\n  \n, \n  \n    \n      \n        \n          v\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "v\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle v_{t}}\n  \n can be estimated by solving:\n\n  \n    \n      \n        \n          min\n          \n            θ\n          \n        \n        \n          ∫\n          \n            0\n          \n          \n            1\n          \n        \n        \n          \n            E\n          \n          \n            x\n            ∼\n            \n              p\n              \n                t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n              \n            \n          \n        \n        \n          [\n          \n            ‖\n            \n              \n                v\n                \n                  t\n                \n              \n              (\n              x\n              ,\n              θ\n              )\n              −\n              \n                v\n                \n                  t\n                \n              \n              (\n              x\n              )",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n              )\n            \n            \n              ‖\n              \n                2\n              \n            \n          \n          ]\n        \n        \n        \n          d\n        \n        t\n        .\n      \n    \n    {\\displaystyle \\min _{\\theta }\\int _{0}^{1}\\mathbb {E} _{x\\sim p_{t}}\\left[\\lVert {v_{t}(x,\\theta )-v_{t}(x)}\\rVert ^{2}\\right]\\,\\mathrm {d} t.}\n  \n\nIn rectified flow, by injecting strong priors that intermediate trajectories are straight, it can achieve both theoret",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ectories are straight, it can achieve both theoretical relevance for optimal transport  and computational efficiency, as ODEs with straight paths can be simulated precisely without time discretization.\n\nSpecifically, rectified flow seeks to match an ODE with the marginal distributions of the linear interpolation between points from distributions \n  \n    \n      \n        \n          π\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\pi _{0}}\n  \n and",
        "source": "diffusion_model.txt"
    },
    {
        "text": "splaystyle \\pi _{0}}\n  \n and \n  \n    \n      \n        \n          π\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\pi _{1}}\n  \n. Given observations \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n        ∼\n        \n          π\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}\\sim \\pi _{0}}\n  \n and \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        ∼",
        "source": "diffusion_model.txt"
    },
    {
        "text": "1\n          \n        \n        ∼\n        \n          π\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle x_{1}\\sim \\pi _{1}}\n  \n, the canonical linear interpolation \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        =\n        t\n        \n          x\n          \n            1\n          \n        \n        +\n        (\n        1\n        −\n        t\n        )\n        \n          x\n          \n            0\n          \n        \n        ,",
        "source": "diffusion_model.txt"
    },
    {
        "text": "0\n          \n        \n        ,\n        t\n        ∈\n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle x_{t}=tx_{1}+(1-t)x_{0},t\\in [0,1]}\n  \n yields a trivial case \n  \n    \n      \n        \n          \n            \n              \n                x\n                ˙\n              \n            \n          \n          \n            t\n          \n        \n        =\n        \n          x\n          \n            1\n          \n        \n        −\n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "−\n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle {\\dot {x}}_{t}=x_{1}-x_{0}}\n  \n, which cannot be causally simulated without \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle x_{1}}\n  \n. To address this, \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t}}\n  \n is \"projected\" into a space of c",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ystyle x_{t}}\n  \n is \"projected\" into a space of causally simulatable ODEs, by minimizing the least squares loss with respect to the direction \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        −\n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{1}-x_{0}}\n  \n:\n\n  \n    \n      \n        \n          min\n          \n            θ\n          \n        \n        \n          ∫\n          \n            0",
        "source": "diffusion_model.txt"
    },
    {
        "text": "∫\n          \n            0\n          \n          \n            1\n          \n        \n        \n          \n            E\n          \n          \n            \n              π\n              \n                0\n              \n            \n            ,\n            \n              π\n              \n                1\n              \n            \n            ,\n            \n              p\n              \n                t\n              \n            \n          \n        \n        \n          [",
        "source": "diffusion_model.txt"
    },
    {
        "text": "[\n          \n            ‖\n            \n              (\n              \n                x\n                \n                  1\n                \n              \n              −\n              \n                x\n                \n                  0\n                \n              \n              )\n              −\n              \n                v\n                \n                  t\n                \n              \n              (\n              \n                x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "(\n              \n                x\n                \n                  t\n                \n              \n              )\n            \n            \n              ‖\n              \n                2\n              \n            \n          \n          ]\n        \n        \n        \n          d\n        \n        t\n        .\n      \n    \n    {\\displaystyle \\min _{\\theta }\\int _{0}^{1}\\mathbb {E} _{\\pi _{0},\\pi _{1},p_{t}}\\left[\\lVert {(x_{1}-x_{0})-v_{t}(x_{t})}\\rVert ^{2}\\right]\\,\\mathrm {d} t.}\n  \n\nThe d",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{t})}\\rVert ^{2}\\right]\\,\\mathrm {d} t.}\n  \n\nThe data pair \n  \n    \n      \n        (\n        \n          x\n          \n            0\n          \n        \n        ,\n        \n          x\n          \n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{0},x_{1})}\n  \n can be any coupling of \n  \n    \n      \n        \n          π\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\pi _{0}}\n  \n and \n  \n    \n      \n        \n          π",
        "source": "diffusion_model.txt"
    },
    {
        "text": "π\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\pi _{1}}\n  \n, typically independent (i.e., \n  \n    \n      \n        (\n        \n          x\n          \n            0\n          \n        \n        ,\n        \n          x\n          \n            1\n          \n        \n        )\n        ∼\n        \n          π\n          \n            0\n          \n        \n        ×\n        \n          π\n          \n            1\n          \n        \n      \n    \n    {\\disp",
        "source": "diffusion_model.txt"
    },
    {
        "text": "1\n          \n        \n      \n    \n    {\\displaystyle (x_{0},x_{1})\\sim \\pi _{0}\\times \\pi _{1}}\n  \n) obtained by randomly combining observations from \n  \n    \n      \n        \n          π\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\pi _{0}}\n  \n and \n  \n    \n      \n        \n          π\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle \\pi _{1}}\n  \n. This process ensures that the trajectories closely mirror the density map of",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ctories closely mirror the density map of \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t}}\n  \n trajectories but reroute at intersections to ensure causality.\n\nA distinctive aspect of rectified flow is its capability for \"reflow\", which straightens the trajectory of ODE paths. Denote the rectified flow \n  \n    \n      \n        \n          ϕ\n          \n            0\n          \n        \n        =\n        {\n        \n          ϕ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "=\n        {\n        \n          ϕ\n          \n            t\n          \n        \n        :\n        t\n        ∈\n        [\n        0\n        ,\n        1\n        ]\n        }\n      \n    \n    {\\displaystyle \\phi ^{0}=\\{\\phi _{t}:t\\in [0,1]\\}}\n  \n induced from \n  \n    \n      \n        (\n        \n          x\n          \n            0\n          \n        \n        ,\n        \n          x\n          \n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle (x_{0},x_{1})}\n  \n as",
        "source": "diffusion_model.txt"
    },
    {
        "text": "{\\displaystyle (x_{0},x_{1})}\n  \n as \n  \n    \n      \n        \n          ϕ\n          \n            0\n          \n        \n        =\n        \n          \n            R\n            e\n            c\n            t\n            f\n            l\n            o\n            w\n          \n        \n        (\n        (\n        \n          x\n          \n            0\n          \n        \n        ,\n        \n          x\n          \n            1\n          \n        \n        )\n        )\n      \n    \n    {\\displayst",
        "source": "diffusion_model.txt"
    },
    {
        "text": ")\n        )\n      \n    \n    {\\displaystyle \\phi ^{0}={\\mathsf {Rectflow}}((x_{0},x_{1}))}\n  \n. Recursively applying this \n  \n    \n      \n        \n          \n            R\n            e\n            c\n            t\n            f\n            l\n            o\n            w\n          \n        \n        (\n        ⋅\n        )\n      \n    \n    {\\displaystyle {\\mathsf {Rectflow}}(\\cdot )}\n  \n operator generates a series of rectified flows \n  \n    \n      \n        \n          ϕ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ϕ\n          \n            k\n            +\n            1\n          \n        \n        =\n        \n          \n            R\n            e\n            c\n            t\n            f\n            l\n            o\n            w\n          \n        \n        (\n        (\n        \n          ϕ\n          \n            0\n          \n          \n            k\n          \n        \n        (\n        \n          x\n          \n            0\n          \n        \n        )\n        ,",
        "source": "diffusion_model.txt"
    },
    {
        "text": ")\n        ,\n        \n          ϕ\n          \n            1\n          \n          \n            k\n          \n        \n        (\n        \n          x\n          \n            1\n          \n        \n        )\n        )\n        )\n      \n    \n    {\\displaystyle \\phi ^{k+1}={\\mathsf {Rectflow}}((\\phi _{0}^{k}(x_{0}),\\phi _{1}^{k}(x_{1})))}\n  \n. This \"reflow\" process not only reduces transport costs but also straightens the paths of rectified flows, making",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ied flows, making \n  \n    \n      \n        \n          ϕ\n          \n            k\n          \n        \n      \n    \n    {\\displaystyle \\phi ^{k}}\n  \n paths straighter with increasing \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n.\nRectified flow includes a nonlinear extension where linear interpolation \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t}}\n  \n is replaced with any time-differentiable curve that connect",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ed with any time-differentiable curve that connects \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n and \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle x_{1}}\n  \n, given by \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n        =\n        \n          α\n          \n            t\n          \n        \n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n        \n          x\n          \n            1\n          \n        \n        +\n        \n          β\n          \n            t\n          \n        \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{t}=\\alpha _{t}x_{1}+\\beta _{t}x_{0}}\n  \n. This framework encompasses DDIM and probability flow ODEs as special cases, with particular choices of \n  \n    \n      \n        \n          α\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n      \n    \n    {\\displaystyle \\alpha _{t}}\n  \n and \n  \n    \n      \n        \n          β\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle \\beta _{t}}\n  \n. However, in the case where the path of \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t}}\n  \n is not straight, the reflow process no longer ensures a reduction in convex transport costs, and also no longer st",
        "source": "diffusion_model.txt"
    },
    {
        "text": "n in convex transport costs, and also no longer straighten the paths of \n  \n    \n      \n        \n          ϕ\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle \\phi _{t}}\n  \n.\n\n\n== Choice of architecture ==\n\n\n=== Diffusion model ===\nFor generating images by DDPM, we need a neural network that takes a time \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n and a noisy image \n  \n    \n      \n        \n          x\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n        \n      \n    \n    {\\displaystyle x_{t}}\n  \n, and predicts a noise \n  \n    \n      \n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x\n          \n            t\n          \n        \n        ,\n        t\n        )\n      \n    \n    {\\displaystyle \\epsilon _{\\theta }(x_{t},t)}\n  \n from it. Since predicting the noise is the same as predicting the denoised image, then subtracting it from",
        "source": "diffusion_model.txt"
    },
    {
        "text": "subtracting it from \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t}}\n  \n, denoising architectures tend to work well. For example, the U-Net, which was found to be good for denoising images, is often used for denoising diffusion models that generate images.\nFor DDPM, the underlying architecture (\"backbone\") does not have to be a U-Net. It just has to predict the noise somehow. For example, the diffusion transformer (DiT) uses",
        "source": "diffusion_model.txt"
    },
    {
        "text": "For example, the diffusion transformer (DiT) uses a Transformer to predict the mean and diagonal covariance of the noise, given the textual conditioning and the partially denoised image. It is the same as standard U-Net-based denoising diffusion model, with a Transformer replacing the U-Net. Mixture of experts-Transformer can also be applied.\nDDPM can be used to model general data distributions, not just natural-looking images. For example, Human Motion Diffusion models human motion trajectory b",
        "source": "diffusion_model.txt"
    },
    {
        "text": "Motion Diffusion models human motion trajectory by DDPM. Each human motion trajectory is a sequence of poses, represented by either joint rotations or positions. It uses a Transformer network to generate a less noisy trajectory out of a noisy one.\n\n\n=== Conditioning ===\nThe base diffusion model can only generate unconditionally from the whole distribution. For example, a diffusion model learned on ImageNet would generate images that look like a random image from ImageNet. To generate images fro",
        "source": "diffusion_model.txt"
    },
    {
        "text": "random image from ImageNet. To generate images from just one category, one would need to impose the condition, and then sample from the conditional distribution. Whatever condition one wants to impose, one needs to first convert the conditioning into a vector of floating point numbers, then feed it into the underlying diffusion model neural network. However, one has freedom in choosing how to convert the conditioning into a vector.\nStable Diffusion, for example, imposes conditioning in the form",
        "source": "diffusion_model.txt"
    },
    {
        "text": "on, for example, imposes conditioning in the form of cross-attention mechanism, where the query is an intermediate representation of the image in the U-Net, and both key and value are the conditioning vectors. The conditioning can be selectively applied to only parts of an image, and new kinds of conditionings can be finetuned upon the base model, as used in ControlNet.\nAs a particularly simple example, consider image inpainting. The conditions are",
        "source": "diffusion_model.txt"
    },
    {
        "text": "re \n  \n    \n      \n        \n          \n            \n              x\n              ~\n            \n          \n        \n      \n    \n    {\\displaystyle {\\tilde {x}}}\n  \n, the reference image, and \n  \n    \n      \n        m\n      \n    \n    {\\displaystyle m}\n  \n, the inpainting mask. The conditioning is imposed at each step of the backward diffusion process, by first sampling \n  \n    \n      \n        \n          \n            \n              \n                x\n                ~",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n                ~\n              \n            \n          \n          \n            t\n          \n        \n        ∼\n        N\n        \n          (\n          \n            \n              \n                \n                  \n                    \n                      \n                        α\n                        ¯\n                      \n                    \n                  \n                  \n                    t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n                  ~\n                \n              \n            \n            ,\n            \n              σ\n              \n                t\n              \n              \n                2\n              \n            \n            I\n          \n          )\n        \n      \n    \n    {\\displaystyle {\\tilde {x}}_{t}\\sim N\\left({\\sqrt {{\\bar {\\alpha }}_{t}}}{\\tilde {x}},\\sigma _{t}^{2}I\\right)}\n  \n, a no",
        "source": "diffusion_model.txt"
    },
    {
        "text": "}}}{\\tilde {x}},\\sigma _{t}^{2}I\\right)}\n  \n, a noisy version of \n  \n    \n      \n        \n          \n            \n              x\n              ~\n            \n          \n        \n      \n    \n    {\\displaystyle {\\tilde {x}}}\n  \n, then replacing \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t}}\n  \n with \n  \n    \n      \n        (\n        1\n        −\n        m\n        )\n        ⊙\n        \n          x\n          \n            t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n            t\n          \n        \n        +\n        m\n        ⊙\n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            t\n          \n        \n      \n    \n    {\\displaystyle (1-m)\\odot x_{t}+m\\odot {\\tilde {x}}_{t}}\n  \n, where \n  \n    \n      \n        ⊙\n      \n    \n    {\\displaystyle \\odot }\n  \n means elementwise multiplication. Another application of cross-attention mechanism i",
        "source": "diffusion_model.txt"
    },
    {
        "text": "Another application of cross-attention mechanism is prompt-to-prompt image editing.\nConditioning is not limited to just generating images from a specific category, or according to a specific caption (as in text-to-image). For example, demonstrated generating human motion, conditioned on an audio clip of human walking (allowing syncing motion to a soundtrack), or video of human running, or a text description of human motion, etc. For how conditional diffusion models are mathematically formulated,",
        "source": "diffusion_model.txt"
    },
    {
        "text": "al diffusion models are mathematically formulated, see a methodological summary in.\n\n\n=== Upscaling ===\nAs generating an image takes a long time, one can try to generate a small image by a base diffusion model, then upscale it by other models. Upscaling can be done by GAN, Transformer, or signal processing methods like Lanczos resampling.\nDiffusion models themselves can be used to perform upscaling. Cascading diffusion model stacks multiple diffusion models one after another, in the style of Pro",
        "source": "diffusion_model.txt"
    },
    {
        "text": "sion models one after another, in the style of Progressive GAN. The lowest level is a standard diffusion model that generate 32x32 image, then the image would be upscaled by a diffusion model specifically trained for upscaling, and the process repeats.\nIn more detail, the diffusion upscaler is trained as follows:\n\nSample \n  \n    \n      \n        (\n        \n          x\n          \n            0\n          \n        \n        ,\n        \n          z\n          \n            0\n          \n        \n        ,",
        "source": "diffusion_model.txt"
    },
    {
        "text": "0\n          \n        \n        ,\n        c\n        )\n      \n    \n    {\\displaystyle (x_{0},z_{0},c)}\n  \n, where \n  \n    \n      \n        \n          x\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle x_{0}}\n  \n is the high-resolution image, \n  \n    \n      \n        \n          z\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle z_{0}}\n  \n is the same image but scaled down to a low-resolution, and \n  \n    \n      \n        c",
        "source": "diffusion_model.txt"
    },
    {
        "text": "-resolution, and \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n is the conditioning, which can be the caption of the image, the class of the image, etc.\nSample two white noises \n  \n    \n      \n        \n          ϵ\n          \n            x\n          \n        \n        ,\n        \n          ϵ\n          \n            z\n          \n        \n      \n    \n    {\\displaystyle \\epsilon _{x},\\epsilon _{z}}\n  \n, two time-steps \n  \n    \n      \n        \n          t\n          \n            x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n            x\n          \n        \n        ,\n        \n          t\n          \n            z\n          \n        \n      \n    \n    {\\displaystyle t_{x},t_{z}}\n  \n. Compute the noisy versions of the high-resolution and low-resolution images: \n  \n    \n      \n        \n          \n            {\n            \n              \n                \n                  \n                    x\n                    \n                      \n                        t",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                        \n                          x\n                        \n                      \n                    \n                  \n                \n                \n                  =\n                  \n                    \n                      \n                        \n                          \n                            \n                              α\n                              ¯",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n                            \n                              x\n                            \n                          \n                        \n                      \n                    \n                  \n                  \n                    x\n                    \n                      0\n                    \n                  \n                  +",
        "source": "diffusion_model.txt"
    },
    {
        "text": "+\n                  \n                    σ\n                    \n                      \n                        t\n                        \n                          x\n                        \n                      \n                    \n                  \n                  \n                    ϵ\n                    \n                      x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "z\n                    \n                      \n                        t\n                        \n                          z\n                        \n                      \n                    \n                  \n                \n                \n                  =",
        "source": "diffusion_model.txt"
    },
    {
        "text": "α\n                              ¯\n                            \n                          \n                        \n                        \n                          \n                            t\n                            \n                              z",
        "source": "diffusion_model.txt"
    },
    {
        "text": "z\n                    \n                      0\n                    \n                  \n                  +\n                  \n                    σ\n                    \n                      \n                        t\n                        \n                          z\n                        \n                      \n                    \n                  \n                  \n                    ϵ\n                    \n                      z",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ϵ\n                    \n                      z\n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{cases}x_{t_{x}}&={\\sqrt {{\\bar {\\alpha }}_{t_{x}}}}x_{0}+\\sigma _{t_{x}}\\epsilon _{x}\\\\z_{t_{z}}&={\\sqrt {{\\bar {\\alpha }}_{t_{z}}}}z_{0}+\\sigma _{t_{z}}\\epsilon _{z}\\end{cases}}}\n  \n.\nTrain the denoising network to predict \n  \n    \n      \n        \n          ϵ\n          \n            x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "ϵ\n          \n            x\n          \n        \n      \n    \n    {\\displaystyle \\epsilon _{x}}\n  \n given \n  \n    \n      \n        \n          x\n          \n            \n              t\n              \n                x\n              \n            \n          \n        \n        ,\n        \n          z\n          \n            \n              t\n              \n                z\n              \n            \n          \n        \n        ,\n        \n          t\n          \n            x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "t\n          \n            x\n          \n        \n        ,\n        \n          t\n          \n            z\n          \n        \n        ,\n        c\n      \n    \n    {\\displaystyle x_{t_{x}},z_{t_{z}},t_{x},t_{z},c}\n  \n. That is, apply gradient descent on \n  \n    \n      \n        θ\n      \n    \n    {\\displaystyle \\theta }\n  \n on the L2 loss \n  \n    \n      \n        ‖\n        \n          ϵ\n          \n            θ\n          \n        \n        (\n        \n          x",
        "source": "diffusion_model.txt"
    },
    {
        "text": "x\n          \n            \n              t\n              \n                x\n              \n            \n          \n        \n        ,\n        \n          z\n          \n            \n              t\n              \n                z\n              \n            \n          \n        \n        ,\n        \n          t\n          \n            x\n          \n        \n        ,\n        \n          t\n          \n            z\n          \n        \n        ,\n        c\n        )\n        −\n        \n          ϵ",
        "source": "diffusion_model.txt"
    },
    {
        "text": "c\n        )\n        −\n        \n          ϵ\n          \n            x\n          \n        \n        \n          ‖\n          \n            2\n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle \\|\\epsilon _{\\theta }(x_{t_{x}},z_{t_{z}},t_{x},t_{z},c)-\\epsilon _{x}\\|_{2}^{2}}\n  \n.\n\n\n== Examples ==\nThis section collects some notable diffusion models, and briefly describes their architecture.\n\n\n=== OpenAI ===\n\nThe DALL-E series by OpenAI are text-conditional diffusio",
        "source": "diffusion_model.txt"
    },
    {
        "text": "L-E series by OpenAI are text-conditional diffusion models of images.\nThe first version of DALL-E (2021) is not actually a diffusion model. Instead, it uses a Transformer architecture that autoregressively generates a sequence of tokens, which is then converted to an image by the decoder of a discrete VAE. Released with DALL-E was the CLIP classifier, which was used by DALL-E to rank generated images according to how close the image fits the text.\nGLIDE (2022-03) is a 3.5-billion diffusion model",
        "source": "diffusion_model.txt"
    },
    {
        "text": ".\nGLIDE (2022-03) is a 3.5-billion diffusion model, and a small version was released publicly. Soon after, DALL-E 2 was released (2022-04). DALL-E 2 is a 3.5-billion cascaded diffusion model that generates images from text by \"inverting the CLIP image encoder\", the technique which they termed \"unCLIP\".\nThe unCLIP method contains 4 models: a CLIP image encoder, a CLIP text encoder, an image decoder, and a \"prior\" model (which can be a diffusion model, or an autoregressive model). During training,",
        "source": "diffusion_model.txt"
    },
    {
        "text": "del, or an autoregressive model). During training, the prior model is trained to convert CLIP image encodings to CLIP text encodings. The image decoder is trained to convert CLIP image encodings back to images. During inference, a text is converted by the CLIP text encoder to a vector, then it is converted by the prior model to an image encoding, then it is converted by the image decoder to an image.\nSora (2024-02) is a diffusion Transformer model (DiT).\n\n\n=== Stability AI ===\n\nStable Diffusion",
        "source": "diffusion_model.txt"
    },
    {
        "text": "l (DiT).\n\n\n=== Stability AI ===\n\nStable Diffusion (2022-08), released by Stability AI, consists of a denoising latent diffusion model (860 million parameters), a VAE, and a text encoder. The denoising network is a U-Net, with cross-attention blocks to allow for conditional image generation.\nStable Diffusion 3 (2024-03) changed the latent diffusion model from the UNet to a Transformer model, and so it is a DiT. It uses rectified flow.\nStable Video 4D (2024-07) is a latent diffusion model for vide",
        "source": "diffusion_model.txt"
    },
    {
        "text": "4D (2024-07) is a latent diffusion model for videos of 3D objects.\n\n\n=== Google ===\nImagen (2022) uses a T5-XXL language model to encode the input text into an embedding vector. It is a cascaded diffusion model with three sub-models. The first step denoises a white noise to a 64×64 image, conditional on the embedding vector of the text. This model has 2B parameters. The second step upscales the image by 64×64→256×256, conditional on embedding. This model has 650M parameters. The third step is s",
        "source": "diffusion_model.txt"
    },
    {
        "text": "his model has 650M parameters. The third step is similar, upscaling by 256×256→1024×1024. This model has 400M parameters. The three denoising networks are all U-Nets.\nMuse (2023-01) is not a diffusion model, but an encoder-only Transformer that is trained to predict masked image tokens from unmasked image tokens.\nImagen 2 (2023-12) is also diffusion-based. It can generate images based on a prompt that mixes images and text. No further information available. Imagen 3 (2024-05) is too. No further",
        "source": "diffusion_model.txt"
    },
    {
        "text": "available. Imagen 3 (2024-05) is too. No further information available.\nVeo (2024) generates videos by latent diffusion. The diffusion is conditioned on a vector that encodes both a text prompt and an image prompt.\n\n\n=== Meta ===\nMake-A-Video (2022) is a text-to-video diffusion model.\nCM3leon (2023) is not a diffusion model, but an autoregressive causally masked Transformer, with mostly the same architecture as LLaMa-2.\n\nTransfusion (2024) is a Transformer that combines autoregressive text gene",
        "source": "diffusion_model.txt"
    },
    {
        "text": "Transformer that combines autoregressive text generation and denoising diffusion. Specifically, it generates text autoregressively (with causal masking), and generates images by denoising multiple times over image tokens (with all-to-all attention).\nMovie Gen (2024) is a series of Diffusion Transformers operating on latent space and by flow matching.\n\n\n== See also ==\nDiffusion process\nMarkov chain\nVariational inference\nVariational autoencoder\n\n\n== Further reading ==\nReview papers\nYang, Ling (202",
        "source": "diffusion_model.txt"
    },
    {
        "text": "= Further reading ==\nReview papers\nYang, Ling (2024-09-06), YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy, retrieved 2024-09-06\nYang, Ling; Zhang, Zhilong; Song, Yang; Hong, Shenda; Xu, Runsheng; Zhao, Yue; Zhang, Wentao; Cui, Bin; Yang, Ming-Hsuan (2023-11-09). \"Diffusion Models: A Comprehensive Survey of Methods and Applications\". ACM Comput. Surv. 56 (4): 105:1–105:39. arXiv:2209.00796. doi:10.1145/3626235. ISSN 0360-0300.\nAustin, Jacob; Johnson, Daniel D.; Ho, Jonathan; Tarlow, Daniel",
        "source": "diffusion_model.txt"
    },
    {
        "text": "; Johnson, Daniel D.; Ho, Jonathan; Tarlow, Daniel; Rianne van den Berg (2021). \"Structured Denoising Diffusion Models in Discrete State-Spaces\". arXiv:2107.03006 [cs.LG].\nCroitoru, Florinel-Alin; Hondru, Vlad; Ionescu, Radu Tudor; Shah, Mubarak (2023-09-01). \"Diffusion Models in Vision: A Survey\". IEEE Transactions on Pattern Analysis and Machine Intelligence. 45 (9): 10850–10869. arXiv:2209.04747. doi:10.1109/TPAMI.2023.3261988. ISSN 0162-8828. PMID 37030794.\nMathematical details omitted in th",
        "source": "diffusion_model.txt"
    },
    {
        "text": "PMID 37030794.\nMathematical details omitted in the article.\n\"Power of Diffusion Models\". AstraBlog. 2022-09-25. Retrieved 2023-09-25.\nLuo, Calvin (2022-08-25). \"Understanding Diffusion Models: A Unified Perspective\". arXiv:2208.11970 [cs.LG].\nWeng, Lilian (2021-07-11). \"What are Diffusion Models?\". lilianweng.github.io. Retrieved 2023-09-25.\nTutorials\nNakkiran, Preetum; Bradley, Arwen; Zhou, Hattie; Advani, Madhu (2024). \"Step-by-Step Diffusion: An Elementary Tutorial\". arXiv:2406.08929 [cs.LG]",
        "source": "diffusion_model.txt"
    },
    {
        "text": "An Elementary Tutorial\". arXiv:2406.08929 [cs.LG].\n\"Guidance: a cheat code for diffusion models\". 26 May 2022. Overview of classifier guidance and classifier-free guidance, light on mathematical details.\n\n\n== References ==",
        "source": "diffusion_model.txt"
    },
    {
        "text": "FAISS (Facebook AI Similarity Search) is an open-source library for similarity search and clustering of vectors. It contains algorithms that search in sets of vectors of any size, up to ones that possibly do not fit in RAM. It also contains supporting code for evaluation and parameter tuning. \nFAISS is written in C++ with complete wrappers for Python and C. Some of the most useful algorithms are implemented on the GPU using CUDA.\n\n\n== Features ==\nFAISS is organized as a toolbox that contains a v",
        "source": "faiss.txt"
    },
    {
        "text": "FAISS is organized as a toolbox that contains a variety of indexing methods that commonly involve a chain of components (preprocessing, compression, non-exhaustive search, etc.). The scope of the library is intentionally limited to focus on ANNS algorithmic implementation and to avoid facilities related to database functionality, distributed computing or feature extraction algorithms.\nFAISS is designed with the following assumptions:\n\nPrimary data type for vector representation is FP32. The sup",
        "source": "faiss.txt"
    },
    {
        "text": "ta type for vector representation is FP32. The support of other floating-point formats, such as BF16 and FP16, is provided.\nPrefer batches of input queries over a single input query for the search.\nEmphasize on allowing users to write a fast prototyping code using its Python wrappers.\nThe code should be as open as possible, so that users can access all the implementation details of the indexes.\nThe following major categories of indexing methods are supported:\n\nBrute-force search\nInverted-lists b",
        "source": "faiss.txt"
    },
    {
        "text": "re supported:\n\nBrute-force search\nInverted-lists based indices\nGraph indices, including  (Hierarchical navigable small world) HNSW and Navigating Spread-out Graph (NSG)\nLocality-sensitive hashing (LSH)\nThe following families of vector quantization methods are supported:\n\nBinary Quantization\nScalar Quantization (SQ)\nProduct Quantization (PQ), including Polysemous Codes, Optimized Product Quantization (OPQ) and Quicker ADC (PQFastScan)\nAdditive Quantization (AQ), including Residual Quantization (R",
        "source": "faiss.txt"
    },
    {
        "text": "ntization (AQ), including Residual Quantization (RQ) and Local Search Quantization (LSQ)\nNeural Quantization, including QINCO\nFAISS focuses on euclidean distance and inner product distance for floating-point data. The limited support of other distances (manhattan distance, Lp distance, etc.) is also available.\nFAISS code supports multithreading via OpenMP, utilizes BLAS via OpenBLAS or Intel MKL, and also uses custom SIMD kernels for x86 and ARM Neon CPUs.\nBesides the similarity search, FAISS pr",
        "source": "faiss.txt"
    },
    {
        "text": "Neon CPUs.\nBesides the similarity search, FAISS provides the following useful facilities:\n\nk-means clustering\nRandom-matrix rotations for spreading the variance over all the dimensions without changing the measured distances\nPrincipal component analysis\nData deduplication, which is especially useful for image datasets.\nFAISS has a standalone Vector Codec functionality for the lossy compression of vectors, allowing to trade the representation accuracy for the binary size.\n\n\n== Applications ==\nTyp",
        "source": "faiss.txt"
    },
    {
        "text": "racy for the binary size.\n\n\n== Applications ==\nTypical FAISS applications include  recommender systems, data mining, text retrieval and content moderation.\nFAISS was reported to index 1.5 trillion 144-dimensional vectors for internal Meta Platforms applications.\nFAISS is used in vector databases as a core component of a search engine (OpenSearch, Milvus, Vearch).\nFAISS is often considered as a baseline in similarity search benchmarks.\nFAISS has an integration with Haystack, LangChain frameworks.",
        "source": "faiss.txt"
    },
    {
        "text": "n integration with Haystack, LangChain frameworks.\nVarious advanced code snippets for FAISS can be found on its snippets wiki page and case studies wiki page.\n\n\n== See also ==\n\nNearest neighbor search\nSimilarity search\nVector database\nVector quantization\n\n\n== References ==\n\n\n== External links ==\nOfficial website\nfaiss on GitHub\nOfficial FAISS wiki\nGuidelines to choose a FAISS index\nAutofaiss - automatically create Faiss knn indices with the most optimal similarity search parameters",
        "source": "faiss.txt"
    },
    {
        "text": "optimal similarity search parameters",
        "source": "faiss.txt"
    },
    {
        "text": "A generative adversarial network (GAN) is a class of machine learning frameworks and a prominent framework for approaching generative artificial intelligence. The concept was initially developed by Ian Goodfellow and his colleagues in June 2014. In a GAN, two neural networks compete with each other in the form of a zero-sum game, where one agent's gain is another agent's loss.\nGiven a training set, this technique learns to generate new data with the same statistics as the training set. For examp",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "the same statistics as the training set. For example, a GAN trained on photographs can generate new photographs that look at least superficially authentic to human observers, having many realistic characteristics. Though originally proposed as a form of generative model for unsupervised learning, GANs have also proved useful for semi-supervised learning, fully supervised learning, and reinforcement learning.\nThe core idea of a GAN is based on the \"indirect\" training through the discriminator, an",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "\"indirect\" training through the discriminator, another neural network that can tell how \"realistic\" the input seems, which itself is also being updated dynamically. This means that the generator is not trained to minimize the distance to a specific image, but rather to fool the discriminator. This enables the model to learn in an unsupervised manner.\nGANs are similar to mimicry in evolutionary biology, with an evolutionary arms race between both networks.\n\n\n== Definition ==\n\n\n=== Mathematical =",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "networks.\n\n\n== Definition ==\n\n\n=== Mathematical ===\nThe original GAN is defined as the following game:\nEach probability space \n  \n    \n      \n        (\n        Ω\n        ,\n        \n          μ\n          \n            ref\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega ,\\mu _{\\text{ref}})}\n  \n defines a GAN game.\nThere are 2 players: generator and discriminator.\nThe generator's strategy set is \n  \n    \n      \n        \n          \n            P\n          \n        \n        (",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "P\n          \n        \n        (\n        Ω\n        )\n      \n    \n    {\\displaystyle {\\mathcal {P}}(\\Omega )}\n  \n, the set of all probability measures \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n on \n  \n    \n      \n        Ω\n      \n    \n    {\\displaystyle \\Omega }\n  \n.\nThe discriminator's strategy set is the set of Markov kernels \n  \n    \n      \n        \n          μ\n          \n            D",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "μ\n          \n            D\n          \n        \n        :\n        Ω\n        →\n        \n          \n            P\n          \n        \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle \\mu _{D}:\\Omega \\to {\\mathcal {P}}[0,1]}\n  \n, where \n  \n    \n      \n        \n          \n            P\n          \n        \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle {\\mathcal {P}}[0,1]}\n  \n is the set of probability measures on",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "is the set of probability measures on \n  \n    \n      \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle [0,1]}\n  \n.\nThe GAN game is a zero-sum game, with objective function\n  \n    \n      \n        L\n        (\n        \n          μ\n          \n            G\n          \n        \n        ,\n        \n          μ\n          \n            D\n          \n        \n        )\n        :=\n        \n          E\n          \n            x\n            ∼\n            \n              μ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "∼\n            \n              μ\n              \n                ref\n              \n            \n            ,\n            y\n            ∼\n            \n              μ\n              \n                D\n              \n            \n            (\n            x\n            )\n          \n        \n        ⁡\n        [\n        ln\n        ⁡\n        y\n        ]\n        +\n        \n          E\n          \n            x\n            ∼\n            \n              μ\n              \n                G",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "μ\n              \n                G\n              \n            \n            ,\n            y\n            ∼\n            \n              μ\n              \n                D\n              \n            \n            (\n            x\n            )\n          \n        \n        ⁡\n        [\n        ln\n        ⁡\n        (\n        1\n        −\n        y\n        )\n        ]\n        .\n      \n    \n    {\\displaystyle L(\\mu _{G},\\mu _{D}):=\\operatorname {E} _{x\\sim \\mu _{\\text{ref}},y\\sim \\mu _{D}(x)}[\\ln y]+\\",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "\\sim \\mu _{\\text{ref}},y\\sim \\mu _{D}(x)}[\\ln y]+\\operatorname {E} _{x\\sim \\mu _{G},y\\sim \\mu _{D}(x)}[\\ln(1-y)].}\n  \n\nThe generator aims to minimize the objective, and the discriminator aims to maximize the objective.\n\nThe generator's task is to approach \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n        ≈\n        \n          μ\n          \n            ref\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}\\approx \\mu _{\\text{ref}}}\n  \n, that is, to m",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "_{G}\\approx \\mu _{\\text{ref}}}\n  \n, that is, to match its own output distribution as closely as possible to the reference distribution. The discriminator's task is to output a value close to 1 when the input appears to be from the reference distribution, and to output a value close to 0 when the input looks like it came from the generator distribution.\n\n\n=== In practice ===\nThe generative network generates candidates while the discriminative network evaluates them. The contest operates in terms",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "work evaluates them. The contest operates in terms of data distributions. Typically, the generative network learns to map from a latent space to a data distribution of interest, while the discriminative network distinguishes candidates produced by the generator from the true data distribution. The generative network's training objective is to increase the error rate of the discriminative network (i.e., \"fool\" the discriminator network by producing novel candidates that the discriminator thinks a",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "g novel candidates that the discriminator thinks are not synthesized (are part of the true data distribution)).\nA known dataset serves as the initial training data for the discriminator. Training involves presenting it with samples from the training dataset until it achieves acceptable accuracy. The generator is trained based on whether it succeeds in fooling the discriminator. Typically, the generator is seeded with randomized input that is sampled from a predefined latent space (e.g. a multiva",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "led from a predefined latent space (e.g. a multivariate normal distribution). Thereafter, candidates synthesized by the generator are evaluated by the discriminator. Independent backpropagation procedures are applied to both networks so that the generator produces better samples, while the discriminator becomes more skilled at flagging synthetic samples. When used for image generation, the generator is typically a deconvolutional neural network, and the discriminator is a convolutional neural ne",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "and the discriminator is a convolutional neural network.\n\n\n=== Relation to other statistical machine learning methods ===\nGANs are implicit generative models, which means that they do not explicitly model the likelihood function nor provide a means for finding the latent variable corresponding to a given sample, unlike alternatives such as flow-based generative model.\n\nCompared to fully visible belief networks such as WaveNet and PixelRNN and autoregressive models in general, GANs can generate o",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "oregressive models in general, GANs can generate one complete sample in one pass, rather than multiple passes through the network.\nCompared to Boltzmann machines and linear ICA, there is no restriction on the type of function used by the network.\nSince neural networks are universal approximators, GANs are asymptotically consistent. Variational autoencoders might be universal approximators, but it is not proven as of 2017.\n\n\n== Mathematical properties ==\n\n\n=== Measure-theoretic considerations ===",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "ties ==\n\n\n=== Measure-theoretic considerations ===\nThis section provides some of the mathematical theory behind these methods.\n\nIn modern probability theory based on measure theory, a probability space also needs to be equipped with a σ-algebra. As a result, a more rigorous definition of the GAN game would make the following changes:Each probability space \n  \n    \n      \n        (\n        Ω\n        ,\n        \n          \n            B\n          \n        \n        ,\n        \n          μ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ",\n        \n          μ\n          \n            ref\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega ,{\\mathcal {B}},\\mu _{\\text{ref}})}\n  \n defines a GAN game.\nThe generator's strategy set is \n  \n    \n      \n        \n          \n            P\n          \n        \n        (\n        Ω\n        ,\n        \n          \n            B\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\mathcal {P}}(\\Omega ,{\\mathcal {B}})}\n  \n, the set of all probability measur",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "hcal {B}})}\n  \n, the set of all probability measures \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n on the measure-space \n  \n    \n      \n        (\n        Ω\n        ,\n        \n          \n            B\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega ,{\\mathcal {B}})}\n  \n.\n\nThe discriminator's strategy set is the set of Markov kernels \n  \n    \n      \n        \n          μ\n          \n            D",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "μ\n          \n            D\n          \n        \n        :\n        (\n        Ω\n        ,\n        \n          \n            B\n          \n        \n        )\n        →\n        \n          \n            P\n          \n        \n        (\n        [\n        0\n        ,\n        1\n        ]\n        ,\n        \n          \n            B\n          \n        \n        (\n        [\n        0\n        ,\n        1\n        ]\n        )\n        )\n      \n    \n    {\\displaystyle \\mu _{D}:(\\Omega ,{\\mathcal {",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle \\mu _{D}:(\\Omega ,{\\mathcal {B}})\\to {\\mathcal {P}}([0,1],{\\mathcal {B}}([0,1]))}\n  \n, where \n  \n    \n      \n        \n          \n            B\n          \n        \n        (\n        [\n        0\n        ,\n        1\n        ]\n        )\n      \n    \n    {\\displaystyle {\\mathcal {B}}([0,1])}\n  \n is the Borel σ-algebra on \n  \n    \n      \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle [0,1]}\n  \n.Since issues of measurability never arise in practice,",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "e issues of measurability never arise in practice, these will not concern us further.\n\n\n=== Choice of the strategy set ===\nIn the most generic version of the GAN game described above, the strategy set for the discriminator contains all Markov kernels \n  \n    \n      \n        \n          μ\n          \n            D\n          \n        \n        :\n        Ω\n        →\n        \n          \n            P\n          \n        \n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle \\m",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "1\n        ]\n      \n    \n    {\\displaystyle \\mu _{D}:\\Omega \\to {\\mathcal {P}}[0,1]}\n  \n, and the strategy set for the generator contains arbitrary probability distributions \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n on \n  \n    \n      \n        Ω\n      \n    \n    {\\displaystyle \\Omega }\n  \n.\nHowever, as shown below, the optimal discriminator strategy against any \n  \n    \n      \n        \n          μ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n is deterministic, so there is no loss of generality in restricting the discriminator's strategies to deterministic functions \n  \n    \n      \n        D\n        :\n        Ω\n        →\n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle D:\\Omega \\to [0,1]}\n  \n. In most applications, \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "D\n      \n    \n    {\\displaystyle D}\n  \n is a deep neural network function.\nAs for the generator, while \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n could theoretically be any computable probability distribution, in practice, it is usually implemented as a pushforward: \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n        =\n        \n          μ\n          \n            Z",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "=\n        \n          μ\n          \n            Z\n          \n        \n        ∘\n        \n          G\n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}=\\mu _{Z}\\circ G^{-1}}\n  \n. That is, start with a random variable \n  \n    \n      \n        z\n        ∼\n        \n          μ\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle z\\sim \\mu _{Z}}\n  \n, where \n  \n    \n      \n        \n          μ\n          \n            Z",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "μ\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}}\n  \n is a probability distribution that is easy to compute (such as the uniform distribution, or the Gaussian distribution), then define a function \n  \n    \n      \n        G\n        :\n        \n          Ω\n          \n            Z\n          \n        \n        →\n        Ω\n      \n    \n    {\\displaystyle G:\\Omega _{Z}\\to \\Omega }\n  \n. Then the distribution \n  \n    \n      \n        \n          μ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n is the distribution of \n  \n    \n      \n        G\n        (\n        z\n        )\n      \n    \n    {\\displaystyle G(z)}\n  \n.\nConsequently, the generator's strategy is usually defined as just \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n, leaving \n  \n    \n      \n        z\n        ∼\n        \n          μ\n          \n            Z",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "Z\n          \n        \n      \n    \n    {\\displaystyle z\\sim \\mu _{Z}}\n  \n implicit. In this formalism, the GAN game objective is\n  \n    \n      \n        L\n        (\n        G\n        ,\n        D\n        )\n        :=\n        \n          E\n          \n            x\n            ∼\n            \n              μ\n              \n                ref\n              \n            \n          \n        \n        ⁡\n        [\n        ln\n        ⁡\n        D\n        (\n        x\n        )\n        ]",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "D\n        (\n        x\n        )\n        ]\n        +\n        \n          E\n          \n            z\n            ∼\n            \n              μ\n              \n                Z\n              \n            \n          \n        \n        ⁡\n        [\n        ln\n        ⁡\n        (\n        1\n        −\n        D\n        (\n        G\n        (\n        z\n        )\n        )\n        )\n        ]\n        .\n      \n    \n    {\\displaystyle L(G,D):=\\operatorname {E} _{x\\sim \\mu _{\\text{ref}}}[\\ln D(x)]+\\operatorn",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "E} _{x\\sim \\mu _{\\text{ref}}}[\\ln D(x)]+\\operatorname {E} _{z\\sim \\mu _{Z}}[\\ln(1-D(G(z)))].}\n  \n\n\n=== Generative reparametrization ===\nThe GAN architecture has two main components. One is casting optimization into a game, of form \n  \n    \n      \n        \n          min\n          \n            G\n          \n        \n        \n          max\n          \n            D\n          \n        \n        L\n        (\n        G\n        ,\n        D\n        )\n      \n    \n    {\\displaystyle \\min _{G}\\max _{D}L(G,D)}",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle \\min _{G}\\max _{D}L(G,D)}\n  \n, which is different from the usual kind of optimization, of form \n  \n    \n      \n        \n          min\n          \n            θ\n          \n        \n        L\n        (\n        θ\n        )\n      \n    \n    {\\displaystyle \\min _{\\theta }L(\\theta )}\n  \n. The other is the decomposition of \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n into",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "le \\mu _{G}}\n  \n into \n  \n    \n      \n        \n          μ\n          \n            Z\n          \n        \n        ∘\n        \n          G\n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}\\circ G^{-1}}\n  \n, which can be understood as a reparametrization trick.\nTo see its significance, one must compare GAN with previous methods for learning generative models, which were plagued with \"intractable probabilistic computations that arise in maximum likeliho",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "listic computations that arise in maximum likelihood estimation and related strategies\".\nAt the same time, Kingma and Welling and Rezende et al. developed the same idea of reparametrization into a general stochastic backpropagation method. Among its first applications was the variational autoencoder.\n\n\n=== Move order and strategic equilibria ===\nIn the original paper, as well as most subsequent papers, it is usually assumed that the generator moves first, and the discriminator moves second, thus",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "es first, and the discriminator moves second, thus giving the following minimax game:\n  \n    \n      \n        \n          min\n          \n            \n              μ\n              \n                G\n              \n            \n          \n        \n        \n          max\n          \n            \n              μ\n              \n                D\n              \n            \n          \n        \n        L\n        (\n        \n          μ\n          \n            G\n          \n        \n        ,",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "G\n          \n        \n        ,\n        \n          μ\n          \n            D\n          \n        \n        )\n        :=\n        \n          E\n          \n            x\n            ∼\n            \n              μ\n              \n                ref\n              \n            \n            ,\n            y\n            ∼\n            \n              μ\n              \n                D\n              \n            \n            (\n            x\n            )\n          \n        \n        ⁡\n        [\n        ln",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "⁡\n        [\n        ln\n        ⁡\n        y\n        ]\n        +\n        \n          E\n          \n            x\n            ∼\n            \n              μ\n              \n                G\n              \n            \n            ,\n            y\n            ∼\n            \n              μ\n              \n                D\n              \n            \n            (\n            x\n            )\n          \n        \n        ⁡\n        [\n        ln\n        ⁡\n        (\n        1",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "[\n        ln\n        ⁡\n        (\n        1\n        −\n        y\n        )\n        ]\n        .\n      \n    \n    {\\displaystyle \\min _{\\mu _{G}}\\max _{\\mu _{D}}L(\\mu _{G},\\mu _{D}):=\\operatorname {E} _{x\\sim \\mu _{\\text{ref}},y\\sim \\mu _{D}(x)}[\\ln y]+\\operatorname {E} _{x\\sim \\mu _{G},y\\sim \\mu _{D}(x)}[\\ln(1-y)].}\n  \n\nIf both the generator's and the discriminator's strategy sets are spanned by a finite number of strategies, then by the minimax theorem,\n  \n    \n      \n        \n          min",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "orem,\n  \n    \n      \n        \n          min\n          \n            \n              μ\n              \n                G\n              \n            \n          \n        \n        \n          max\n          \n            \n              μ\n              \n                D\n              \n            \n          \n        \n        L\n        (\n        \n          μ\n          \n            G\n          \n        \n        ,\n        \n          μ\n          \n            D\n          \n        \n        )\n        =",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ")\n        =\n        \n          max\n          \n            \n              μ\n              \n                D\n              \n            \n          \n        \n        \n          min\n          \n            \n              μ\n              \n                G\n              \n            \n          \n        \n        L\n        (\n        \n          μ\n          \n            G\n          \n        \n        ,\n        \n          μ\n          \n            D\n          \n        \n        )",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "D\n          \n        \n        )\n      \n    \n    {\\displaystyle \\min _{\\mu _{G}}\\max _{\\mu _{D}}L(\\mu _{G},\\mu _{D})=\\max _{\\mu _{D}}\\min _{\\mu _{G}}L(\\mu _{G},\\mu _{D})}\n  \nthat is, the move order does not matter.\nHowever, since the strategy sets are both not finitely spanned, the minimax theorem does not apply, and the idea of an \"equilibrium\" becomes delicate. To wit, there are the following different concepts of equilibrium:\n\nEquilibrium when generator moves first, and disc",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "Equilibrium when generator moves first, and discriminator moves second:\n  \n    \n      \n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        ∈\n        arg\n        ⁡\n        \n          min\n          \n            \n              μ\n              \n                G\n              \n            \n          \n        \n        \n          max\n          \n            \n              μ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "max\n          \n            \n              μ\n              \n                D\n              \n            \n          \n        \n        L\n        (\n        \n          μ\n          \n            G\n          \n        \n        ,\n        \n          μ\n          \n            D\n          \n        \n        )\n        ,\n        \n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            D\n          \n        \n        ∈",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "D\n          \n        \n        ∈\n        arg\n        ⁡\n        \n          max\n          \n            \n              μ\n              \n                D\n              \n            \n          \n        \n        L\n        (\n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        ,\n        \n          μ\n          \n            D\n          \n        \n        )\n        ,",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "D\n          \n        \n        )\n        ,\n        \n      \n    \n    {\\displaystyle {\\hat {\\mu }}_{G}\\in \\arg \\min _{\\mu _{G}}\\max _{\\mu _{D}}L(\\mu _{G},\\mu _{D}),\\quad {\\hat {\\mu }}_{D}\\in \\arg \\max _{\\mu _{D}}L({\\hat {\\mu }}_{G},\\mu _{D}),\\quad }\n  \n\nEquilibrium when discriminator moves first, and generator moves second:\n  \n    \n      \n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            D",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "D\n          \n        \n        ∈\n        arg\n        ⁡\n        \n          max\n          \n            \n              μ\n              \n                D\n              \n            \n          \n        \n        \n          min\n          \n            \n              μ\n              \n                G\n              \n            \n          \n        \n        L\n        (\n        \n          μ\n          \n            G\n          \n        \n        ,\n        \n          μ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ",\n        \n          μ\n          \n            D\n          \n        \n        )\n        ,\n        \n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        ∈\n        arg\n        ⁡\n        \n          min\n          \n            \n              μ\n              \n                G\n              \n            \n          \n        \n        L\n        (",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "L\n        (\n        \n          μ\n          \n            G\n          \n        \n        ,\n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            D\n          \n        \n        )\n        ,\n      \n    \n    {\\displaystyle {\\hat {\\mu }}_{D}\\in \\arg \\max _{\\mu _{D}}\\min _{\\mu _{G}}L(\\mu _{G},\\mu _{D}),\\quad {\\hat {\\mu }}_{G}\\in \\arg \\min _{\\mu _{G}}L(\\mu _{G},{\\hat {\\mu }}_{D}),}\n  \n\nNash eq",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "u _{G}}L(\\mu _{G},{\\hat {\\mu }}_{D}),}\n  \n\nNash equilibrium \n  \n    \n      \n        (\n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            D\n          \n        \n        ,\n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        )\n      \n    \n    {\\displaystyle ({\\hat {\\mu }}_{D},{\\hat {\\",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle ({\\hat {\\mu }}_{D},{\\hat {\\mu }}_{G})}\n  \n, which is stable under simultaneous move order:\n  \n    \n      \n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            D\n          \n        \n        ∈\n        arg\n        ⁡\n        \n          max\n          \n            \n              μ\n              \n                D\n              \n            \n          \n        \n        L\n        (",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "L\n        (\n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        ,\n        \n          μ\n          \n            D\n          \n        \n        )\n        ,\n        \n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        ∈",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "G\n          \n        \n        ∈\n        arg\n        ⁡\n        \n          min\n          \n            \n              μ\n              \n                G\n              \n            \n          \n        \n        L\n        (\n        \n          μ\n          \n            G\n          \n        \n        ,\n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            D\n          \n        \n        )",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "D\n          \n        \n        )\n      \n    \n    {\\displaystyle {\\hat {\\mu }}_{D}\\in \\arg \\max _{\\mu _{D}}L({\\hat {\\mu }}_{G},\\mu _{D}),\\quad {\\hat {\\mu }}_{G}\\in \\arg \\min _{\\mu _{G}}L(\\mu _{G},{\\hat {\\mu }}_{D})}\n  \n\nFor general games, these equilibria do not have to agree, or even to exist. For the original GAN game, these equilibria all exist, and are all equal. However, for more general GAN games, these do not necessarily exist, or agree.\n\n\n=== Main theorems for GAN game ===\nThe original G",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "=== Main theorems for GAN game ===\nThe original GAN paper proved the following two theorems:\nInterpretation: For any fixed generator strategy \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n, the optimal discriminator keeps track of the likelihood ratio between the reference distribution and the generator distribution:\n  \n    \n      \n        \n          \n            \n              D\n              (\n              x",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "D\n              (\n              x\n              )\n            \n            \n              1\n              −\n              D\n              (\n              x\n              )\n            \n          \n        \n        =\n        \n          \n            \n              d\n              \n                μ\n                \n                  ref\n                \n              \n            \n            \n              d\n              \n                μ\n                \n                  G",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "μ\n                \n                  G\n                \n              \n            \n          \n        \n        (\n        x\n        )\n        =\n        \n          \n            \n              \n                μ\n                \n                  ref\n                \n              \n              (\n              d\n              x\n              )\n            \n            \n              \n                μ\n                \n                  G\n                \n              \n              (",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "(\n              d\n              x\n              )\n            \n          \n        \n        ;\n        \n        D\n        (\n        x\n        )\n        =\n        σ\n        (\n        ln\n        ⁡\n        \n          μ\n          \n            ref\n          \n        \n        (\n        d\n        x\n        )\n        −\n        ln\n        ⁡\n        \n          μ\n          \n            G\n          \n        \n        (\n        d\n        x\n        )\n        )",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "d\n        x\n        )\n        )\n      \n    \n    {\\displaystyle {\\frac {D(x)}{1-D(x)}}={\\frac {d\\mu _{\\text{ref}}}{d\\mu _{G}}}(x)={\\frac {\\mu _{\\text{ref}}(dx)}{\\mu _{G}(dx)}};\\quad D(x)=\\sigma (\\ln \\mu _{\\text{ref}}(dx)-\\ln \\mu _{G}(dx))}\n  \nwhere \n  \n    \n      \n        σ\n      \n    \n    {\\displaystyle \\sigma }\n  \n is the logistic function.\nIn particular, if the prior probability for an image \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n to come from the reference distri",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "playstyle x}\n  \n to come from the reference distribution is equal to \n  \n    \n      \n        \n          \n            1\n            2\n          \n        \n      \n    \n    {\\displaystyle {\\frac {1}{2}}}\n  \n, then \n  \n    \n      \n        D\n        (\n        x\n        )\n      \n    \n    {\\displaystyle D(x)}\n  \n is just the posterior probability that \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n came from the reference distribution:\n  \n    \n      \n        D\n        (\n        x",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "D\n        (\n        x\n        )\n        =\n        Pr\n        (\n        x\n        \n           came from reference distribution\n        \n        ∣\n        x\n        )\n        .\n      \n    \n    {\\displaystyle D(x)=\\Pr(x{\\text{ came from reference distribution}}\\mid x).}\n  \n\n\n== Training and evaluating GAN ==\n\n\n=== Training ===\n\n\n==== Unstable convergence ====\nWhile the GAN game has a unique global equilibrium point when both the generator and discriminator have access to their",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "generator and discriminator have access to their entire strategy sets, the equilibrium is no longer guaranteed when they have a restricted strategy set.\nIn practice, the generator has access only to measures of form \n  \n    \n      \n        \n          μ\n          \n            Z\n          \n        \n        ∘\n        \n          G\n          \n            θ\n          \n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}\\circ G_{\\theta }^{-1}}\n  \n, where",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "style \\mu _{Z}\\circ G_{\\theta }^{-1}}\n  \n, where \n  \n    \n      \n        \n          G\n          \n            θ\n          \n        \n      \n    \n    {\\displaystyle G_{\\theta }}\n  \n is a function computed by a neural network with parameters \n  \n    \n      \n        θ\n      \n    \n    {\\displaystyle \\theta }\n  \n, and \n  \n    \n      \n        \n          μ\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}}\n  \n is an easily sampled distribution, such as the uniform or no",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "ly sampled distribution, such as the uniform or normal distribution. Similarly, the discriminator has access only to functions of form \n  \n    \n      \n        \n          D\n          \n            ζ\n          \n        \n      \n    \n    {\\displaystyle D_{\\zeta }}\n  \n, a function computed by a neural network with parameters \n  \n    \n      \n        ζ\n      \n    \n    {\\displaystyle \\zeta }\n  \n. These restricted strategy sets take up a vanishingly small proportion of their entire strategy sets.\nFurther,",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "proportion of their entire strategy sets.\nFurther, even if an equilibrium still exists, it can only be found by searching in the high-dimensional space of all possible neural network functions. The standard strategy of using gradient descent to find the equilibrium often does not work for GAN, and often the game \"collapses\" into one of several failure modes. To improve the convergence stability, some training strategies start with an easier task, such as generating low-resolution images or simpl",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "such as generating low-resolution images or simple images (one object with uniform background), and gradually increase the difficulty of the task during training. This essentially translates to applying a curriculum learning scheme.\n\n\n==== Mode collapse ====\n\nGANs often suffer from mode collapse where they fail to generalize properly, missing entire modes from the input data. For example, a GAN trained on the MNIST dataset containing many samples of each digit might only generate pictures of di",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "s of each digit might only generate pictures of digit 0. This was termed \"the Helvetica scenario\".\nOne way this can happen is if the generator learns too fast compared to the discriminator. If the discriminator \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n is held constant, then the optimal generator would only output elements of \n  \n    \n      \n        arg\n        ⁡\n        \n          max\n          \n            x\n          \n        \n        D\n        (\n        x\n        )",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "D\n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\arg \\max _{x}D(x)}\n  \n. So for example, if during GAN training for generating MNIST dataset, for a few epochs, the discriminator somehow prefers the digit 0 slightly more than other digits, the generator may seize the opportunity to generate only digit 0, then be unable to escape the local minimum after the discriminator improves.\nSome researchers perceive the root problem to be a weak discriminative network that fails",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "lem to be a weak discriminative network that fails to notice the pattern of omission, while others assign blame to a bad choice of objective function. Many solutions have been proposed, but it is still an open problem.\nEven the state-of-the-art architecture, BigGAN (2019), could not avoid mode collapse. The authors resorted to \"allowing collapse to occur at the later stages of training, by which time a model is sufficiently trained to achieve good results\".\n\n\n==== Two time-scale update rule ====",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "d results\".\n\n\n==== Two time-scale update rule ====\nThe two time-scale update rule (TTUR) is proposed to make GAN convergence more stable by making the learning rate of the generator lower than that of the discriminator. The authors argued that the generator should move slower than the discriminator, so that it does not \"drive the discriminator steadily into new regions without capturing its gathered information\".\nThey proved that a general class of games that included the GAN game, when trained",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "of games that included the GAN game, when trained under TTUR, \"converges under mild assumptions to a stationary local Nash equilibrium\".\nThey also proposed using the Adam stochastic optimization to avoid mode collapse, as well as the Fréchet inception distance for evaluating GAN performances.\n\n\n==== Vanishing gradient ====\nConversely, if the discriminator learns too fast compared to the generator, then the discriminator could almost perfectly distinguish \n  \n    \n      \n        \n          μ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "tinguish \n  \n    \n      \n        \n          μ\n          \n            \n              G\n              \n                θ\n              \n            \n          \n        \n        ,\n        \n          μ\n          \n            ref\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G_{\\theta }},\\mu _{\\text{ref}}}\n  \n. In such case, the generator \n  \n    \n      \n        \n          G\n          \n            θ\n          \n        \n      \n    \n    {\\displaystyle G_{\\theta }}\n  \n could be stuck with a v",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "playstyle G_{\\theta }}\n  \n could be stuck with a very high loss no matter which direction it changes its \n  \n    \n      \n        θ\n      \n    \n    {\\displaystyle \\theta }\n  \n, meaning that the gradient \n  \n    \n      \n        \n          ∇\n          \n            θ\n          \n        \n        L\n        (\n        \n          G\n          \n            θ\n          \n        \n        ,\n        \n          D\n          \n            ζ\n          \n        \n        )\n      \n    \n    {\\displaystyle \\nabla _{\\the",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ")\n      \n    \n    {\\displaystyle \\nabla _{\\theta }L(G_{\\theta },D_{\\zeta })}\n  \n would be close to zero. In such case, the generator cannot learn, a case of the vanishing gradient problem.\nIntuitively speaking, the discriminator is too good, and since the generator cannot take any small step (only small steps are considered in gradient descent) to improve its payoff, it does not even try.\nOne important method for solving this problem is the Wasserstein GAN.\n\n\n=== Evaluation ===\nGANs are usua",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "asserstein GAN.\n\n\n=== Evaluation ===\nGANs are usually evaluated by Inception score (IS), which measures how varied the generator's outputs are (as classified by an image classifier, usually Inception-v3), or Fréchet inception distance (FID), which measures how similar the generator's outputs are to a reference set (as classified by a learned image featurizer, such as Inception-v3 without its final layer). Many papers that propose new GAN architectures for image generation report how their archit",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "tures for image generation report how their architectures break the state of the art on FID or IS.\nAnother evaluation method is the Learned Perceptual Image Patch Similarity (LPIPS), which starts with a learned image featurizer \n  \n    \n      \n        \n          f\n          \n            θ\n          \n        \n        :\n        \n          Image\n        \n        →\n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle f_{\\theta }:{\\t",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle f_{\\theta }:{\\text{Image}}\\to \\mathbb {R} ^{n}}\n  \n, and finetunes it by supervised learning on a set of \n  \n    \n      \n        (\n        x\n        ,\n        \n          x\n          ′\n        \n        ,\n        \n          p\n          e\n          r\n          c\n          e\n          p\n          t\n          u\n          a\n          l\n           \n          d\n          i\n          f\n          f\n          e\n          r\n          e\n          n\n          c\n          e",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "e\n          n\n          c\n          e\n        \n        ⁡\n        (\n        x\n        ,\n        \n          x\n          ′\n        \n        )\n        )\n      \n    \n    {\\displaystyle (x,x',\\operatorname {perceptual~difference} (x,x'))}\n  \n, where \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n is an image, \n  \n    \n      \n        \n          x\n          ′\n        \n      \n    \n    {\\displaystyle x'}\n  \n is a perturbed version of it, and \n  \n    \n      \n        \n          p",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "n of it, and \n  \n    \n      \n        \n          p\n          e\n          r\n          c\n          e\n          p\n          t\n          u\n          a\n          l\n           \n          d\n          i\n          f\n          f\n          e\n          r\n          e\n          n\n          c\n          e\n        \n        ⁡\n        (\n        x\n        ,\n        \n          x\n          ′\n        \n        )\n      \n    \n    {\\displaystyle \\operatorname {perceptual~difference} (x,x')}\n  \n is how much they differ, as",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "fference} (x,x')}\n  \n is how much they differ, as reported by human subjects. The model is finetuned so that it can approximate \n  \n    \n      \n        ‖\n        \n          f\n          \n            θ\n          \n        \n        (\n        x\n        )\n        −\n        \n          f\n          \n            θ\n          \n        \n        (\n        \n          x\n          ′\n        \n        )\n        ‖\n        ≈\n        \n          p\n          e\n          r\n          c\n          e\n          p\n          t",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "r\n          c\n          e\n          p\n          t\n          u\n          a\n          l\n           \n          d\n          i\n          f\n          f\n          e\n          r\n          e\n          n\n          c\n          e\n        \n        ⁡\n        (\n        x\n        ,\n        \n          x\n          ′\n        \n        )\n      \n    \n    {\\displaystyle \\|f_{\\theta }(x)-f_{\\theta }(x')\\|\\approx \\operatorname {perceptual~difference} (x,x')}\n  \n. This finetuned model is then used to define",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "inetuned model is then used to define \n  \n    \n      \n        LPIPS\n        ⁡\n        (\n        x\n        ,\n        \n          x\n          ′\n        \n        )\n        :=\n        ‖\n        \n          f\n          \n            θ\n          \n        \n        (\n        x\n        )\n        −\n        \n          f\n          \n            θ\n          \n        \n        (\n        \n          x\n          ′\n        \n        )\n        ‖\n      \n    \n    {\\displaystyle \\operatorname {LPIPS} (x,x'):=\\|f_{\\theta }(",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "style \\operatorname {LPIPS} (x,x'):=\\|f_{\\theta }(x)-f_{\\theta }(x')\\|}\n  \n.\nOther evaluation methods are reviewed in.\n\n\n== Variants ==\nThere is a veritable zoo of GAN variants. Some of the most prominent are as follows:\n\n\n=== Conditional GAN ===\nConditional GANs are similar to standard GANs except they allow the model to conditionally generate samples based on additional information. For example, if we want to generate a cat face given a dog picture, we could use a conditional GAN.\nThe generato",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "ture, we could use a conditional GAN.\nThe generator in a GAN game generates \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n      \n    \n    {\\displaystyle \\mu _{G}}\n  \n, a probability distribution on the probability space \n  \n    \n      \n        Ω\n      \n    \n    {\\displaystyle \\Omega }\n  \n. This leads to the idea of a conditional GAN, where instead of generating one probability distribution on \n  \n    \n      \n        Ω\n      \n    \n    {\\displaystyle \\Omega }",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "Ω\n      \n    \n    {\\displaystyle \\Omega }\n  \n, the generator generates a different probability distribution \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n        (\n        c\n        )\n      \n    \n    {\\displaystyle \\mu _{G}(c)}\n  \n on \n  \n    \n      \n        Ω\n      \n    \n    {\\displaystyle \\Omega }\n  \n, for each given class label \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n.\nFor example, for generating images that look like ImageNet,",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "e, for generating images that look like ImageNet, the generator should be able to generate a picture of cat when given the class label \"cat\".\nIn the original paper, the authors noted that GAN can be trivially extended to conditional GAN by providing the labels to both the generator and the discriminator.\nConcretely, the conditional GAN game is just the GAN game with class labels provided:\n  \n    \n      \n        L\n        (\n        \n          μ\n          \n            G",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "G\n          \n        \n        ,\n        D\n        )\n        :=\n        \n          E\n          \n            c\n            ∼\n            \n              μ\n              \n                C\n              \n            \n            ,\n            x\n            ∼\n            \n              μ\n              \n                ref\n              \n            \n            (\n            c\n            )\n          \n        \n        ⁡\n        [\n        ln\n        ⁡\n        D\n        (\n        x",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "ln\n        ⁡\n        D\n        (\n        x\n        ,\n        c\n        )\n        ]\n        +\n        \n          E\n          \n            c\n            ∼\n            \n              μ\n              \n                C\n              \n            \n            ,\n            x\n            ∼\n            \n              μ\n              \n                G\n              \n            \n            (\n            c\n            )\n          \n        \n        ⁡\n        [\n        ln\n        ⁡\n        (",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "⁡\n        [\n        ln\n        ⁡\n        (\n        1\n        −\n        D\n        (\n        x\n        ,\n        c\n        )\n        )\n        ]\n      \n    \n    {\\displaystyle L(\\mu _{G},D):=\\operatorname {E} _{c\\sim \\mu _{C},x\\sim \\mu _{\\text{ref}}(c)}[\\ln D(x,c)]+\\operatorname {E} _{c\\sim \\mu _{C},x\\sim \\mu _{G}(c)}[\\ln(1-D(x,c))]}\n  \nwhere \n  \n    \n      \n        \n          μ\n          \n            C\n          \n        \n      \n    \n    {\\displaystyle \\mu _{C}}\n  \n is a probability distributi",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "laystyle \\mu _{C}}\n  \n is a probability distribution over classes, \n  \n    \n      \n        \n          μ\n          \n            ref\n          \n        \n        (\n        c\n        )\n      \n    \n    {\\displaystyle \\mu _{\\text{ref}}(c)}\n  \n is the probability distribution of real images of class \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n, and \n  \n    \n      \n        \n          μ\n          \n            G\n          \n        \n        (\n        c\n        )\n      \n    \n    {\\display",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "(\n        c\n        )\n      \n    \n    {\\displaystyle \\mu _{G}(c)}\n  \n the probability distribution of images generated by the generator when given class label \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n.\nIn 2017, a conditional GAN learned to generate 1000 image classes of ImageNet.\n\n\n=== GANs with alternative architectures ===\nThe GAN game is a general framework and can be run with any reasonable parametrization of the generator \n  \n    \n      \n        G\n      \n    \n    {\\",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "rator \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n and discriminator \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n. In the original paper, the authors demonstrated it using multilayer perceptron networks and convolutional neural networks. Many alternative architectures have been tried.\nDeep convolutional GAN (DCGAN): For both generator and discriminator, uses only deep networks consisting entirely of convolution-deconvolution layers, that is, fully convolutio",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "on-deconvolution layers, that is, fully convolutional networks.\nSelf-attention GAN (SAGAN): Starts with the DCGAN, then adds residually-connected standard self-attention modules to the generator and discriminator.\nVariational autoencoder GAN (VAEGAN): Uses a variational autoencoder (VAE) for the generator.\nTransformer GAN (TransGAN): Uses the pure transformer architecture for both the generator and discriminator, entirely devoid of convolution-deconvolution layers.\nFlow-GAN: Uses flow-based gene",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "convolution layers.\nFlow-GAN: Uses flow-based generative model for the generator, allowing efficient computation of the likelihood function.\n\n\n=== GANs with alternative objectives ===\nMany GAN variants are merely obtained by changing the loss functions for the generator and discriminator.\nOriginal GAN:\nWe recast the original GAN objective into a form more convenient for comparison:\n  \n    \n      \n        \n          \n            {",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "min\n                    \n                      D\n                    \n                  \n                  \n                    L\n                    \n                      D\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    μ\n                    \n                      G\n                    \n                  \n                  )",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ")\n                  =\n                  −\n                  \n                    E\n                    \n                      x\n                      ∼\n                      \n                        μ\n                        \n                          G\n                        \n                      \n                    \n                  \n                  ⁡\n                  [\n                  ln\n                  ⁡\n                  D\n                  (",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "⁡\n                  D\n                  (\n                  x\n                  )\n                  ]\n                  −\n                  \n                    E\n                    \n                      x\n                      ∼\n                      \n                        μ\n                        \n                          ref\n                        \n                      \n                    \n                  \n                  ⁡\n                  [\n                  ln",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "⁡\n                  [\n                  ln\n                  ⁡\n                  (\n                  1\n                  −\n                  D\n                  (\n                  x\n                  )\n                  )\n                  ]\n                \n              \n              \n                \n                  \n                    min\n                    \n                      G\n                    \n                  \n                  \n                    L",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "L\n                    \n                      G\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    μ\n                    \n                      G\n                    \n                  \n                  )\n                  =\n                  −\n                  \n                    E\n                    \n                      x\n                      ∼",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "∼\n                      \n                        μ\n                        \n                          G\n                        \n                      \n                    \n                  \n                  ⁡\n                  [\n                  ln\n                  ⁡\n                  (\n                  1\n                  −\n                  D\n                  (\n                  x\n                  )\n                  )\n                  ]",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "]\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{cases}\\min _{D}L_{D}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{G}}[\\ln D(x)]-\\operatorname {E} _{x\\sim \\mu _{\\text{ref}}}[\\ln(1-D(x))]\\\\\\min _{G}L_{G}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{G}}[\\ln(1-D(x))]\\end{cases}}}\n  \n\nOriginal GAN, non-saturating loss:\nThis objective for generator was recommended in the original paper for faster convergence.",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "the original paper for faster convergence.\n  \n    \n      \n        \n          L\n          \n            G\n          \n        \n        =\n        \n          E\n          \n            x\n            ∼\n            \n              μ\n              \n                G\n              \n            \n          \n        \n        ⁡\n        [\n        ln\n        ⁡\n        D\n        (\n        x\n        )\n        ]\n      \n    \n    {\\displaystyle L_{G}=\\operatorname {E} _{x\\sim \\mu _{G}}[\\ln D(x)]}\n  \nThe effect of usi",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "_{x\\sim \\mu _{G}}[\\ln D(x)]}\n  \nThe effect of using this objective is analyzed in Section 2.2.2 of Arjovsky et al.\nOriginal GAN, maximum likelihood:\n\n  \n    \n      \n        \n          L\n          \n            G\n          \n        \n        =\n        \n          E\n          \n            x\n            ∼\n            \n              μ\n              \n                G\n              \n            \n          \n        \n        ⁡\n        [\n        (\n        \n          exp\n        \n        ∘",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "exp\n        \n        ∘\n        \n          σ\n          \n            −\n            1\n          \n        \n        ∘\n        D\n        )\n        (\n        x\n        )\n        ]\n      \n    \n    {\\displaystyle L_{G}=\\operatorname {E} _{x\\sim \\mu _{G}}[({\\exp }\\circ \\sigma ^{-1}\\circ D)(x)]}\n  \nwhere \n  \n    \n      \n        σ\n      \n    \n    {\\displaystyle \\sigma }\n  \n is the logistic function. When the discriminator is optimal, the generator gradient is the same as in maximum likelihood est",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "gradient is the same as in maximum likelihood estimation, even though GAN cannot perform maximum likelihood estimation itself.\nHinge loss GAN:\n  \n    \n      \n        \n          L\n          \n            D\n          \n        \n        =\n        −\n        \n          E\n          \n            x\n            ∼\n            \n              p\n              \n                ref\n              \n            \n          \n        \n        ⁡\n        \n          [\n          \n            min",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "min\n            \n              (\n              \n                0\n                ,\n                −\n                1\n                +\n                D\n                (\n                x\n                )\n              \n              )\n            \n          \n          ]\n        \n        −\n        \n          E\n          \n            x\n            ∼\n            \n              μ\n              \n                G\n              \n            \n          \n        \n        ⁡",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "⁡\n        \n          [\n          \n            min\n            \n              (\n              \n                0\n                ,\n                −\n                1\n                −\n                D\n                \n                  (\n                  x\n                  )\n                \n              \n              )\n            \n          \n          ]\n        \n      \n    \n    {\\displaystyle L_{D}=-\\operatorname {E} _{x\\sim p_{\\text{ref}}}\\lef",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{D}=-\\operatorname {E} _{x\\sim p_{\\text{ref}}}\\left[\\min \\left(0,-1+D(x)\\right)\\right]-\\operatorname {E} _{x\\sim \\mu _{G}}\\left[\\min \\left(0,-1-D\\left(x\\right)\\right)\\right]}\n  \n\n  \n    \n      \n        \n          L\n          \n            G\n          \n        \n        =\n        −\n        \n          E\n          \n            x\n            ∼\n            \n              μ\n              \n                G\n              \n            \n          \n        \n        ⁡\n        [\n        D\n        (\n        x",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "⁡\n        [\n        D\n        (\n        x\n        )\n        ]\n      \n    \n    {\\displaystyle L_{G}=-\\operatorname {E} _{x\\sim \\mu _{G}}[D(x)]}\n  \nLeast squares GAN:\n  \n    \n      \n        \n          L\n          \n            D\n          \n        \n        =\n        \n          E\n          \n            x\n            ∼\n            \n              μ\n              \n                ref\n              \n            \n          \n        \n        ⁡\n        [\n        (\n        D\n        (\n        x",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "[\n        (\n        D\n        (\n        x\n        )\n        −\n        b\n        \n          )\n          \n            2\n          \n        \n        ]\n        +\n        \n          E\n          \n            x\n            ∼\n            \n              μ\n              \n                G\n              \n            \n          \n        \n        ⁡\n        [\n        (\n        D\n        (\n        x\n        )\n        −\n        a\n        \n          )\n          \n            2\n          \n        \n        ]",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "2\n          \n        \n        ]\n      \n    \n    {\\displaystyle L_{D}=\\operatorname {E} _{x\\sim \\mu _{\\text{ref}}}[(D(x)-b)^{2}]+\\operatorname {E} _{x\\sim \\mu _{G}}[(D(x)-a)^{2}]}\n  \n\n  \n    \n      \n        \n          L\n          \n            G\n          \n        \n        =\n        \n          E\n          \n            x\n            ∼\n            \n              μ\n              \n                G\n              \n            \n          \n        \n        ⁡\n        [\n        (\n        D",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "⁡\n        [\n        (\n        D\n        (\n        x\n        )\n        −\n        c\n        \n          )\n          \n            2\n          \n        \n        ]\n      \n    \n    {\\displaystyle L_{G}=\\operatorname {E} _{x\\sim \\mu _{G}}[(D(x)-c)^{2}]}\n  \nwhere \n  \n    \n      \n        a\n        ,\n        b\n        ,\n        c\n      \n    \n    {\\displaystyle a,b,c}\n  \n are parameters to be chosen. The authors recommended \n  \n    \n      \n        a\n        =\n        −\n        1\n        ,",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "a\n        =\n        −\n        1\n        ,\n        b\n        =\n        1\n        ,\n        c\n        =\n        0\n      \n    \n    {\\displaystyle a=-1,b=1,c=0}\n  \n.\n\n\n=== Wasserstein GAN (WGAN) ===\n\nThe Wasserstein GAN modifies the GAN game at two points:\n\nThe discriminator's strategy set is the set of measurable functions of type \n  \n    \n      \n        D\n        :\n        Ω\n        →\n        \n          R\n        \n      \n    \n    {\\displaystyle D:\\Omega \\to \\mathbb {R} }\n  \n with bounded L",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "tyle D:\\Omega \\to \\mathbb {R} }\n  \n with bounded Lipschitz norm: \n  \n    \n      \n        ‖\n        D\n        \n          ‖\n          \n            L\n          \n        \n        ≤\n        K\n      \n    \n    {\\displaystyle \\|D\\|_{L}\\leq K}\n  \n, where \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n is a fixed positive constant.\nThe objective is\n  \n    \n      \n        \n          L\n          \n            W\n            G\n            A\n            N\n          \n        \n        (",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "N\n          \n        \n        (\n        \n          μ\n          \n            G\n          \n        \n        ,\n        D\n        )\n        :=\n        \n          E\n          \n            x\n            ∼\n            \n              μ\n              \n                G\n              \n            \n          \n        \n        ⁡\n        [\n        D\n        (\n        x\n        )\n        ]\n        −\n        \n          \n            E\n          \n          \n            x\n            ∼",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "x\n            ∼\n            \n              μ\n              \n                ref\n              \n            \n          \n        \n        [\n        D\n        (\n        x\n        )\n        ]\n      \n    \n    {\\displaystyle L_{WGAN}(\\mu _{G},D):=\\operatorname {E} _{x\\sim \\mu _{G}}[D(x)]-\\mathbb {E} _{x\\sim \\mu _{\\text{ref}}}[D(x)]}\n  \n\nOne of its purposes is to solve the problem of mode collapse (see above). The authors claim \"In no experiment did we see evidence of mode collapse for t",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "eriment did we see evidence of mode collapse for the WGAN algorithm\".\n\n\n=== GANs with more than two players ===\n\n\n==== Adversarial autoencoder ====\nAn adversarial autoencoder (AAE) is more autoencoder than GAN. The idea is to start with a plain autoencoder, but train a discriminator to discriminate the latent vectors from a reference distribution (often the normal distribution).\n\n\n==== InfoGAN ====\nIn conditional GAN, the generator receives both a noise vector \n  \n    \n      \n        z",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "a noise vector \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n and a label \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n, and produces an image \n  \n    \n      \n        G\n        (\n        z\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle G(z,c)}\n  \n. The discriminator receives image-label pairs \n  \n    \n      \n        (\n        x\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle (x,c)}\n  \n, and computes \n  \n    \n      \n        D\n        (",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ", and computes \n  \n    \n      \n        D\n        (\n        x\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle D(x,c)}\n  \n.\nWhen the training dataset is unlabeled, conditional GAN does not work directly.\nThe idea of InfoGAN is to decree that every latent vector in the latent space can be decomposed as \n  \n    \n      \n        (\n        z\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle (z,c)}\n  \n: an incompressible noise part \n  \n    \n      \n        z\n      \n    \n    {\\disp",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "t \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n, and an informative label part \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n, and encourage the generator to comply with the decree, by encouraging it to maximize \n  \n    \n      \n        I\n        (\n        c\n        ,\n        G\n        (\n        z\n        ,\n        c\n        )\n        )\n      \n    \n    {\\displaystyle I(c,G(z,c))}\n  \n, the mutual information between \n  \n    \n      \n        c\n      \n    \n    {\\dis",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "en \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n and \n  \n    \n      \n        G\n        (\n        z\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle G(z,c)}\n  \n, while making no demands on the mutual information \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n between \n  \n    \n      \n        G\n        (\n        z\n        ,\n        c\n        )\n      \n    \n    {\\displaystyle G(z,c)}\n  \n.\nUnfortunately, \n  \n    \n      \n        I\n        (\n        c",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "I\n        (\n        c\n        ,\n        G\n        (\n        z\n        ,\n        c\n        )\n        )\n      \n    \n    {\\displaystyle I(c,G(z,c))}\n  \n is intractable in general, The key idea of InfoGAN is Variational Mutual Information Maximization: indirectly maximize it by maximizing a lower bound\n  \n    \n      \n        \n          \n            \n              I\n              ^\n            \n          \n        \n        (\n        G\n        ,\n        Q\n        )\n        =",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "G\n        ,\n        Q\n        )\n        =\n        \n          \n            E\n          \n          \n            z\n            ∼\n            \n              μ\n              \n                Z\n              \n            \n            ,\n            c\n            ∼\n            \n              μ\n              \n                C\n              \n            \n          \n        \n        [\n        ln\n        ⁡\n        Q\n        (\n        c\n        ∣\n        G\n        (\n        z\n        ,\n        c",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "G\n        (\n        z\n        ,\n        c\n        )\n        )\n        ]\n        ;\n        \n        I\n        (\n        c\n        ,\n        G\n        (\n        z\n        ,\n        c\n        )\n        )\n        ≥\n        \n          sup\n          \n            Q\n          \n        \n        \n          \n            \n              I\n              ^\n            \n          \n        \n        (\n        G\n        ,\n        Q\n        )\n      \n    \n    {\\displaystyle {\\hat {I}}(G,Q)=\\mathbb {E} _{z\\sim \\mu _{",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "aystyle {\\hat {I}}(G,Q)=\\mathbb {E} _{z\\sim \\mu _{Z},c\\sim \\mu _{C}}[\\ln Q(c\\mid G(z,c))];\\quad I(c,G(z,c))\\geq \\sup _{Q}{\\hat {I}}(G,Q)}\n  \nwhere \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  \n ranges over all Markov kernels of type \n  \n    \n      \n        Q\n        :\n        \n          Ω\n          \n            Y\n          \n        \n        →\n        \n          \n            P\n          \n        \n        (\n        \n          Ω\n          \n            C",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "C\n          \n        \n        )\n      \n    \n    {\\displaystyle Q:\\Omega _{Y}\\to {\\mathcal {P}}(\\Omega _{C})}\n  \n.\n\nThe InfoGAN game is defined as follows:Three probability spaces define an InfoGAN game:\n\n  \n    \n      \n        (\n        \n          Ω\n          \n            X\n          \n        \n        ,\n        \n          μ\n          \n            ref\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{X},\\mu _{\\text{ref}})}\n  \n, the space of reference image",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "_{\\text{ref}})}\n  \n, the space of reference images.\n\n  \n    \n      \n        (\n        \n          Ω\n          \n            Z\n          \n        \n        ,\n        \n          μ\n          \n            Z\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{Z},\\mu _{Z})}\n  \n, the fixed random noise generator.\n\n  \n    \n      \n        (\n        \n          Ω\n          \n            C\n          \n        \n        ,\n        \n          μ\n          \n            C",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "C\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{C},\\mu _{C})}\n  \n, the fixed random information generator.\nThere are 3 players in 2 teams: generator, Q, and discriminator. The generator and Q are on one team, and the discriminator on the other team.\nThe objective function is\n  \n    \n      \n        L\n        (\n        G\n        ,\n        Q\n        ,\n        D\n        )\n        =\n        \n          L\n          \n            G\n            A\n            N",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "G\n            A\n            N\n          \n        \n        (\n        G\n        ,\n        D\n        )\n        −\n        λ\n        \n          \n            \n              I\n              ^\n            \n          \n        \n        (\n        G\n        ,\n        Q\n        )\n      \n    \n    {\\displaystyle L(G,Q,D)=L_{GAN}(G,D)-\\lambda {\\hat {I}}(G,Q)}\n  \nwhere \n  \n    \n      \n        \n          L\n          \n            G\n            A\n            N\n          \n        \n        (",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "A\n            N\n          \n        \n        (\n        G\n        ,\n        D\n        )\n        =\n        \n          E\n          \n            x\n            ∼\n            \n              μ\n              \n                ref\n              \n            \n            ,\n          \n        \n        ⁡\n        [\n        ln\n        ⁡\n        D\n        (\n        x\n        )\n        ]\n        +\n        \n          E\n          \n            z\n            ∼\n            \n              μ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "μ\n              \n                Z\n              \n            \n          \n        \n        ⁡\n        [\n        ln\n        ⁡\n        (\n        1\n        −\n        D\n        (\n        G\n        (\n        z\n        ,\n        c\n        )\n        )\n        )\n        ]\n      \n    \n    {\\displaystyle L_{GAN}(G,D)=\\operatorname {E} _{x\\sim \\mu _{\\text{ref}},}[\\ln D(x)]+\\operatorname {E} _{z\\sim \\mu _{Z}}[\\ln(1-D(G(z,c)))]}\n  \n is the original GAN game objective, and",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "original GAN game objective, and \n  \n    \n      \n        \n          \n            \n              I\n              ^\n            \n          \n        \n        (\n        G\n        ,\n        Q\n        )\n        =\n        \n          \n            E\n          \n          \n            z\n            ∼\n            \n              μ\n              \n                Z\n              \n            \n            ,\n            c\n            ∼\n            \n              μ\n              \n                C",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "μ\n              \n                C\n              \n            \n          \n        \n        [\n        ln\n        ⁡\n        Q\n        (\n        c\n        ∣\n        G\n        (\n        z\n        ,\n        c\n        )\n        )\n        ]\n      \n    \n    {\\displaystyle {\\hat {I}}(G,Q)=\\mathbb {E} _{z\\sim \\mu _{Z},c\\sim \\mu _{C}}[\\ln Q(c\\mid G(z,c))]}\n  \n\nGenerator-Q team aims to minimize the objective, and discriminator aims to maximize it:\n  \n    \n      \n        \n          min",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "min\n          \n            G\n            ,\n            Q\n          \n        \n        \n          max\n          \n            D\n          \n        \n        L\n        (\n        G\n        ,\n        Q\n        ,\n        D\n        )\n      \n    \n    {\\displaystyle \\min _{G,Q}\\max _{D}L(G,Q,D)}\n  \n\n\n==== Bidirectional GAN (BiGAN) ====\nThe standard GAN generator is a function of type \n  \n    \n      \n        G\n        :\n        \n          Ω\n          \n            Z",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "Ω\n          \n            Z\n          \n        \n        →\n        \n          Ω\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle G:\\Omega _{Z}\\to \\Omega _{X}}\n  \n, that is, it is a mapping from a latent space \n  \n    \n      \n        \n          Ω\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\Omega _{Z}}\n  \n to the image space \n  \n    \n      \n        \n          Ω\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle \\Omega _{X}}\n  \n. This can be understood as a \"decoding\" process, whereby every latent vector \n  \n    \n      \n        z\n        ∈\n        \n          Ω\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle z\\in \\Omega _{Z}}\n  \n is a code for an image \n  \n    \n      \n        x\n        ∈\n        \n          Ω\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle x\\in \\Omega _{X}}\n  \n, and the generator per",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "style x\\in \\Omega _{X}}\n  \n, and the generator performs the decoding. This naturally leads to the idea of training another network that performs \"encoding\", creating an autoencoder out of the encoder-generator pair.\nAlready in the original paper, the authors noted that \"Learned approximate inference can be performed by training an auxiliary network to predict \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n given \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n\". Th",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "x\n      \n    \n    {\\displaystyle x}\n  \n\". The bidirectional GAN architecture performs exactly this.\n\nThe BiGAN is defined as follows: Two probability spaces define a BiGAN game:\n\n  \n    \n      \n        (\n        \n          Ω\n          \n            X\n          \n        \n        ,\n        \n          μ\n          \n            X\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{X},\\mu _{X})}\n  \n, the space of reference images.\n\n  \n    \n      \n        (\n        \n          Ω",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "s.\n\n  \n    \n      \n        (\n        \n          Ω\n          \n            Z\n          \n        \n        ,\n        \n          μ\n          \n            Z\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{Z},\\mu _{Z})}\n  \n, the latent space.\nThere are 3 players in 2 teams: generator, encoder, and discriminator. The generator and encoder are on one team, and the discriminator on the other team.\nThe generator's strategies are functions \n  \n    \n      \n        G\n        :",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "ions \n  \n    \n      \n        G\n        :\n        \n          Ω\n          \n            Z\n          \n        \n        →\n        \n          Ω\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle G:\\Omega _{Z}\\to \\Omega _{X}}\n  \n, and the encoder's strategies are functions \n  \n    \n      \n        E\n        :\n        \n          Ω\n          \n            X\n          \n        \n        →\n        \n          Ω\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle E:\\Omega _{X}\\to \\Omega _{Z}}\n  \n. The discriminator's strategies are functions \n  \n    \n      \n        D\n        :\n        \n          Ω\n          \n            X\n          \n        \n        →\n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle D:\\Omega _{X}\\to [0,1]}\n  \n.\nThe objective function is\n  \n    \n      \n        L\n        (\n        G\n        ,\n        E\n        ,\n        D\n        )\n        =",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ",\n        D\n        )\n        =\n        \n          \n            E\n          \n          \n            x\n            ∼\n            \n              μ\n              \n                X\n              \n            \n          \n        \n        [\n        ln\n        ⁡\n        D\n        (\n        x\n        ,\n        E\n        (\n        x\n        )\n        )\n        ]\n        +\n        \n          \n            E\n          \n          \n            z\n            ∼\n            \n              μ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "∼\n            \n              μ\n              \n                Z\n              \n            \n          \n        \n        [\n        ln\n        ⁡\n        (\n        1\n        −\n        D\n        (\n        G\n        (\n        z\n        )\n        ,\n        z\n        )\n        )\n        ]\n      \n    \n    {\\displaystyle L(G,E,D)=\\mathbb {E} _{x\\sim \\mu _{X}}[\\ln D(x,E(x))]+\\mathbb {E} _{z\\sim \\mu _{Z}}[\\ln(1-D(G(z),z))]}\n  \n\nGenerator-encoder team aims to minimize the objective, and discriminator aims",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "to minimize the objective, and discriminator aims to maximize it:\n  \n    \n      \n        \n          min\n          \n            G\n            ,\n            E\n          \n        \n        \n          max\n          \n            D\n          \n        \n        L\n        (\n        G\n        ,\n        E\n        ,\n        D\n        )\n      \n    \n    {\\displaystyle \\min _{G,E}\\max _{D}L(G,E,D)}\n  \n In the paper, they gave a more abstract definition of the objective as:\n  \n    \n      \n        L\n        (",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "jective as:\n  \n    \n      \n        L\n        (\n        G\n        ,\n        E\n        ,\n        D\n        )\n        =\n        \n          \n            E\n          \n          \n            (\n            x\n            ,\n            z\n            )\n            ∼\n            \n              μ\n              \n                E\n                ,\n                X\n              \n            \n          \n        \n        [\n        ln\n        ⁡\n        D\n        (\n        x\n        ,\n        z\n        )",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "(\n        x\n        ,\n        z\n        )\n        ]\n        +\n        \n          \n            E\n          \n          \n            (\n            x\n            ,\n            z\n            )\n            ∼\n            \n              μ\n              \n                G\n                ,\n                Z\n              \n            \n          \n        \n        [\n        ln\n        ⁡\n        (\n        1\n        −\n        D\n        (\n        x\n        ,\n        z\n        )\n        )\n        ]",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "z\n        )\n        )\n        ]\n      \n    \n    {\\displaystyle L(G,E,D)=\\mathbb {E} _{(x,z)\\sim \\mu _{E,X}}[\\ln D(x,z)]+\\mathbb {E} _{(x,z)\\sim \\mu _{G,Z}}[\\ln(1-D(x,z))]}\n  \nwhere \n  \n    \n      \n        \n          μ\n          \n            E\n            ,\n            X\n          \n        \n        (\n        d\n        x\n        ,\n        d\n        z\n        )\n        =\n        \n          μ\n          \n            X\n          \n        \n        (\n        d\n        x\n        )\n        ⋅",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "(\n        d\n        x\n        )\n        ⋅\n        \n          δ\n          \n            E\n            (\n            x\n            )\n          \n        \n        (\n        d\n        z\n        )\n      \n    \n    {\\displaystyle \\mu _{E,X}(dx,dz)=\\mu _{X}(dx)\\cdot \\delta _{E(x)}(dz)}\n  \n is the probability distribution on \n  \n    \n      \n        \n          Ω\n          \n            X\n          \n        \n        ×\n        \n          Ω\n          \n            Z\n          \n        \n      \n    \n    {\\disp",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "Z\n          \n        \n      \n    \n    {\\displaystyle \\Omega _{X}\\times \\Omega _{Z}}\n  \n obtained by pushing \n  \n    \n      \n        \n          μ\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle \\mu _{X}}\n  \n forward via \n  \n    \n      \n        x\n        ↦\n        (\n        x\n        ,\n        E\n        (\n        x\n        )\n        )\n      \n    \n    {\\displaystyle x\\mapsto (x,E(x))}\n  \n, and \n  \n    \n      \n        \n          μ\n          \n            G",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "μ\n          \n            G\n            ,\n            Z\n          \n        \n        (\n        d\n        x\n        ,\n        d\n        z\n        )\n        =\n        \n          δ\n          \n            G\n            (\n            z\n            )\n          \n        \n        (\n        d\n        x\n        )\n        ⋅\n        \n          μ\n          \n            Z\n          \n        \n        (\n        d\n        z\n        )\n      \n    \n    {\\displaystyle \\mu _{G,Z}(dx,dz)=\\delta _{G(z)}(dx)\\",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "displaystyle \\mu _{G,Z}(dx,dz)=\\delta _{G(z)}(dx)\\cdot \\mu _{Z}(dz)}\n  \n is the probability distribution on \n  \n    \n      \n        \n          Ω\n          \n            X\n          \n        \n        ×\n        \n          Ω\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\Omega _{X}\\times \\Omega _{Z}}\n  \n obtained by pushing \n  \n    \n      \n        \n          μ\n          \n            Z\n          \n        \n      \n    \n    {\\displaystyle \\mu _{Z}}\n  \n forward via",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle \\mu _{Z}}\n  \n forward via \n  \n    \n      \n        z\n        ↦\n        (\n        G\n        (\n        x\n        )\n        ,\n        z\n        )\n      \n    \n    {\\displaystyle z\\mapsto (G(x),z)}\n  \n.\nApplications of bidirectional models include semi-supervised learning, interpretable machine learning, and neural machine translation.\n\n\n==== CycleGAN ====\nCycleGAN is an architecture for performing translations between two domains, such as between photos of horses and photos of zebras,",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "as between photos of horses and photos of zebras, or photos of night cities and photos of day cities.\n\nThe CycleGAN game is defined as follows:There are two probability spaces \n  \n    \n      \n        (\n        \n          Ω\n          \n            X\n          \n        \n        ,\n        \n          μ\n          \n            X\n          \n        \n        )\n        ,\n        (\n        \n          Ω\n          \n            Y\n          \n        \n        ,\n        \n          μ\n          \n            Y",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "μ\n          \n            Y\n          \n        \n        )\n      \n    \n    {\\displaystyle (\\Omega _{X},\\mu _{X}),(\\Omega _{Y},\\mu _{Y})}\n  \n, corresponding to the two domains needed for translations fore-and-back.\nThere are 4 players in 2 teams: generators \n  \n    \n      \n        \n          G\n          \n            X\n          \n        \n        :\n        \n          Ω\n          \n            X\n          \n        \n        →\n        \n          Ω\n          \n            Y",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "Ω\n          \n            Y\n          \n        \n        ,\n        \n          G\n          \n            Y\n          \n        \n        :\n        \n          Ω\n          \n            Y\n          \n        \n        →\n        \n          Ω\n          \n            X\n          \n        \n      \n    \n    {\\displaystyle G_{X}:\\Omega _{X}\\to \\Omega _{Y},G_{Y}:\\Omega _{Y}\\to \\Omega _{X}}\n  \n, and discriminators \n  \n    \n      \n        \n          D\n          \n            X\n          \n        \n        :",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "X\n          \n        \n        :\n        \n          Ω\n          \n            X\n          \n        \n        →\n        [\n        0\n        ,\n        1\n        ]\n        ,\n        \n          D\n          \n            Y\n          \n        \n        :\n        \n          Ω\n          \n            Y\n          \n        \n        →\n        [\n        0\n        ,\n        1\n        ]\n      \n    \n    {\\displaystyle D_{X}:\\Omega _{X}\\to [0,1],D_{Y}:\\Omega _{Y}\\to [0,1]}\n  \n.\nThe objective functio",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "}:\\Omega _{Y}\\to [0,1]}\n  \n.\nThe objective function is\n  \n    \n      \n        L\n        (\n        \n          G\n          \n            X\n          \n        \n        ,\n        \n          G\n          \n            Y\n          \n        \n        ,\n        \n          D\n          \n            X\n          \n        \n        ,\n        \n          D\n          \n            Y\n          \n        \n        )\n        =\n        \n          L\n          \n            G\n            A\n            N",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "A\n            N\n          \n        \n        (\n        \n          G\n          \n            X\n          \n        \n        ,\n        \n          D\n          \n            X\n          \n        \n        )\n        +\n        \n          L\n          \n            G\n            A\n            N\n          \n        \n        (\n        \n          G\n          \n            Y\n          \n        \n        ,\n        \n          D\n          \n            Y\n          \n        \n        )\n        +\n        λ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ")\n        +\n        λ\n        \n          L\n          \n            c\n            y\n            c\n            l\n            e\n          \n        \n        (\n        \n          G\n          \n            X\n          \n        \n        ,\n        \n          G\n          \n            Y\n          \n        \n        )\n      \n    \n    {\\displaystyle L(G_{X},G_{Y},D_{X},D_{Y})=L_{GAN}(G_{X},D_{X})+L_{GAN}(G_{Y},D_{Y})+\\lambda L_{cycle}(G_{X},G_{Y})}\n  \n\nwhere \n  \n    \n      \n        λ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{X},G_{Y})}\n  \n\nwhere \n  \n    \n      \n        λ\n      \n    \n    {\\displaystyle \\lambda }\n  \n is a positive adjustable parameter, \n  \n    \n      \n        \n          L\n          \n            G\n            A\n            N\n          \n        \n      \n    \n    {\\displaystyle L_{GAN}}\n  \n is the GAN game objective, and \n  \n    \n      \n        \n          L\n          \n            c\n            y\n            c\n            l\n            e\n          \n        \n      \n    \n    {\\displaystyle L_{cycle}}\n  \n is",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle L_{cycle}}\n  \n is the cycle consistency loss:\n  \n    \n      \n        \n          L\n          \n            c\n            y\n            c\n            l\n            e\n          \n        \n        (\n        \n          G\n          \n            X\n          \n        \n        ,\n        \n          G\n          \n            Y\n          \n        \n        )\n        =\n        \n          E\n          \n            x\n            ∼\n            \n              μ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "μ\n              \n                X\n              \n            \n          \n        \n        ‖\n        \n          G\n          \n            X\n          \n        \n        (\n        \n          G\n          \n            Y\n          \n        \n        (\n        x\n        )\n        )\n        −\n        x\n        ‖\n        +\n        \n          E\n          \n            y\n            ∼\n            \n              μ\n              \n                Y",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "Y\n              \n            \n          \n        \n        ‖\n        \n          G\n          \n            Y\n          \n        \n        (\n        \n          G\n          \n            X\n          \n        \n        (\n        y\n        )\n        )\n        −\n        y\n        ‖\n      \n    \n    {\\displaystyle L_{cycle}(G_{X},G_{Y})=E_{x\\sim \\mu _{X}}\\|G_{X}(G_{Y}(x))-x\\|+E_{y\\sim \\mu _{Y}}\\|G_{Y}(G_{X}(y))-y\\|}\n  \nThe generators aim to minimize the objective, and the discriminators aim to maxi",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "the objective, and the discriminators aim to maximize it:\n  \n    \n      \n        \n          min\n          \n            \n              G\n              \n                X\n              \n            \n            ,\n            \n              G\n              \n                Y\n              \n            \n          \n        \n        \n          max\n          \n            \n              D\n              \n                X\n              \n            \n            ,\n            \n              D",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ",\n            \n              D\n              \n                Y\n              \n            \n          \n        \n        L\n        (\n        \n          G\n          \n            X\n          \n        \n        ,\n        \n          G\n          \n            Y\n          \n        \n        ,\n        \n          D\n          \n            X\n          \n        \n        ,\n        \n          D\n          \n            Y\n          \n        \n        )\n      \n    \n    {\\displaystyle \\min _{G_{X},G_{Y}}\\max _",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle \\min _{G_{X},G_{Y}}\\max _{D_{X},D_{Y}}L(G_{X},G_{Y},D_{X},D_{Y})}\n  \n  Unlike previous work like pix2pix, which requires paired training data, cycleGAN requires no paired data. For example, to train a pix2pix model to turn a summer scenery photo to winter scenery photo and back, the dataset must contain pairs of the same place in summer and winter, shot at the same angle; cycleGAN would only need a set of summer scenery photos, and an unrelated set of winter scenery phot",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "hotos, and an unrelated set of winter scenery photos.\n\n\n=== GANs with particularly large or small scales ===\n\n\n==== BigGAN ====\nThe BigGAN is essentially a self-attention GAN trained on a large scale (up to 80 million parameters) to generate large images of ImageNet (up to 512 x 512 resolution), with numerous engineering tricks to make it converge.\n\n\n==== Invertible data augmentation ====\nWhen there is insufficient training data, the reference distribution \n  \n    \n      \n        \n          μ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "stribution \n  \n    \n      \n        \n          μ\n          \n            ref\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\text{ref}}}\n  \n cannot be well-approximated by the empirical distribution given by the training dataset. In such cases, data augmentation can be applied, to allow training GAN on smaller datasets. Naïve data augmentation, however, brings its problems.\nConsider the original GAN game, slightly reformulated as follows:\n  \n    \n      \n        \n          \n            {",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\n            \n              \n                \n                  \n                    min\n                    \n                      D\n                    \n                  \n                  \n                    L\n                    \n                      D\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    μ\n                    \n                      G",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "G\n                    \n                  \n                  )\n                  =\n                  −\n                  \n                    E\n                    \n                      x\n                      ∼\n                      \n                        μ\n                        \n                          ref\n                        \n                      \n                    \n                  \n                  ⁡\n                  [",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "⁡\n                  [\n                  ln\n                  ⁡\n                  D\n                  (\n                  x\n                  )\n                  ]\n                  −\n                  \n                    E\n                    \n                      x\n                      ∼\n                      \n                        μ\n                        \n                          G",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "⁡\n                  [\n                  ln\n                  ⁡\n                  (\n                  1\n                  −\n                  D\n                  (\n                  x\n                  )\n                  )\n                  ]\n                \n              \n              \n                \n                  \n                    min\n                    \n                      G",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "G\n                    \n                  \n                  \n                    L\n                    \n                      G\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    μ\n                    \n                      G\n                    \n                  \n                  )\n                  =\n                  −\n                  \n                    E",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "E\n                    \n                      x\n                      ∼\n                      \n                        μ\n                        \n                          G\n                        \n                      \n                    \n                  \n                  ⁡\n                  [\n                  ln\n                  ⁡\n                  (\n                  1\n                  −\n                  D\n                  (\n                  x\n                  )",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "(\n                  x\n                  )\n                  )\n                  ]\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{cases}\\min _{D}L_{D}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{\\text{ref}}}[\\ln D(x)]-\\operatorname {E} _{x\\sim \\mu _{G}}[\\ln(1-D(x))]\\\\\\min _{G}L_{G}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{G}}[\\ln(1-D(x))]\\end{cases}}}\n  \nNow we use data augmentation by randomly sampling semantic-preservi",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "ugmentation by randomly sampling semantic-preserving transforms \n  \n    \n      \n        T\n        :\n        Ω\n        →\n        Ω\n      \n    \n    {\\displaystyle T:\\Omega \\to \\Omega }\n  \n and applying them to the dataset, to obtain the reformulated GAN game:\n  \n    \n      \n        \n          \n            {\n            \n              \n                \n                  \n                    min\n                    \n                      D",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "L\n                    \n                      D\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    μ\n                    \n                      G\n                    \n                  \n                  )\n                  =\n                  −\n                  \n                    E\n                    \n                      x",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "x\n                      ∼\n                      \n                        μ\n                        \n                          ref\n                        \n                      \n                      ,\n                      T\n                      ∼\n                      \n                        μ\n                        \n                          trans\n                        \n                      \n                    \n                  \n                  ⁡",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "⁡\n                  [\n                  ln\n                  ⁡\n                  D\n                  (\n                  T\n                  (\n                  x\n                  )\n                  )\n                  ]\n                  −\n                  \n                    E\n                    \n                      x\n                      ∼\n                      \n                        μ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "G\n                        \n                      \n                    \n                  \n                  ⁡\n                  [\n                  ln\n                  ⁡\n                  (\n                  1\n                  −\n                  D\n                  (\n                  x\n                  )\n                  )\n                  ]",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "min\n                    \n                      G\n                    \n                  \n                  \n                    L\n                    \n                      G\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    μ\n                    \n                      G\n                    \n                  \n                  )\n                  =",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ")\n                  =\n                  −\n                  \n                    E\n                    \n                      x\n                      ∼\n                      \n                        μ\n                        \n                          G\n                        \n                      \n                    \n                  \n                  ⁡\n                  [\n                  ln\n                  ⁡\n                  (\n                  1",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "(\n                  1\n                  −\n                  D\n                  (\n                  x\n                  )\n                  )\n                  ]\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{cases}\\min _{D}L_{D}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{\\text{ref}},T\\sim \\mu _{\\text{trans}}}[\\ln D(T(x))]-\\operatorname {E} _{x\\sim \\mu _{G}}[\\ln(1-D(x))]\\\\\\min _{G}L_{G}(D,\\mu _{G})=-\\operatorn",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "n(1-D(x))]\\\\\\min _{G}L_{G}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{G}}[\\ln(1-D(x))]\\end{cases}}}\n  \nThis is equivalent to a GAN game with a different distribution \n  \n    \n      \n        \n          μ\n          \n            ref\n          \n          ′\n        \n      \n    \n    {\\displaystyle \\mu _{\\text{ref}}'}\n  \n, sampled by \n  \n    \n      \n        T\n        (\n        x\n        )\n      \n    \n    {\\displaystyle T(x)}\n  \n, with \n  \n    \n      \n        x\n        ∼\n        \n          μ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "x\n        ∼\n        \n          μ\n          \n            ref\n          \n        \n        ,\n        T\n        ∼\n        \n          μ\n          \n            trans\n          \n        \n      \n    \n    {\\displaystyle x\\sim \\mu _{\\text{ref}},T\\sim \\mu _{\\text{trans}}}\n  \n. For example, if \n  \n    \n      \n        \n          μ\n          \n            ref\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\text{ref}}}\n  \n is the distribution of images in ImageNet, and",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "f images in ImageNet, and \n  \n    \n      \n        \n          μ\n          \n            trans\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\text{trans}}}\n  \n samples identity-transform with probability 0.5, and horizontal-reflection with probability 0.5, then \n  \n    \n      \n        \n          μ\n          \n            ref\n          \n          ′\n        \n      \n    \n    {\\displaystyle \\mu _{\\text{ref}}'}\n  \n is the distribution of images in ImageNet and horizontally-reflected ImageNet,",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "in ImageNet and horizontally-reflected ImageNet, combined.\nThe result of such training would be a generator that mimics \n  \n    \n      \n        \n          μ\n          \n            ref\n          \n          ′\n        \n      \n    \n    {\\displaystyle \\mu _{\\text{ref}}'}\n  \n. For example, it would generate images that look like they are randomly cropped, if the data augmentation uses random cropping.\nThe solution is to apply data augmentation to both generated and real images:",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "generated and real images:\n  \n    \n      \n        \n          \n            {\n            \n              \n                \n                  \n                    min\n                    \n                      D\n                    \n                  \n                  \n                    L\n                    \n                      D\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    μ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "μ\n                    \n                      G\n                    \n                  \n                  )\n                  =\n                  −\n                  \n                    E\n                    \n                      x\n                      ∼\n                      \n                        μ\n                        \n                          ref\n                        \n                      \n                      ,\n                      T",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ",\n                      T\n                      ∼\n                      \n                        μ\n                        \n                          trans\n                        \n                      \n                    \n                  \n                  ⁡\n                  [\n                  ln\n                  ⁡\n                  D\n                  (\n                  T\n                  (\n                  x\n                  )\n                  )\n                  ]",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ")\n                  ]\n                  −\n                  \n                    E\n                    \n                      x\n                      ∼\n                      \n                        μ\n                        \n                          G\n                        \n                      \n                      ,\n                      T\n                      ∼\n                      \n                        μ\n                        \n                          trans",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "trans\n                        \n                      \n                    \n                  \n                  ⁡\n                  [\n                  ln\n                  ⁡\n                  (\n                  1\n                  −\n                  D\n                  (\n                  T\n                  (\n                  x\n                  )\n                  )\n                  )\n                  ]",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "]\n                \n              \n              \n                \n                  \n                    min\n                    \n                      G\n                    \n                  \n                  \n                    L\n                    \n                      G\n                    \n                  \n                  (\n                  D\n                  ,\n                  \n                    μ\n                    \n                      G",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "G\n                    \n                  \n                  )\n                  =\n                  −\n                  \n                    E\n                    \n                      x\n                      ∼\n                      \n                        μ\n                        \n                          G\n                        \n                      \n                      ,\n                      T\n                      ∼",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "∼\n                      \n                        μ\n                        \n                          trans\n                        \n                      \n                    \n                  \n                  ⁡\n                  [\n                  ln\n                  ⁡\n                  (\n                  1\n                  −\n                  D\n                  (\n                  T\n                  (\n                  x\n                  )\n                  )\n                  )",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ")\n                  )\n                  )\n                  ]\n                \n              \n            \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{cases}\\min _{D}L_{D}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{\\text{ref}},T\\sim \\mu _{\\text{trans}}}[\\ln D(T(x))]-\\operatorname {E} _{x\\sim \\mu _{G},T\\sim \\mu _{\\text{trans}}}[\\ln(1-D(T(x)))]\\\\\\min _{G}L_{G}(D,\\mu _{G})=-\\operatorname {E} _{x\\sim \\mu _{G},T\\sim \\mu _{\\text{trans}}}[\\ln(1-D(T(x)))]\\end{cases}}",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "m \\mu _{\\text{trans}}}[\\ln(1-D(T(x)))]\\end{cases}}}\n  \nThe authors demonstrated high-quality generation using just 100-picture-large datasets.\nThe StyleGAN-2-ADA paper points out a further point on data augmentation: it must be invertible. Continue with the example of generating ImageNet pictures. If the data augmentation is \"randomly rotate the picture by 0, 90, 180, 270 degrees with equal probability\", then there is no way for the generator to know which is the true orientation: Consider two g",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "know which is the true orientation: Consider two generators \n  \n    \n      \n        G\n        ,\n        \n          G\n          ′\n        \n      \n    \n    {\\displaystyle G,G'}\n  \n, such that for any latent \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n, the generated image \n  \n    \n      \n        G\n        (\n        z\n        )\n      \n    \n    {\\displaystyle G(z)}\n  \n is a 90-degree rotation of \n  \n    \n      \n        \n          G\n          ′\n        \n        (\n        z",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "′\n        \n        (\n        z\n        )\n      \n    \n    {\\displaystyle G'(z)}\n  \n. They would have exactly the same expected loss, and so neither is preferred over the other.\nThe solution is to only use invertible data augmentation: instead of \"randomly rotate the picture by 0, 90, 180, 270 degrees with equal probability\", use \"randomly rotate the picture by 90, 180, 270 degrees with 0.1 probability, and keep the picture as it is with 0.7 probability\". This way, the generator is stil",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "0.7 probability\". This way, the generator is still rewarded  to keep images oriented the same way as un-augmented ImageNet pictures.\nAbstractly, the effect of randomly sampling transformations \n  \n    \n      \n        T\n        :\n        Ω\n        →\n        Ω\n      \n    \n    {\\displaystyle T:\\Omega \\to \\Omega }\n  \n from the distribution \n  \n    \n      \n        \n          μ\n          \n            trans\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\text{trans}}}\n  \n is to define a Mark",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "style \\mu _{\\text{trans}}}\n  \n is to define a Markov kernel \n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n        :\n        Ω\n        →\n        \n          \n            P\n          \n        \n        (\n        Ω\n        )\n      \n    \n    {\\displaystyle K_{\\text{trans}}:\\Omega \\to {\\mathcal {P}}(\\Omega )}\n  \n. Then, the data-augmented GAN game pushes the generator to find some \n  \n    \n      \n        \n          \n            \n              \n                μ",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "μ\n                ^\n              \n            \n          \n          \n            G\n          \n        \n        ∈\n        \n          \n            P\n          \n        \n        (\n        Ω\n        )\n      \n    \n    {\\displaystyle {\\hat {\\mu }}_{G}\\in {\\mathcal {P}}(\\Omega )}\n  \n, such that \n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n        ∗\n        \n          μ\n          \n            ref",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "μ\n          \n            ref\n          \n        \n        =\n        \n          K\n          \n            trans\n          \n        \n        ∗\n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            G\n          \n        \n      \n    \n    {\\displaystyle K_{\\text{trans}}*\\mu _{\\text{ref}}=K_{\\text{trans}}*{\\hat {\\mu }}_{G}}\n  \nwhere \n  \n    \n      \n        ∗\n      \n    \n    {\\displaystyle *}\n  \n is the Markov ke",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle *}\n  \n is the Markov kernel convolution.\nA data-augmentation method is defined to be invertible if its Markov kernel \n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n      \n    \n    {\\displaystyle K_{\\text{trans}}}\n  \n satisfies\n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n        ∗\n        μ\n        =\n        \n          K\n          \n            trans\n          \n        \n        ∗",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "trans\n          \n        \n        ∗\n        \n          μ\n          ′\n        \n        \n        ⟹\n        \n        μ\n        =\n        \n          μ\n          ′\n        \n        \n        ∀\n        μ\n        ,\n        \n          μ\n          ′\n        \n        ∈\n        \n          \n            P\n          \n        \n        (\n        Ω\n        )\n      \n    \n    {\\displaystyle K_{\\text{trans}}*\\mu =K_{\\text{trans}}*\\mu '\\implies \\mu =\\mu '\\quad \\forall \\mu ,\\mu '\\in {\\mathcal {P}}(\\Omega )}\n  \nImmed",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "ll \\mu ,\\mu '\\in {\\mathcal {P}}(\\Omega )}\n  \nImmediately by definition, we see that composing multiple invertible data-augmentation methods results in yet another invertible method. Also by definition, if the data-augmentation method is invertible, then using it in a GAN game does not change the optimal strategy \n  \n    \n      \n        \n          \n            \n              \n                μ\n                ^\n              \n            \n          \n          \n            G",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "G\n          \n        \n      \n    \n    {\\displaystyle {\\hat {\\mu }}_{G}}\n  \n for the generator, which is still \n  \n    \n      \n        \n          μ\n          \n            ref\n          \n        \n      \n    \n    {\\displaystyle \\mu _{\\text{ref}}}\n  \n.\nThere are two prototypical examples of invertible Markov kernels:\nDiscrete case: Invertible stochastic matrices, when \n  \n    \n      \n        Ω\n      \n    \n    {\\displaystyle \\Omega }\n  \n is finite.\nFor example, if",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "\\Omega }\n  \n is finite.\nFor example, if \n  \n    \n      \n        Ω\n        =\n        {\n        ↑\n        ,\n        ↓\n        ,\n        ←\n        ,\n        →\n        }\n      \n    \n    {\\displaystyle \\Omega =\\{\\uparrow ,\\downarrow ,\\leftarrow ,\\rightarrow \\}}\n  \n is the set of four images of an arrow, pointing in 4 directions, and the data augmentation is \"randomly rotate the picture by 90, 180, 270 degrees with probability \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n, and keep t",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle p}\n  \n, and keep the picture as it is with probability \n  \n    \n      \n        (\n        1\n        −\n        3\n        p\n        )\n      \n    \n    {\\displaystyle (1-3p)}\n  \n\", then the Markov kernel \n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n      \n    \n    {\\displaystyle K_{\\text{trans}}}\n  \n can be represented as a stochastic matrix:\n  \n    \n      \n        [\n        \n          K\n          \n            trans",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "K\n          \n            trans\n          \n        \n        ]\n        =\n        \n          \n            [\n            \n              \n                \n                  (\n                  1\n                  −\n                  3\n                  p\n                  )\n                \n                \n                  p\n                \n                \n                  p\n                \n                \n                  p",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "p\n                \n                \n                  (\n                  1\n                  −\n                  3\n                  p\n                  )\n                \n                \n                  p\n                \n                \n                  p\n                \n              \n              \n                \n                  p\n                \n                \n                  p",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "p\n                \n                \n                  (\n                  1\n                  −\n                  3\n                  p\n                  )\n                \n                \n                  p\n                \n              \n              \n                \n                  p\n                \n                \n                  p\n                \n                \n                  p\n                \n                \n                  (\n                  1",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "(\n                  1\n                  −\n                  3\n                  p\n                  )\n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle [K_{\\text{trans}}]={\\begin{bmatrix}(1-3p)&p&p&p\\\\p&(1-3p)&p&p\\\\p&p&(1-3p)&p\\\\p&p&p&(1-3p)\\end{bmatrix}}}\n  \n and \n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n      \n    \n    {\\displaystyle K_{\\text{trans}}}\n  \n is an inver",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle K_{\\text{trans}}}\n  \n is an invertible kernel iff \n  \n    \n      \n        [\n        \n          K\n          \n            trans\n          \n        \n        ]\n      \n    \n    {\\displaystyle [K_{\\text{trans}}]}\n  \n is an invertible matrix, that is, \n  \n    \n      \n        p\n        ≠\n        1\n        \n          /\n        \n        4\n      \n    \n    {\\displaystyle p\\neq 1/4}\n  \n.\nContinuous case: The gaussian kernel, when \n  \n    \n      \n        Ω\n        =",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "Ω\n        =\n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\Omega =\\mathbb {R} ^{n}}\n  \n for some \n  \n    \n      \n        n\n        ≥\n        1\n      \n    \n    {\\displaystyle n\\geq 1}\n  \n.\nFor example, if \n  \n    \n      \n        Ω\n        =\n        \n          \n            R\n          \n          \n            \n              256\n              \n                2",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle \\Omega =\\mathbb {R} ^{256^{2}}}\n  \n is the space of 256x256 images, and the data-augmentation method is \"generate a gaussian noise \n  \n    \n      \n        z\n        ∼\n        \n          \n            N\n          \n        \n        (\n        0\n        ,\n        \n          I\n          \n            \n              256\n              \n                2\n              \n            \n          \n        \n        )\n      \n    \n    {\\d",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ")\n      \n    \n    {\\displaystyle z\\sim {\\mathcal {N}}(0,I_{256^{2}})}\n  \n, then add \n  \n    \n      \n        ϵ\n        z\n      \n    \n    {\\displaystyle \\epsilon z}\n  \n to the image\", then \n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n      \n    \n    {\\displaystyle K_{\\text{trans}}}\n  \n is just convolution by the density function of \n  \n    \n      \n        \n          \n            N\n          \n        \n        (\n        0",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "N\n          \n        \n        (\n        0\n        ,\n        \n          ϵ\n          \n            2\n          \n        \n        \n          I\n          \n            \n              256\n              \n                2\n              \n            \n          \n        \n        )\n      \n    \n    {\\displaystyle {\\mathcal {N}}(0,\\epsilon ^{2}I_{256^{2}})}\n  \n. This is invertible, because convolution by a gaussian is just convolution by the heat kernel, so given any \n  \n    \n      \n        μ\n        ∈",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "iven any \n  \n    \n      \n        μ\n        ∈\n        \n          \n            P\n          \n        \n        (\n        \n          \n            R\n          \n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle \\mu \\in {\\mathcal {P}}(\\mathbb {R} ^{n})}\n  \n, the convolved distribution \n  \n    \n      \n        \n          K\n          \n            trans\n          \n        \n        ∗\n        μ\n      \n    \n    {\\displaystyle K_{\\text{trans}}*\\mu }\n  \n can be obtained by hea",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "K_{\\text{trans}}*\\mu }\n  \n can be obtained by heating up \n  \n    \n      \n        \n          \n            R\n          \n          \n            n\n          \n        \n      \n    \n    {\\displaystyle \\mathbb {R} ^{n}}\n  \n precisely according to \n  \n    \n      \n        μ\n      \n    \n    {\\displaystyle \\mu }\n  \n, then wait for time \n  \n    \n      \n        \n          ϵ\n          \n            2\n          \n        \n        \n          /\n        \n        4\n      \n    \n    {\\displaystyle \\epsilon ^{2}/4}",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle \\epsilon ^{2}/4}\n  \n. With that, we can recover \n  \n    \n      \n        μ\n      \n    \n    {\\displaystyle \\mu }\n  \n by running the heat equation backwards in time for \n  \n    \n      \n        \n          ϵ\n          \n            2\n          \n        \n        \n          /\n        \n        4\n      \n    \n    {\\displaystyle \\epsilon ^{2}/4}\n  \n.\nMore examples of invertible data augmentations are found in the paper.\n\n\n==== SinGAN ====\nSinGAN pushes data augmentation to the",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "inGAN ====\nSinGAN pushes data augmentation to the limit, by using only a single image as training data and performing data augmentation on it. The GAN architecture is adapted to this training method by using a multi-scale pipeline.\nThe generator \n  \n    \n      \n        G\n      \n    \n    {\\displaystyle G}\n  \n is decomposed into a pyramid of generators \n  \n    \n      \n        G\n        =\n        \n          G\n          \n            1\n          \n        \n        ∘\n        \n          G",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "∘\n        \n          G\n          \n            2\n          \n        \n        ∘\n        ⋯\n        ∘\n        \n          G\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle G=G_{1}\\circ G_{2}\\circ \\cdots \\circ G_{N}}\n  \n, with the lowest one generating the image \n  \n    \n      \n        \n          G\n          \n            N\n          \n        \n        (\n        \n          z\n          \n            N\n          \n        \n        )\n      \n    \n    {\\displaystyle G_{",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ")\n      \n    \n    {\\displaystyle G_{N}(z_{N})}\n  \n at the lowest resolution, then the generated image is scaled up to \n  \n    \n      \n        r\n        (\n        \n          G\n          \n            N\n          \n        \n        (\n        \n          z\n          \n            N\n          \n        \n        )\n        )\n      \n    \n    {\\displaystyle r(G_{N}(z_{N}))}\n  \n, and fed to the next level to generate an image \n  \n    \n      \n        \n          G\n          \n            N",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "G\n          \n            N\n            −\n            1\n          \n        \n        (\n        \n          z\n          \n            N\n            −\n            1\n          \n        \n        +\n        r\n        (\n        \n          G\n          \n            N\n          \n        \n        (\n        \n          z\n          \n            N\n          \n        \n        )\n        )\n        )\n      \n    \n    {\\displaystyle G_{N-1}(z_{N-1}+r(G_{N}(z_{N})))}\n  \n at a higher resolution, and so on.",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "(z_{N})))}\n  \n at a higher resolution, and so on. The discriminator is decomposed into a pyramid as well.\n\n\n=== StyleGAN series ===\n\nThe StyleGAN family is a series of architectures published by Nvidia's research division.\n\n\n==== Progressive GAN ====\nProgressive GAN is a method for training GAN for large-scale image generation stably, by growing a GAN generator from small to large scale in a pyramidal fashion. Like SinGAN, it decomposes the generator as\n  \n    \n      \n        G\n        =",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "ator as\n  \n    \n      \n        G\n        =\n        \n          G\n          \n            1\n          \n        \n        ∘\n        \n          G\n          \n            2\n          \n        \n        ∘\n        ⋯\n        ∘\n        \n          G\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle G=G_{1}\\circ G_{2}\\circ \\cdots \\circ G_{N}}\n  \n, and the discriminator as \n  \n    \n      \n        D\n        =\n        \n          D\n          \n            1\n          \n        \n        ∘",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "1\n          \n        \n        ∘\n        \n          D\n          \n            2\n          \n        \n        ∘\n        ⋯\n        ∘\n        \n          D\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle D=D_{1}\\circ D_{2}\\circ \\cdots \\circ D_{N}}\n  \n.\nDuring training, at first only \n  \n    \n      \n        \n          G\n          \n            N\n          \n        \n        ,\n        \n          D\n          \n            N\n          \n        \n      \n    \n    {\\dis",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "N\n          \n        \n      \n    \n    {\\displaystyle G_{N},D_{N}}\n  \n are used in a GAN game to generate 4x4 images. Then \n  \n    \n      \n        \n          G\n          \n            N\n            −\n            1\n          \n        \n        ,\n        \n          D\n          \n            N\n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle G_{N-1},D_{N-1}}\n  \n are added to reach the second stage of GAN game, to generate 8x8 images, and so on, until we reach a GAN",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "erate 8x8 images, and so on, until we reach a GAN game to generate 1024x1024 images.\nTo avoid shock between stages of the GAN game, each new layer is \"blended in\" (Figure 2 of the paper). For example, this is how the second stage GAN game starts:\n\nJust before, the GAN game consists of the pair \n  \n    \n      \n        \n          G\n          \n            N\n          \n        \n        ,\n        \n          D\n          \n            N\n          \n        \n      \n    \n    {\\displaystyle G_{N},D_{N}}",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle G_{N},D_{N}}\n  \n generating and discriminating 4x4 images.\nJust after, the GAN game consists of the pair \n  \n    \n      \n        (\n        (\n        1\n        −\n        α\n        )\n        +\n        α\n        ⋅\n        \n          G\n          \n            N\n            −\n            1\n          \n        \n        )\n        ∘\n        u\n        ∘\n        \n          G\n          \n            N\n          \n        \n        ,\n        \n          D\n          \n            N",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": ",\n        \n          D\n          \n            N\n          \n        \n        ∘\n        d\n        ∘\n        (\n        (\n        1\n        −\n        α\n        )\n        +\n        α\n        ⋅\n        \n          D\n          \n            N\n            −\n            1\n          \n        \n        )\n      \n    \n    {\\displaystyle ((1-\\alpha )+\\alpha \\cdot G_{N-1})\\circ u\\circ G_{N},D_{N}\\circ d\\circ ((1-\\alpha )+\\alpha \\cdot D_{N-1})}\n  \n generating and discriminating 8x8 images. Here, the functions",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "d discriminating 8x8 images. Here, the functions \n  \n    \n      \n        u\n        ,\n        d\n      \n    \n    {\\displaystyle u,d}\n  \n are image up- and down-sampling functions, and \n  \n    \n      \n        α\n      \n    \n    {\\displaystyle \\alpha }\n  \n is a blend-in factor (much like an alpha in image composing) that smoothly glides from 0 to 1.\n\n\n==== StyleGAN-1 ====\n\nStyleGAN-1 is designed as a combination of Progressive GAN with neural style transfer.\nThe key architectural choice of StyleGAN-1",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "ansfer.\nThe key architectural choice of StyleGAN-1 is a progressive growth mechanism, similar to Progressive GAN. Each generated image starts as a constant \n  \n    \n      \n        4\n        ×\n        4\n        ×\n        512\n      \n    \n    {\\displaystyle 4\\times 4\\times 512}\n  \n array, and repeatedly passed through style blocks. Each style block applies a \"style latent vector\" via affine transform (\"adaptive instance normalization\"), similar to how neural style transfer uses Gramian matrix. It t",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "ow neural style transfer uses Gramian matrix. It then adds noise, and normalize (subtract the mean, then divide by the variance).\nAt training time, usually only one style latent vector is used per image generated, but sometimes two (\"mixing regularization\") in order to encourage each style block to independently perform its stylization without expecting help from other style blocks (since they might receive an entirely different style latent vector).\nAfter training, multiple style latent vectors",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "or).\nAfter training, multiple style latent vectors can be fed into each style block. Those fed to the lower layers control the large-scale styles, and those fed to the higher layers control the fine-detail styles.\nStyle-mixing between two images \n  \n    \n      \n        x\n        ,\n        \n          x\n          ′\n        \n      \n    \n    {\\displaystyle x,x'}\n  \n can be performed as well. First, run a gradient descent to find \n  \n    \n      \n        z\n        ,\n        \n          z\n          ′",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "z\n        ,\n        \n          z\n          ′\n        \n      \n    \n    {\\displaystyle z,z'}\n  \n such that \n  \n    \n      \n        G\n        (\n        z\n        )\n        ≈\n        x\n        ,\n        G\n        (\n        \n          z\n          ′\n        \n        )\n        ≈\n        \n          x\n          ′\n        \n      \n    \n    {\\displaystyle G(z)\\approx x,G(z')\\approx x'}\n  \n. This is called \"projecting an image back to style latent space\". Then, \n  \n    \n      \n        z\n      \n    \n    {\\",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "Then, \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n can be fed to the lower style blocks, and \n  \n    \n      \n        \n          z\n          ′\n        \n      \n    \n    {\\displaystyle z'}\n  \n to the higher style blocks, to generate a composite image that has the large-scale style of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n, and the fine-detail style of \n  \n    \n      \n        \n          x\n          ′\n        \n      \n    \n    {\\displaystyle x'}\n  \n. Multipl",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "{\\displaystyle x'}\n  \n. Multiple images can also be composed this way.\n\n\n==== StyleGAN-2 ====\nStyleGAN-2 improves upon StyleGAN-1, by using the style latent vector to transform the convolution layer's weights instead, thus solving the \"blob\" problem.\nThis was updated by the StyleGAN-2-ADA (\"ADA\" stands for \"adaptive\"), which uses invertible data augmentation as described above. It also tunes the amount of data augmentation applied by starting at zero, and gradually increasing",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "ied by starting at zero, and gradually increasing it until an \"overfitting heuristic\" reaches a target level, thus the name \"adaptive\".\n\n\n==== StyleGAN-3 ====\nStyleGAN-3 improves upon StyleGAN-2 by solving the \"texture sticking\" problem, which can be seen in the official videos. They analyzed the problem by the Nyquist–Shannon sampling theorem, and argued that the layers in the generator learned to exploit the high-frequency signal in the pixels they operate upon.\nTo solve this, they proposed im",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "they operate upon.\nTo solve this, they proposed imposing strict lowpass filters between each generator's layers, so that the generator is forced to operate on the pixels in a way faithful to the continuous signals they represent, rather than operate on them as merely discrete signals. They further imposed rotational and translational invariance by using more signal filters. The resulting StyleGAN-3 is able to solve the texture sticking problem, as well as generating images that rotate and transl",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "s well as generating images that rotate and translate smoothly.\n\n\n== Other uses ==\nOther than for generative and discriminative modelling of data, GANs have been used for other things.\nGANs have been used for transfer learning to enforce the alignment of the latent feature space, such as in deep reinforcement learning. This works by feeding the embeddings of the source and target task to the discriminator which tries to guess the context. The resulting loss is then (inversely) backpropagated thr",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "ulting loss is then (inversely) backpropagated through the encoder.\n\n\n== Applications ==\n\n\n=== Science ===\nIteratively reconstruct astronomical images\nSimulate gravitational lensing for dark matter research.\nModel the distribution of dark matter in a particular direction in space and to predict the gravitational lensing that will occur.\nModel high energy jet formation and showers through calorimeters of high-energy physics experiments.\nApproximate bottlenecks in computationally expensive simulat",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "e bottlenecks in computationally expensive simulations of particle physics experiments. Applications in the context of present and proposed CERN experiments have demonstrated the potential of these methods for accelerating simulation and/or improving simulation fidelity.\nReconstruct velocity and scalar fields in turbulent flows.\nGAN-generated molecules were validated experimentally in mice.\n\n\n=== Medical ===\nOne of the major concerns in medical imaging is preserving patient privacy. Due to these",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "maging is preserving patient privacy. Due to these reasons, researchers often face difficulties in obtaining medical images for their research purposes. GAN has been used for generating synthetic medical images, such as MRI and PET images to address this challenge. \nGAN can be used to detect glaucomatous images helping the early diagnosis which is essential to avoid partial or total loss of vision.\nGANs have been used to create forensic facial reconstructions of deceased historical figures.\n\n\n==",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "constructions of deceased historical figures.\n\n\n=== Malicious ===\n\nConcerns have been raised about the potential use of GAN-based human image synthesis for sinister purposes, e.g., to produce fake, possibly incriminating, photographs and videos.\nGANs can be used to generate unique, realistic profile photos of people who do not exist, in order to automate creation of fake social media profiles.\nIn 2019 the state of California considered and passed on October 3, 2019, the bill AB-602, which bans t",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "on October 3, 2019, the bill AB-602, which bans the use of human image synthesis technologies to make fake pornography without the consent of the people depicted, and bill AB-730, which prohibits distribution of manipulated videos of a political candidate within 60 days of an election. Both bills were authored by Assembly member Marc Berman and signed by Governor Gavin Newsom. The laws went into effect in 2020.\nDARPA's Media Forensics program studies ways to counteract fake media, including fak",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "udies ways to counteract fake media, including fake media produced using GANs.\n\n\n=== Fashion, art and advertising ===\nGANs can be used to generate art; The Verge wrote in March 2019 that \"The images created by GANs have become the defining look of contemporary AI art.\" GANs can also be used to\n\ninpaint photographs\ngenerate fashion models, shadows, photorealistic renders of interior design, industrial design, shoes, etc. Such networks were reported to be used by Facebook.\nSome have worked with us",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "d to be used by Facebook.\nSome have worked with using GAN for artistic creativity, as \"creative adversarial network\". A GAN, trained on a set of 15,000 portraits from WikiArt from the 14th to the 19th century, created the 2018 painting Edmond de Belamy, which sold for US$432,500.\nGANs were used by the video game modding community to up-scale low-resolution 2D textures in old video games by recreating them in 4k or higher resolutions via image training, and then down-sampling them to fit the game",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "ining, and then down-sampling them to fit the game's native resolution (resembling supersampling anti-aliasing).\nIn 2020, Artbreeder was used to create the main antagonist in the sequel to the psychological web horror series Ben Drowned. The author would later go on to praise GAN applications for their ability to help generate assets for independent artists who are short on budget and manpower.\nIn May 2020, Nvidia researchers taught an AI system (termed \"GameGAN\") to recreate the game of Pac-Man",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "(termed \"GameGAN\") to recreate the game of Pac-Man simply by watching it being played.\nIn August 2019, a large dataset consisting of 12,197 MIDI songs each with paired lyrics and melody alignment was created for neural melody generation from lyrics using conditional GAN-LSTM (refer to sources at GitHub AI Melody Generation from Lyrics).\n\n\n=== Miscellaneous ===\nGANs have been used to \n\nshow how an individual's appearance might change with age.\nreconstruct 3D models of objects from images,\ngenerat",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "onstruct 3D models of objects from images,\ngenerate novel objects as 3D point clouds,\nmodel patterns of motion in video.\ninpaint missing features in maps, transfer map styles in cartography or augment street view imagery.\nuse feedback to generate images and replace image search systems.\nvisualize the effect that climate change will have on specific houses.\nreconstruct an image of a person's face after listening to their voice.\nproduces videos of a person speaking, given only a single photo of th",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "a person speaking, given only a single photo of that person.\nrecurrent sequence generation.\n\n\n== History ==\nIn 1991, Juergen Schmidhuber published \"artificial curiosity\", neural networks in a zero-sum game. The first network is a generative model that models a probability distribution over output patterns. The second network learns by gradient descent to predict the reactions of the environment to these patterns. GANs can be regarded as a case where the environmental reaction is 1 or 0 depending",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "ere the environmental reaction is 1 or 0 depending on whether the first network's output is in a given set.\nOther people had similar ideas but did not develop them similarly. An idea involving adversarial networks was published in a 2010 blog post by Olli Niemitalo. This idea was never implemented and did not involve stochasticity in the generator and thus was not a generative model. It is now known as a conditional GAN or cGAN. An idea similar to GANs was used to model animal behavior by Wei Li",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "o GANs was used to model animal behavior by Wei Li, Melvin Gauci and Roderich Gross in 2013.\nAnother inspiration for GANs was noise-contrastive estimation, which uses the same loss function as GANs and which Goodfellow studied during his PhD in 2010–2014.\nAdversarial machine learning has other uses besides generative modeling and can be applied to models other than neural networks. In control theory, adversarial learning based on neural networks was used in 2006 to train robust controllers in a",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "was used in 2006 to train robust controllers in a game theoretic sense, by alternating the iterations between a minimizer policy, the controller, and a maximizer policy, the disturbance.\nIn 2017, a GAN was used for image enhancement focusing on realistic textures rather than pixel-accuracy, producing a higher image quality at high magnification. In 2017, the first faces were generated. These were exhibited in February 2018 at the Grand Palais. Faces generated by StyleGAN in 2019 drew comparisons",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "ces generated by StyleGAN in 2019 drew comparisons with Deepfakes.\n\n\n== See also ==\nArtificial intelligence art – Visual media created with AIPages displaying short descriptions of redirect targets\nDeepfake – Realistic artificially generated media\nDeep learning – Branch of machine learning\nDiffusion model – Deep learning algorithm\nGenerative artificial intelligence – Subset of AI using generative models\nSynthetic media – Artificial production of media by automated means\n\n\n== References ==\n\n\n== E",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "media by automated means\n\n\n== References ==\n\n\n== External links ==\n\nKnight, Will. \"5 Big Predictions for Artificial Intelligence in 2017\". MIT Technology Review. Retrieved January 5, 2017.\nKarras, Tero; Laine, Samuli; Aila, Timo (2018). \"A Style-Based Generator Architecture for Generative Adversarial Networks\". arXiv:1812.04948 [cs.NE].\nThis Person Does Not Exist –  photorealistic images of people who do not exist, generated by StyleGAN\nThis Cat Does Not Exist Archived March 5, 2019, at the Wayb",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "Does Not Exist Archived March 5, 2019, at the Wayback Machine –  photorealistic images of cats who do not exist, generated by StyleGAN\nWang, Zhengwei; She, Qi; Ward, Tomas E. (2019). \"Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy\". arXiv:1906.01529 [cs.LG].",
        "source": "generative_adversarial_network.txt"
    },
    {
        "text": "Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation.\nPython is dynamically type-checked and garbage-collected. It supports multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library.\nGuido van Rossum began working on Python in the late",
        "source": "python_programming_language.txt"
    },
    {
        "text": "do van Rossum began working on Python in the late 1980s as a successor to the ABC programming language, and he first released it in 1991 as Python 0.9.0. Python 2.0 was released in 2000. Python 3.0, released in 2008, was a major revision not completely backward-compatible with earlier versions. Python 2.7.18, released in 2020, was the last release of Python 2.\nPython consistently ranks as one of the most popular programming languages, and it has gained widespread use in the machine learning comm",
        "source": "python_programming_language.txt"
    },
    {
        "text": "gained widespread use in the machine learning community.\n\n\n== History ==\n\nPython was conceived in the late 1980s by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands; it was conceived as a successor to the ABC programming language, which was inspired by SETL, capable of exception handling and interfacing with the Amoeba operating system. Python implementation began in December, 1989. Van Rossum assumed sole responsibility for the project, as the lead developer, until 12",
        "source": "python_programming_language.txt"
    },
    {
        "text": "y for the project, as the lead developer, until 12 July 2018, when he announced his \"permanent vacation\" from responsibilities as Python's \"benevolent dictator for life\" (BDFL); this title was bestowed on him by the Python community to reflect his long-term commitment as the project's chief decision-maker. (He has since come out of retirement and is self-titled \"BDFL-emeritus\".) In January 2019, active Python core developers elected a five-member Steering Council to lead the project.\nThe name Py",
        "source": "python_programming_language.txt"
    },
    {
        "text": "Steering Council to lead the project.\nThe name Python is said to derive from the British comedy series Monty Python's Flying Circus.\nPython 2.0 was released on 16 October 2000, with many major new features such as list comprehensions, cycle-detecting garbage collection, reference counting, and Unicode support. Python 2.7's end-of-life was initially set for 2015, and then postponed to 2020 out of concern that a large body of existing code could not easily be forward-ported to Python 3. It no lon",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ot easily be forward-ported to Python 3. It no longer receives security patches or updates. While Python 2.7 and older versions are officially unsupported, a different unofficial Python implementation, PyPy, continues to support Python 2, i.e., \"2.7.18+\" (plus 3.10), with the plus signifying (at least some) \"backported security updates\".\nPython 3.0 was released on 3 December 2008, with some new semantics and changed syntax. Several releases in the Python 3.x series have added new syntax to the l",
        "source": "python_programming_language.txt"
    },
    {
        "text": "e Python 3.x series have added new syntax to the language; a few releases in 3.x have also removed outdated modules.\nAs of 8 April 2025, Python 3.13.3 is the latest stable release (it is highly recommended to upgrade to it, or upgrade to any other recent version past Python 3.9). This version currently receives full bug-fix and security updates, while Python 3.12—released in October 2023—had active bug-fix support only until April 2025, and since then only security fixes. Python 3.9 is the oldes",
        "source": "python_programming_language.txt"
    },
    {
        "text": "then only security fixes. Python 3.9 is the oldest supported version of Python (albeit in the 'security support' phase), because Python 3.8 has become an end-of-life product. Starting with Python 3.13, it and later versions receive two years of full support (which has increased from one and a half years), followed by three years of security support; this is the same total duration of support as previously.\nSecurity updates were expedited in 2021 and again twice in 2022. More issues were fixed i",
        "source": "python_programming_language.txt"
    },
    {
        "text": "and again twice in 2022. More issues were fixed in 2023 and in September 2024 (for Python versions 3.8.20 through 3.12.6)—all versions (including 2.7) had been insecure because of issues leading to possible remote code execution and web-cache poisoning.   \nPython 3.10 added the | union type operator and added structural pattern matching capability to the language, with the new match and case keywords. Python 3.11 expanded exception handling functionality. Python 3.12 added the new keyword type.",
        "source": "python_programming_language.txt"
    },
    {
        "text": "tionality. Python 3.12 added the new keyword type. Notable changes from version 3.10 to 3.11 include increased program execution speed and improved error reporting. Python 3.11 is claimed to be 10–60% faster than Python 3.10, and Python 3.12 increases by an additional 5%. Python 3.12 also includes improved error messages (again improved in 3.14) and many other changes.\nPython 3.13 introduced more syntax for types; a new and improved interactive interpreter (REPL), featuring multi-line editing an",
        "source": "python_programming_language.txt"
    },
    {
        "text": "nterpreter (REPL), featuring multi-line editing and color support; an incremental garbage collector, which results in shorter pauses for collection in programs that have many objects, as well as increasing the improved speed in 3.11 and 3.12);  an experimental just-in-time (JIT) compiler (such features need to be enabled specifically for the increase in speed); and an experimental free-threaded build mode, which disables the global interpreter lock (GIL), allowing threads to run more concurrentl",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ck (GIL), allowing threads to run more concurrently, as enabled in python3.13t or python3.13t.exe.\nPython Enhancement Proposal (PEP) 711 proposes PyBI—a standard format for distributing Python binaries.\nPython 3.14.0 is now in the beta 4 phase (introduces e.g. a new opt-in interpreter, up to 30% faster).\nPython 3.15 will \"Make UTF-8 mode default\"; This mode is supported in all current Python versions, but it currently must be opted into. UTF-8 is already used by default on Windows (and other ope",
        "source": "python_programming_language.txt"
    },
    {
        "text": "already used by default on Windows (and other operating systems) for most purposes; an exception is opening files. Enabling UTF-8 also makes code fully cross-platform.\n\nPotentially breaking changes\nPython 3.0 introduced very breaking changes, but all breaking changes in 3.x discussed below, are designed to affect few users.\nPython 3.12 dropped some outdated modules, and more will be dropped in the future, deprecated as of 3.13; already deprecated array 'u' format code will emit DeprecationWarni",
        "source": "python_programming_language.txt"
    },
    {
        "text": "d array 'u' format code will emit DeprecationWarning since 3.13 and will be removed in Python 3.16. The 'w' format code should be used instead. Part of ctypes is also deprecated and http.server.CGIHTTPRequestHandler will emit a DeprecationWarning, and will be removed in 3.15. Using that code already has a high potential for both security and functionality bugs. Parts of the typing module are deprecated, e.g. creating a typing.NamedTuple class using keyword arguments to denote the fields and such",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ng keyword arguments to denote the fields and such (and more) will be disallowed in Python 3.15. Python 3.12 removed wstr meaning Python extensions need to be modified.\nPython 3.13 introduces some changes in behavior, i.e., new \"well-defined semantics\", fixing bugs, and removing many deprecated classes, functions and methods (as well as some of the Python/C API and outdated modules). \"The  old implementation of locals() and frame.f_locals was slow, inconsistent and buggy,  and it had many corner",
        "source": "python_programming_language.txt"
    },
    {
        "text": "w, inconsistent and buggy,  and it had many corner cases and oddities. Code that works around those may need revising; code that uses locals() for simple templating or print debugging should continue to work correctly.\"\nPython 3.13 introduces the experimental free-threaded build mode, which disables the Global Interpreter Lock (GIL); the GIL is a feature of CPython that previously prevented multiple threads from executing Python bytecode simultaneously. This optional build, introduced through PE",
        "source": "python_programming_language.txt"
    },
    {
        "text": "eously. This optional build, introduced through PEP 703, enables better exploitation of multi-core CPUs. By allowing multiple threads to run Python code in parallel, the free-threaded mode addresses long-standing performance bottlenecks associated with the GIL. This change offers a new path for parallelism in Python, without resorting to multiprocessing or external concurrency frameworks.\nRegarding annotations in upcoming Python version: \"In Python 3.14, from __future__ import annotations will c",
        "source": "python_programming_language.txt"
    },
    {
        "text": "on 3.14, from __future__ import annotations will continue to work as it did before, converting annotations into strings.\"\nPython 3.14 drops the PGP digital verification signatures, it had deprecated in version 3.11, when its replacement Sigstore was added for all CPython artifacts; the use of PGP has been criticized by security practitioners.\nSome additional standard-library modules will be removed in Python 3.15 or 3.16, as will be many deprecated classes, functions and methods.\n\n\n== Design phi",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ed classes, functions and methods.\n\n\n== Design philosophy and features ==\nPython is a multi-paradigm programming language. Object-oriented programming and structured programming are fully supported, and many of their features support functional programming and aspect-oriented programming (including metaprogramming and metaobjects). Many other paradigms are supported via extensions, including design by contract and logic programming. Python is often referred to as a 'glue language' because it can",
        "source": "python_programming_language.txt"
    },
    {
        "text": "en referred to as a 'glue language' because it can seamlessly integrate components written in other languages.\nPython uses dynamic typing and a combination of reference counting and a cycle-detecting garbage collector for memory management. It uses dynamic name resolution (late binding), which binds method and variable names during program execution.\nPython's design offers some support for functional programming in the Lisp tradition. It has filter,mapandreduce functions; list comprehensions, di",
        "source": "python_programming_language.txt"
    },
    {
        "text": "er,mapandreduce functions; list comprehensions, dictionaries, sets, and generator expressions. The standard library has two modules (itertools and functools) that implement functional tools borrowed from Haskell and Standard ML.\nPython's core philosophy is summarized in the Zen of Python (PEP 20), which includes aphorisms such as these:\n\nBeautiful is better than ugly.\nExplicit is better than implicit.\nSimple is better than complex.\nComplex is better than complicated.\nReadability counts.\nHowever,",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ter than complicated.\nReadability counts.\nHowever, Python features regularly violate these principles and have received criticism for adding unnecessary language bloat. Responses to these criticisms note that the Zen of Python is a guideline rather than a rule. The addition of some new features had been controversial: Guido van Rossum resigned as Benevolent Dictator for Life after conflict about adding the assignment expression operator in Python 3.8.\nNevertheless, rather than building all funct",
        "source": "python_programming_language.txt"
    },
    {
        "text": "3.8.\nNevertheless, rather than building all functionality into its core, Python was designed to be highly extensible via modules. This compact modularity has made it particularly popular as a means of adding programmable interfaces to existing applications. Van Rossum's vision of a small core language with a large standard library and easily extensible interpreter stemmed from his frustrations with ABC, which represented the opposite approach.\nPython claims to strive for a simpler, less-clutter",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ython claims to strive for a simpler, less-cluttered syntax and grammar, while giving developers a choice in their coding methodology. In contrast to Perl's motto \"there is more than one way to do it\", Python advocates an approach where \"there should be one—and preferably only one—obvious way to do it.\". In practice, however, Python provides many ways to achieve a given goal. There are, for example, at least three ways to format a string literal, with no certainty as to which one a programmer sh",
        "source": "python_programming_language.txt"
    },
    {
        "text": "with no certainty as to which one a programmer should use. Alex Martelli is a Fellow at the Python Software Foundation and Python book author; he wrote that \"To describe something as 'clever' is not considered a compliment in the Python culture.\"\nPython's developers usually try to avoid premature optimization; they also reject patches to non-critical parts of the CPython reference implementation that would offer marginal increases in speed at the cost of clarity. Execution speed can be improved",
        "source": "python_programming_language.txt"
    },
    {
        "text": "e cost of clarity. Execution speed can be improved by moving speed-critical functions to extension modules written in languages such as C, or by using a just-in-time compiler like PyPy. It is also possible to cross-compile to other languages; but this approach either fails to achieve the expected speed-up, since Python is a very dynamic language, or only a restricted subset of Python is compiled (with potential minor semantic changes).\nPython's developers aim for the language to be fun to use. T",
        "source": "python_programming_language.txt"
    },
    {
        "text": "evelopers aim for the language to be fun to use. This goal is reflected in the name—a tribute to the British comedy group Monty Python—and in playful approaches to some tutorials and reference materials. For instance, some code examples use the terms \"spam\" and \"eggs\" (in reference to a Monty Python sketch), rather than the typical terms \"foo\" and \"bar\". A common neologism in the Python community is pythonic, which has a wide range of meanings related to program style. Pythonic code may use Pyth",
        "source": "python_programming_language.txt"
    },
    {
        "text": "lated to program style. Pythonic code may use Python idioms well; be natural or show fluency in the language; or conform with Python's minimalist philosophy and emphasis on readability.\n\n\n== Syntax and semantics ==\n\nPython is meant to be an easily readable language. Its formatting is visually uncluttered and often uses English keywords where other languages use punctuation. Unlike many other languages, it does not use curly brackets to delimit blocks, and semicolons after statements are allowed",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ocks, and semicolons after statements are allowed but rarely used. It has fewer syntactic exceptions and special cases than C or Pascal.\n\n\n=== Indentation ===\n\nPython uses whitespace indentation, rather than curly brackets or keywords, to delimit blocks. An increase in indentation comes after certain statements; a decrease in indentation signifies the end of the current block. Thus, the program's visual structure accurately represents its semantic structure. This feature is sometimes termed the",
        "source": "python_programming_language.txt"
    },
    {
        "text": "c structure. This feature is sometimes termed the off-side rule. Some other languages use indentation this way; but in most, indentation has no semantic meaning. The recommended indent size is four spaces.\n\n\n=== Statements and control flow ===\nPython's statements include the following:\n\nThe assignment statement, using a single equals sign =\nThe if statement, which conditionally executes a block of code, along with else and elif (a contraction of else if)\nThe for statement, which iterates over an",
        "source": "python_programming_language.txt"
    },
    {
        "text": "else if)\nThe for statement, which iterates over an iterable object, capturing each element to a local variable for use by the attached block\nThe while statement, which executes a block of code as long as boolean condition is true\nThe try statement, which allows exceptions raised in its attached code block to be caught and handled by except clauses (or new syntax except* in Python 3.11 for exception groups); the try statement also ensures that clean-up code in a finally block is always run regard",
        "source": "python_programming_language.txt"
    },
    {
        "text": "an-up code in a finally block is always run regardless of how the block exits\nThe raise statement, used to raise a specified exception or re-raise a caught exception\nThe class statement, which executes a block of code and attaches its local namespace to a class, for use in object-oriented programming\nThe def statement, which defines a function or method\nThe with statement, which encloses a code block within a context manager, allowing resource-acquisition-is-initialization (RAII)-like behavior a",
        "source": "python_programming_language.txt"
    },
    {
        "text": "quisition-is-initialization (RAII)-like behavior and replacing a common try/finally idiom Examples of a context include acquiring a lock before some code is run, and then releasing the lock; or opening and then closing a file\nThe break statement, which exits a loop\nThe continue statement, which skips the rest of the current iteration and continues with the next\nThe del statement, which removes a variable—deleting the reference from the name to the value, and producing an error if the variable is",
        "source": "python_programming_language.txt"
    },
    {
        "text": "e value, and producing an error if the variable is referred to before it is redefined \nThe pass statement, serving as a NOP (i.e., no operation), which is syntactically needed to create an empty code block\nThe assert statement, used in debugging to check for conditions that should apply\nThe yield statement, which returns a value from a generator function (and also an operator); used to implement coroutines\nThe return statement, used to return a value from a function\nThe import and from statement",
        "source": "python_programming_language.txt"
    },
    {
        "text": "alue from a function\nThe import and from statements, used to import modules whose functions or variables can be used in the current program\nThe match and case statements, analogous to a switch statement construct, which compares an expression against one or more cases as a control-flow measure\nThe assignment statement (=) binds a name as a reference to a separate, dynamically allocated object. Variables may subsequently be rebound at any time to any object. In Python, a variable name is a generi",
        "source": "python_programming_language.txt"
    },
    {
        "text": "any object. In Python, a variable name is a generic reference holder without a fixed data type; however, it always refers to some object with a type. This is called dynamic typing—in contrast to statically-typed languages, where each variable may contain only a value of a certain type.\nPython does not support tail call optimization or first-class continuations; according to Van Rossum, the language never will. However, better support for coroutine-like functionality is provided by extending Pyth",
        "source": "python_programming_language.txt"
    },
    {
        "text": "e-like functionality is provided by extending Python's generators. Before 2.5, generators were lazy iterators; data was passed unidirectionally out of the generator. From Python 2.5 on, it is possible to pass data back into a generator function; and from version 3.3, data can be passed through multiple stack levels.\n\n\n=== Expressions ===\nPython's expressions include the following:\n\nThe +, -, and * operators for mathematical addition, subtraction, and multiplication are similar to other languages",
        "source": "python_programming_language.txt"
    },
    {
        "text": "and multiplication are similar to other languages, but the behavior of division differs. There are two types of division in Python: floor division (or integer division) //, and floating-point division /. Python uses the ** operator for exponentiation.\nPython uses the + operator for string concatenation. The language uses the * operator for duplicating a string a specified number of times.\nThe @ infix operator is intended to be used by libraries such as NumPy for matrix multiplication.\nThe synta",
        "source": "python_programming_language.txt"
    },
    {
        "text": "such as NumPy for matrix multiplication.\nThe syntax :=, called the \"walrus operator\", was introduced in Python 3.8. This operator assigns values to variables as part of a larger expression.\nIn Python, == compares two objects by value. Python's is operator may be used to compare object identities (i.e., comparison by reference), and comparisons may be chained—for example, a <= b <= c.\nPython uses and, or, and not as Boolean operators.\nPython has a type of expression called a list comprehension, a",
        "source": "python_programming_language.txt"
    },
    {
        "text": "type of expression called a list comprehension, and a more general expression called a generator expression.\nAnonymous functions are implemented using lambda expressions; however, there may be only one expression in each body.\nConditional expressions are written as x if c else y. (This is different in operand order from the c ? x : y operator common to many other languages.)\nPython makes a distinction between lists and tuples. Lists are written as [1, 2, 3], are mutable, and cannot be used as t",
        "source": "python_programming_language.txt"
    },
    {
        "text": "as [1, 2, 3], are mutable, and cannot be used as the keys of dictionaries (since dictionary keys must be immutable in Python). Tuples, written as (1, 2, 3), are immutable and thus can be used as the keys of dictionaries, provided that all of the tuple's elements are immutable. The + operator can be used to concatenate two tuples, which does not directly modify their contents, but produces a new tuple containing the elements of both. For example, given the variable t initially equal to (1, 2, 3),",
        "source": "python_programming_language.txt"
    },
    {
        "text": "given the variable t initially equal to (1, 2, 3), executing t = t + (4, 5) first evaluates t + (4, 5), which yields (1, 2, 3, 4, 5); this result is then assigned back to t—thereby effectively \"modifying the contents\" of t while conforming to the immutable nature of tuple objects. Parentheses are optional for tuples in unambiguous contexts.\nPython features sequence unpacking where multiple expressions, each evaluating to something assignable (e.g., a variable or a writable property) are associat",
        "source": "python_programming_language.txt"
    },
    {
        "text": "., a variable or a writable property) are associated just as in forming tuple literal; as a whole, the results are then put on the left-hand side of the equal sign in an assignment statement. This statement expects an iterable object on the right-hand side of the equal sign to produce the same number of values as the writable expressions on the left-hand side; while iterating, the statement assigns each of the values produced on the right to the corresponding expression on the left.\nPython has a",
        "source": "python_programming_language.txt"
    },
    {
        "text": "corresponding expression on the left.\nPython has a \"string format\" operator % that functions analogously to printf format strings in the C language—e.g. \"spam=%s eggs=%d\" % (\"blah\", 2) evaluates to \"spam=blah eggs=2\". In Python 2.6+ and 3+, this operator was supplemented by the format() method of the str class, e.g., \"spam={0} eggs={1}\".format(\"blah\", 2). Python 3.6 added \"f-strings\": spam = \"blah\"; eggs = 2; f'spam={spam} eggs={eggs}'.\nStrings in Python can be concatenated by \"adding\" them (usi",
        "source": "python_programming_language.txt"
    },
    {
        "text": "n Python can be concatenated by \"adding\" them (using the same operator as for adding integers and floats); e.g., \"spam\" + \"eggs\" returns \"spameggs\". If strings contain numbers, they are concatenated as strings rather than as integers, e.g. \"2\" + \"2\" returns \"22\".\nPython supports string literals in several ways:\nDelimited by single or double quotation marks; single and double quotation marks have equivalent functionality (unlike in Unix shells, Perl, and Perl-influenced languages). Both marks use",
        "source": "python_programming_language.txt"
    },
    {
        "text": "rl, and Perl-influenced languages). Both marks use the backslash (\\) as an escape character. String interpolation became available in Python 3.6 as \"formatted string literals\".\nTriple-quoted, i.e., starting and ending with three single or double quotation marks; this may span multiple lines and function like here documents in shells, Perl, and Ruby.\nRaw string varieties, denoted by prefixing the string literal with r. Escape sequences are not interpreted; hence raw strings are useful where liter",
        "source": "python_programming_language.txt"
    },
    {
        "text": "erpreted; hence raw strings are useful where literal backslashes are common, such as in regular expressions and Windows-style paths. (Compare \"@-quoting\" in C#.)\nPython has array index and array slicing expressions in lists, which are written as a[key], a[start:stop] or a[start:stop:step]. Indexes are zero-based, and negative indexes are relative to the end. Slices take elements from the start index up to, but not including, the stop index. The (optional) third slice parameter, called step or st",
        "source": "python_programming_language.txt"
    },
    {
        "text": "optional) third slice parameter, called step or stride, allows elements to be skipped or reversed. Slice indexes may be omitted—for example, a[:] returns a copy of the entire list. Each element of a slice is a shallow copy.\nIn Python, a distinction between expressions and statements is rigidly enforced, in contrast to languages such as Common Lisp, Scheme, or Ruby. This distinction leads to duplicating some functionality, for example:\n\nList comprehensions vs. for-loops\nConditional expressions vs",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ehensions vs. for-loops\nConditional expressions vs. if blocks\nThe eval() vs. exec() built-in functions (in Python 2, exec is a statement); the former function is for expressions, while the latter is for statements\nA statement cannot be part of an expression; because of this restriction, expressions such as list and dict comprehensions (and lambda expressions) cannot contain statements. As a particular case, an assignment statement such as a = 1 cannot be part of the conditional expression of a c",
        "source": "python_programming_language.txt"
    },
    {
        "text": "annot be part of the conditional expression of a conditional statement.\n\n\n=== Methods ===\nMethods of objects are functions attached to the object's class; the syntax for normal methods and functions, instance.method(argument), is syntactic sugar for Class.method(instance, argument). Python methods have an explicit self parameter to access instance data, in contrast to the implicit self (or this) parameter in some object-oriented programming languages (e.g., C++, Java, Objective-C, Ruby). Python",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ages (e.g., C++, Java, Objective-C, Ruby). Python also provides methods, often called dunder methods (because their names begin and end with double underscores); these methods allow user-defined classes to modify how they are handled by native operations including length, comparison, arithmetic, and type conversion.\n\n\n=== Typing ===\n\nPython uses duck typing, and it has typed objects but untyped variable names. Type constraints are not checked at definition time; rather, operations on an object m",
        "source": "python_programming_language.txt"
    },
    {
        "text": "definition time; rather, operations on an object may fail at usage time, indicating that the object is not of an appropriate type. Despite being dynamically typed, Python is strongly typed, forbidding operations that are poorly defined (e.g., adding a number and a string) rather than quietly attempting to interpret them.\nPython allows programmers to define their own types using classes, most often for object-oriented programming. New instances of classes are constructed by calling the class, for",
        "source": "python_programming_language.txt"
    },
    {
        "text": "classes are constructed by calling the class, for example, SpamClass() or EggsClass()); the classes are instances of the metaclass type (which is an instance of itself), thereby allowing metaprogramming and reflection.\nBefore version 3.0, Python had two kinds of classes, both using the same syntax: old-style and new-style. Current Python versions support the semantics of only the new style.\nPython supports optional type annotations. These annotations are not enforced by the language, but may be",
        "source": "python_programming_language.txt"
    },
    {
        "text": "tions are not enforced by the language, but may be used by external tools such as mypy to catch errors. Mypy also supports a Python compiler called mypyc, which leverages type annotations for optimization.\n\n\n=== Arithmetic operations ===\nPython includes conventional symbols for arithmetic operators (+, -, *, /), the floor-division operator //, and the modulo operator %. (With the module operator, a remainder can be negative, e.g., 4 % -3 == -2.) Python also offers the ** symbol for exponentiatio",
        "source": "python_programming_language.txt"
    },
    {
        "text": "Python also offers the ** symbol for exponentiation, e.g. 5**3 == 125 and 9**0.5 == 3.0; it also offers the matrix‑multiplication operator @ . These operators work as in traditional mathematics; with the same precedence rules, the infix operators + and - can also be unary, to represent positive and negative numbers respectively.\nDivision between integers produces floating-point results. The behavior of division has changed significantly over time:\n\nThe current version of Python (i.e., since 3.0)",
        "source": "python_programming_language.txt"
    },
    {
        "text": ":\n\nThe current version of Python (i.e., since 3.0) changed the / operator to always represent floating-point division, e.g., 5/2 == 2.5.\nThe floor division // operator was introduced. Thus 7//3 == 2, -7//3 == -3, 7.5//3 == 2.0, and -7.5//3 == -3.0. For outdated Python 2.7 adding the from __future__ import division statement causes a module in Python 2.7 to use Python 3.0 rules for division instead (see above).\nIn Python terms, the / operator represents true division (or simply division), while t",
        "source": "python_programming_language.txt"
    },
    {
        "text": "esents true division (or simply division), while the // operator represents floor division. Before version 3.0, the / operator represents classic division.\nRounding towards negative infinity, though a different method than in most languages, adds consistency to Python. For instance, this rounding implies that the equation (a + b)//b == a//b + 1 is always true. The rounding also implies that the equation b*(a//b) + a%b == a is valid for both positive and negative values of a. As expected, the res",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ive and negative values of a. As expected, the result of a%b lies in the half-open interval [0, b), where b is a positive integer; however, maintaining the validity of the equation requires that the result must lie in the interval (b, 0] when b is negative.\nPython provides a round function for rounding a float to the nearest integer. For tie-breaking, Python 3 uses the round to even method: round(1.5) and round(2.5) both produce 2. Python versions before 3 used the round-away-from-zero method: r",
        "source": "python_programming_language.txt"
    },
    {
        "text": "s before 3 used the round-away-from-zero method: round(0.5) is 1.0, and round(-0.5) is −1.0.\nPython allows Boolean expressions that contain multiple equality relations to be consistent with general usage in mathematics. For example, the expression a < b < c tests whether a is less than b and b is less than c. C-derived languages interpret this expression differently: in C, the expression would first evaluate a < b, resulting in 0 or 1, and that result would then be compared with c.\nPython uses a",
        "source": "python_programming_language.txt"
    },
    {
        "text": "esult would then be compared with c.\nPython uses arbitrary-precision arithmetic for all integer operations. The Decimal type/class in the decimal module provides decimal floating-point numbers to a pre-defined arbitrary precision with several rounding modes. The Fraction class in the fractions module provides arbitrary precision for rational numbers.\nDue to Python's extensive mathematics library and the third-party library NumPy, the language is frequently used for scientific scripting in tasks",
        "source": "python_programming_language.txt"
    },
    {
        "text": "frequently used for scientific scripting in tasks such as numerical data processing and manipulation.\n\n\n=== Function syntax ===\nFunctions are created in Python by using the def keyword. A function is defined similarly to how it is called, by first providing the function name and then the required parameters. Here is an example of a function that prints its inputs:\n\nTo assign a default value to a function parameter in case no actual value is provided at run time, variable-definition syntax can be",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ded at run time, variable-definition syntax can be used inside the function header.\n\n\n== Code examples ==\n\"Hello, World!\" program:\n\nProgram to calculate the factorial of a positive integer:\n\n\n== Libraries ==\nPython's large standard library is commonly cited as one of its greatest strengths. For Internet-facing applications, many standard formats and protocols such as MIME and HTTP are supported. The language includes modules for creating graphical user interfaces, connecting to relational databa",
        "source": "python_programming_language.txt"
    },
    {
        "text": "l user interfaces, connecting to relational databases, generating pseudorandom numbers, arithmetic with arbitrary-precision decimals, manipulating regular expressions, and unit testing.\nSome parts of the standard library are covered by specifications—for example, the Web Server Gateway Interface (WSGI) implementation wsgiref follows PEP 333—but most parts are specified by their code, internal documentation, and test suites. However, because most of the standard library is cross-platform Python c",
        "source": "python_programming_language.txt"
    },
    {
        "text": "of the standard library is cross-platform Python code, only a few modules must be altered or rewritten for variant implementations.\nAs of 13 March 2025, the Python Package Index (PyPI), the official repository for third-party Python software, contains over 614,339 packages. These have a wide range of functionality, including the following:\n\n\n== Development environments ==\n\nMost Python implementations (including CPython) include a read–eval–print loop (REPL); this permits the environment to funct",
        "source": "python_programming_language.txt"
    },
    {
        "text": "loop (REPL); this permits the environment to function as a command line interpreter, with which users enter statements sequentially and receive results immediately.\nPython is also bundled with an integrated development environment (IDE) called IDLE, which is oriented toward beginners.\nOther shells, including IDLE and IPython, add additional capabilities such as improved auto-completion, session-state retention, and syntax highlighting.\nStandard desktop IDEs include PyCharm, IntelliJ Idea, Visual",
        "source": "python_programming_language.txt"
    },
    {
        "text": "esktop IDEs include PyCharm, IntelliJ Idea, Visual Studio Code; there are also web browser-based IDEs, such as the following environments:\n\nSageMath, for developing science- and math-related programs;\nJupyter Notebooks, an open-source interactive computing platform;\nPythonAnywhere, a browser-based IDE and hosting environment; and\nCanopy IDE, a commercial IDE that emphasizes scientific computing.\n\n\n== Implementations ==\n\n\n=== Reference implementation ===\nCPython is the reference implementation of",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ion ===\nCPython is the reference implementation of Python. This implementation is written in C, meeting the C11 standard (since version 3.11, older versions use the C89 standard with several select C99 features), but third-party extensions are not limited to older C versions—e.g., they can be implemented using C11 or C++. CPython compiles Python programs into an intermediate bytecode, which is then executed by a virtual machine. CPython is distributed with a large standard library written in a c",
        "source": "python_programming_language.txt"
    },
    {
        "text": "buted with a large standard library written in a combination of C and native Python.\nCPython is available for many platforms, including Windows and most modern Unix-like systems, including macOS (and Apple M1 Macs, since Python 3.9.1, using an experimental installer). Starting with Python 3.9, the Python installer intentionally fails to install on Windows 7 and 8; Windows XP was supported until Python 3.5, with unofficial support for VMS. Platform portability was one of Python's earliest priorit",
        "source": "python_programming_language.txt"
    },
    {
        "text": "m portability was one of Python's earliest priorities. During development of Python 1 and 2, even OS/2 and Solaris were supported; since that time, support has been dropped for many platforms.\nAll current Python versions (since 3.7) support only operating systems that feature multithreading, by now supporting not nearly as many operating systems (dropping many outdated) than in the past.\n\n\n=== Other implementations ===\nAll alternative implementations have at least slightly different semantic. Fo",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ions have at least slightly different semantic. For example, an alternative may include unordered dictionaries, in contrast to other current Python versions. As another example in the larger Python ecosystem, PyPy does not support the full C Python API. Alternative implementations include the following:\n\nPyPy is a fast, compliant interpreter of Python 2.7 and  3.10. PyPy's just-in-time compiler often improves speed significantly relative to CPython, but PyPy does not support some libraries writt",
        "source": "python_programming_language.txt"
    },
    {
        "text": "on, but PyPy does not support some libraries written in C. PyPy offers support for the RISC-V instruction-set architecture.\nCodon is an implentation with an ahead-of-time (AOT) compiler, which compiles a statically-typed Python-like language whose \"syntax and semantics are nearly identical to Python's, there are some notable differences\" For example, Codon uses 64-bit machine integers for speed, not arbitrarily as with Python; Codon developers claim that speedups over CPython are usually on the",
        "source": "python_programming_language.txt"
    },
    {
        "text": "aim that speedups over CPython are usually on the order of ten to a hundred times. Codon compiles to machine code (via LLVM) and supports native multithreading.  Codon can also compile to Python extension modules that can be imported and used from Python.\nMicroPython and CircuitPython are Python 3 variants that are optimized for microcontrollers, including the Lego Mindstorms EV3.\nPyston is a variant of the Python runtime that uses just-in-time compilation to speed up execution of Python program",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ompilation to speed up execution of Python programs.\nCinder is a performance-oriented fork of CPython 3.8 that features a number of optimizations, including bytecode inline caching, eager evaluation of coroutines, a method-at-a-time JIT, and an experimental bytecode compiler.\nThe Snek embedded computing language \"is Python-inspired, but it is not Python. It is possible to write Snek programs that run under a full Python system, but most Python programs will not run under Snek.\" Snek is compatibl",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ograms will not run under Snek.\" Snek is compatible with 8-bit AVR microcontrollers such as ATmega 328P-based Arduino, as well as larger microcontrollers that are compatible with MicroPython. Snek is an imperative language that (unlike Python) omits object-oriented programming. Snek supports only one numeric data type, which features 32-bit single precision (resembling JavaScript numbers, though smaller).\n\n\n=== Unsupported implementations ===\nStackless Python is a significant fork of CPython tha",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ckless Python is a significant fork of CPython that implements microthreads. This implementation uses the call stack differently, thus allowing massively concurrent programs. PyPy also offers a stackless version.\nJust-in-time Python compilers have been developed, but are now unsupported:\n\nGoogle began a project named Unladen Swallow in 2009: this project aimed to speed up the Python interpreter five-fold by using LLVM, and improve multithreading capability for scaling to thousands of cores, whil",
        "source": "python_programming_language.txt"
    },
    {
        "text": "capability for scaling to thousands of cores, while typical implementations are limited by the global interpreter lock.\nPsyco is a discontinued just-in-time specializing compiler, which integrates with CPython and transforms bytecode to machine code at runtime. The emitted code is specialized for certain data types and is faster than standard Python code. Psyco does not support Python 2.7 or later.\nPyS60 was a Python 2 interpreter for Series 60 mobile phones, which was released by Nokia in 2005.",
        "source": "python_programming_language.txt"
    },
    {
        "text": "obile phones, which was released by Nokia in 2005. The interpreter implemented many modules from Python's standard library, as well as additional modules for integration with the Symbian operating system. The Nokia N900 also supports Python through the GTK widget library, allowing programs to be written and run on the target device.\n\n\n=== Cross-compilers to other languages ===\nThere are several compilers/transpilers to high-level object languages; the source language is unrestricted Python, a su",
        "source": "python_programming_language.txt"
    },
    {
        "text": "; the source language is unrestricted Python, a subset of Python, or a language similar to Python:\n\nBrython, Transcrypt, and Pyjs compile Python to JavaScript. (The latest release of Pyjs was in 2012.)\nCython compiles a superset of Python to C. The resulting code can be used with Python via direct C-level API calls into the Python interpreter.\nPyJL compiles/transpiles a subset of Python to \"human-readable, maintainable, and high-performance Julia source code\". Despite the developers' performance",
        "source": "python_programming_language.txt"
    },
    {
        "text": "source code\". Despite the developers' performance claims, this is not possible for arbitrary Python code; that is, compiling to a faster language or machine code is known to be impossible in the general case. The semantics of Python might potentially be changed, but in many cases speedup is possible with few or no changes in the Python code. The faster Julia source code can then be used from Python or compiled to machine code.\nNuitka compiles Python into C. This compiler works with Python 3.4 t",
        "source": "python_programming_language.txt"
    },
    {
        "text": "thon into C. This compiler works with Python 3.4 to 3.12 (and 2.6 and 2.7) for Python's main supported platforms (and Windows 7 or even Windows XP) and for Android. The compiler developers claim full support for Python 3.10, partial support for Python 3.11 and 3.12,  and experimental support for Python 3.13. Nuitka supports macOS including Apple Silicon-based versions.  The compiler is free of cost, though it has commercial add-ons (e.g., for hiding source code).\nNumba is a JIT compiler that is",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ing source code).\nNumba is a JIT compiler that is used from Python; the compiler translates a subset of Python and NumPy code into fast machine code. This tool is enabled by adding a decorator to the relevant Python code.\nPythran compiles a subset of Python 3 to C++ (C++11).\nRPython can be compiled to C, and it is used to build the PyPy interpreter for Python.\nThe Python → 11l → C++ transpiler compiles a subset of Python 3 to C++ (C++17).\nThere are also specialized compilers:\n\nMyHDL is a Python-",
        "source": "python_programming_language.txt"
    },
    {
        "text": "re also specialized compilers:\n\nMyHDL is a Python-based hardware description language (HDL) that converts MyHDL code to Verilog or VHDL code.\nSome older projects existed, as well as compilers not designed for use with Python 3.x and related syntax:\n\nGoogle's Grumpy transpiles Python 2 to Go. The latest release was in 2017.\nIronPython allows running Python 2.7 programs with the .NET Common Language Runtime. An alpha version (released in 2021), is available for \"Python 3.4, although features and b",
        "source": "python_programming_language.txt"
    },
    {
        "text": "available for \"Python 3.4, although features and behaviors from later versions may be included.\"\nJython compiles Python 2.7 to Java bytecode, allowing the use of Java libraries from a Python program.\nPyrex (last released in 2010) and Shed Skin (last released in 2013) compile to C and C++ respectively.\n\n\n=== Performance ===\nA performance comparison among various Python implementations, using a non-numerical (combinatorial) workload, was presented at EuroSciPy '13. In addition, Python's performanc",
        "source": "python_programming_language.txt"
    },
    {
        "text": "at EuroSciPy '13. In addition, Python's performance relative to other programming languages is benchmarked by The Computer Language Benchmarks Game.\nThere are several approaches to optimizing Python performance, given the inherent slowness of an interpreted language. These approaches include the following strategies or tools:\n\nJust-in-time compilation: Dynamically compiling Python code just before it is executed. This technique is used in libraries such as Numba and PyPy.\nStatic compilation: Pyt",
        "source": "python_programming_language.txt"
    },
    {
        "text": "es such as Numba and PyPy.\nStatic compilation: Python code is compiled into machine code sometime before execution. An example of this approach is Cython, which compiles Python into C.\nConcurrency and parallelism: Multiple tasks can be run simultaneously. Python contains modules such as `multiprocessing` to support this form of parallelism. Moreover, this approach helps to overcome limitations of the Global Interpreter Lock (GIL) in CPU tasks.\nEfficient data structures: Performance can also be i",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ficient data structures: Performance can also be improved by using data types such as Set for membership tests, or deque from collections for queue operations.\n\n\n== Language Development ==\nPython's development is conducted largely through the Python Enhancement Proposal (PEP) process; this process is the primary mechanism for proposing major new features, collecting community input on issues, and documenting Python design decisions. Python coding style is covered in PEP 8. Outstanding PEPs are r",
        "source": "python_programming_language.txt"
    },
    {
        "text": "style is covered in PEP 8. Outstanding PEPs are reviewed and commented on by the Python community and the steering council.\nEnhancement of the language corresponds with development of the CPython reference implementation. The mailing list python-dev is the primary forum for the language's development. Specific issues were originally discussed in the Roundup bug tracker hosted by the foundation. In 2022, all issues and discussions were migrated to GitHub. Development originally took place on a s",
        "source": "python_programming_language.txt"
    },
    {
        "text": "o GitHub. Development originally took place on a self-hosted source-code repository running Mercurial, until Python moved to GitHub in January 2017.\nCPython's public releases have three types, distinguished by which part of the version number is incremented:\n\nBackward-incompatible versions, where code is expected to break and must be manually ported. The first part of the version number is incremented. These releases happen infrequently—version 3.0 was released 8 years after 2.0. According to Gu",
        "source": "python_programming_language.txt"
    },
    {
        "text": ".0 was released 8 years after 2.0. According to Guido van Rossum, a version 4.0 will probably never exist.\nMajor or \"feature\" releases are largely compatible with the previous version but introduce new features. The second part of the version number is incremented. Starting with Python 3.9, these releases are expected to occur annually. Each major version is supported by bug fixes for several years after its release.\nBug fix releases, which introduce no new features, occur approximately every th",
        "source": "python_programming_language.txt"
    },
    {
        "text": "duce no new features, occur approximately every three months; these releases are made when a sufficient number of bugs have been fixed upstream since the last release. Security vulnerabilities are also patched in these releases. The third and final part of the version number is incremented.\nMany alpha, beta, and release-candidates are also released as previews and for testing before final releases. Although there is a rough schedule for releases, they are often delayed if the code is not ready y",
        "source": "python_programming_language.txt"
    },
    {
        "text": "they are often delayed if the code is not ready yet. Python's development team monitors the state of the code by running a large unit test suite during development.\nThe major academic conference on Python is PyCon. There are also special Python mentoring programs, such as PyLadies.\n\n\n== API documentation generators ==\nTools that can generate documentation for Python API include pydoc (available as part of the standard library); Sphinx; and Pdoc and its forks, Doxygen and Graphviz.\n\n\n== Naming =",
        "source": "python_programming_language.txt"
    },
    {
        "text": "and its forks, Doxygen and Graphviz.\n\n\n== Naming ==\nPython's name is inspired by the British comedy group Monty Python, whom Python creator Guido van Rossum enjoyed while developing the language. Monty Python references appear frequently in Python code and culture; for example, the metasyntactic variables often used in Python literature are spam and eggs, rather than the traditional foo and bar. The official Python documentation also contains various references to Monty Python routines. Python u",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ious references to Monty Python routines. Python users are sometimes referred to as \"Pythonistas\".\nThe affix Py is often used when naming Python applications or libraries. Some examples include the following:\n\nPygame, a binding of Simple DirectMedia Layer to Python (commonly used to create games);\nPyQt and PyGTK, which bind Qt and GTK to Python respectively;\nPyPy, a Python implementation originally written in Python;\nNumPy, a Python library for numerical processing.\n\n\n== Popularity ==\nSince 2003",
        "source": "python_programming_language.txt"
    },
    {
        "text": "umerical processing.\n\n\n== Popularity ==\nSince 2003, Python has consistently ranked in the top ten of the most popular programming languages in the TIOBE Programming Community Index; as of December 2022, Python was the most popular language. Python was selected as Programming Language of the Year (for \"the highest rise in ratings in a year\") in 2007, 2010, 2018, and 2020—the only language to have done so four times as of 2020). In the TIOBE Index, monthly rankings are based on the volume of searc",
        "source": "python_programming_language.txt"
    },
    {
        "text": "monthly rankings are based on the volume of searches for programming languages on Google, Amazon, Wikipedia, Bing, and 20 other platforms. According to the accompanying graph, Python has shown a marked upward trend since the early 2000s, eventually passing more established languages such as C, C++, and Java. This trend can be attributed to Python's readable syntax, comprehensive standard library, and application in data science and machine learning fields.\n\nLarge organizations that use Python i",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ing fields.\n\nLarge organizations that use Python include Wikipedia, Google, Yahoo!, CERN, NASA, Facebook, Amazon, Instagram, Spotify, and some smaller entities such as Industrial Light & Magic and ITA. The social news networking site Reddit was developed mostly in Python. Organizations that partly use Python include Discord and Baidu.\n\n\n== Types of Use ==\n\nPython has many uses, including the following:\n\nScripting for web applications\nScientific computing\nArtificial intelligence and machine learn",
        "source": "python_programming_language.txt"
    },
    {
        "text": "omputing\nArtificial intelligence and machine learning projects\nGraphical user interfaces and desktop environments\nEmbedded scripting in software and hardware products\nOperating systems\nInformation security\nPython can serve as a scripting language for web applications, e.g., via the mod_wsgi module for the Apache web server. With Web Server Gateway Interface, a standard API has evolved to facilitate these applications. Web frameworks such as Django, Pylons, Pyramid, TurboGears, web2py, Tornado, F",
        "source": "python_programming_language.txt"
    },
    {
        "text": "o, Pylons, Pyramid, TurboGears, web2py, Tornado, Flask, Bottle, and Zope support developers in the design and maintenance of complex applications. Pyjs and IronPython can be used to develop the client-side of Ajax-based applications. SQLAlchemy can be used as a data mapper to a relational database. Twisted is a framework to program communication between computers; this framework is used by Dropbox, for example.\nLibraries such as NumPy, SciPy and Matplotlib allow the effective use of Python in sc",
        "source": "python_programming_language.txt"
    },
    {
        "text": "Matplotlib allow the effective use of Python in scientific computing, with specialized libraries such as Biopython and Astropy providing domain-specific functionality. SageMath is a computer algebra system with a notebook interface that is programmable in Python; the SageMath library covers many aspects of mathematics, including algebra, combinatorics, numerical mathematics, number theory, and calculus. OpenCV has Python bindings with a rich set of features for computer vision and image processi",
        "source": "python_programming_language.txt"
    },
    {
        "text": "of features for computer vision and image processing.\nPython is commonly used in artificial-intelligence and machine-learning projects, with support from libraries such as TensorFlow, Keras, Pytorch, scikit-learn and ProbLog (a logic language). As a scripting language with a modular architecture, simple syntax, and rich text processing tools, Python is often used for natural language processing.\nThe combination of Python and Prolog has proven useful for AI applications, with Prolog providing kno",
        "source": "python_programming_language.txt"
    },
    {
        "text": "ful for AI applications, with Prolog providing knowledge representation and reasoning capabilities. The Janus system, in particular, exploits similarities between these two languages, in part because of their dynamic typing and their simple, recursive data structures. This combination is typically applied natural language processing, visual query answering, geospatial reasoning, and handling semantic web data.\nThe Natlog system, implemented in Python, uses Definite Clause Grammars (DCGs) to crea",
        "source": "python_programming_language.txt"
    },
    {
        "text": "thon, uses Definite Clause Grammars (DCGs) to create prompts for two types of generators: text-to-text generators such as GPT3, and text-to-image generators such as DALL-E or Stable Diffusion.\nPython can be used for graphical user interfaces (GUIs), by using libraries such as Tkinter. Similarly, for the One Laptop per Child XO computer, most of the Sugar desktop environment is written in Python (as of 2008).\nPython is embedded in many software products (and some hardware products) as a scripting",
        "source": "python_programming_language.txt"
    },
    {
        "text": "oducts (and some hardware products) as a scripting language. These products include the following: \n\nfinite element method software such as Abaqus,\n3D parametric modelers such as FreeCAD,\n3D animation packages such as 3ds Max, Blender, Cinema 4D, Lightwave, Houdini, Maya, modo, MotionBuilder, Softimage,\nthe visual effects compositor Nuke,\n2D imaging programs such as GIMP, Inkscape, Scribus and Paint Shop Pro, and\nmusical notation programs such as scorewriter and capella.\nSimilarly, GNU Debugger",
        "source": "python_programming_language.txt"
    },
    {
        "text": "scorewriter and capella.\nSimilarly, GNU Debugger uses Python as a pretty printer to show complex structures such as C++ containers. Esri promotes Python as the best choice for writing scripts in ArcGIS. Python has also been used in several video games, and it has been adopted as first of the three programming languages available in Google App Engine (the other two being Java and Go). LibreOffice includes Python, and its developers plan to replace Java with Python; LibreOffice's Python Scripting",
        "source": "python_programming_language.txt"
    },
    {
        "text": "e Java with Python; LibreOffice's Python Scripting Provider is a core feature since version 4.0 (from 7 February 2013). \nAmong hardware products, the Raspberry Pi single-board computer project has adopted Python as its main user-programming language.\nMany operating systems include Python as a standard component. Python ships with most Linux distributions, AmigaOS 4 (using Python 2.7), FreeBSD (as a package), NetBSD, and OpenBSD (as a package); it can be used from the command line (terminal). Man",
        "source": "python_programming_language.txt"
    },
    {
        "text": "can be used from the command line (terminal). Many Linux distributions use installers written in Python: Ubuntu uses the Ubiquity installer, while Red Hat Linux and Fedora Linux use the Anaconda installer. Gentoo Linux uses Python in its package management system, Portage.\nPython is used extensively in the information security industry, including in exploit development.\n\n\n== Languages influenced by Python ==\nPython's design and philosophy have influenced many other programming languages:\n\nBoo u",
        "source": "python_programming_language.txt"
    },
    {
        "text": "nfluenced many other programming languages:\n\nBoo uses indentation, a similar syntax, and a similar object model.\nCobra uses indentation and a similar syntax; its Acknowledgements document lists Python first among influencing languages.\nCoffeeScript, a programming language that cross-compiles to JavaScript, has a Python-inspired syntax.\nECMAScript–JavaScript borrowed iterators and generators from Python.\nGDScript, a Python-like scripting language that is built in to the Godot game engine.\nGo is d",
        "source": "python_programming_language.txt"
    },
    {
        "text": "that is built in to the Godot game engine.\nGo is designed for \"speed of working in a dynamic language like Python\"; Go shares Python's syntax for slicing arrays.\nGroovy was motivated by a desire to incorporate the Python design philosophy into Java.\nJulia was designed to be \"as usable for general programming as Python\".\nMojo is a non-strict superset of Python (e.g., omitting classes, and adding struct).\nNim uses indentation and a similar syntax.\nRuby's creator, Yukihiro Matsumoto, said that \"I w",
        "source": "python_programming_language.txt"
    },
    {
        "text": "Ruby's creator, Yukihiro Matsumoto, said that \"I wanted a scripting language that was more powerful than Perl, and more object-oriented than Python. That's why I decided to design my own language.\"\nSwift, a programming language developed by Apple, has some Python-inspired syntax.\nKotlin blends Python and Java features, which minimizes boilerplate code and enhances developer efficiency.\nPython's development practices have also been emulated by other languages. For example, Python requires a docum",
        "source": "python_programming_language.txt"
    },
    {
        "text": "er languages. For example, Python requires a document that describes the rationale and context for any language change; this document is known as a Python Enhancement Proposal or PEP. This practice is also used by the developers of Tcl, Erlang, and Swift.\n\n\n== See also ==\n\nPython syntax and semantics\npip (package manager)\nList of programming languages\nHistory of programming languages\nComparison of programming languages\n\n\n== Notes ==\n\n\n== References ==\n\n\n=== Sources ===\n\"Python for Artificial Int",
        "source": "python_programming_language.txt"
    },
    {
        "text": "es ==\n\n\n=== Sources ===\n\"Python for Artificial Intelligence\". Python Wiki. 19 July 2012. Archived from the original on 1 November 2012. Retrieved 3 December 2012.\nPaine, Jocelyn, ed. (August 2005). \"AI in Python\". AI Expert Newsletter. Amzi!. Archived from the original on 26 March 2012. Retrieved 11 February 2012.\n\"PyAIML 0.8.5 : Python Package Index\". Pypi.python.org. Retrieved 17 July 2013.\nRussell, Stuart J. & Norvig, Peter (2009). Artificial Intelligence: A Modern Approach (3rd ed.). Upper S",
        "source": "python_programming_language.txt"
    },
    {
        "text": "Intelligence: A Modern Approach (3rd ed.). Upper Saddle River, NJ: Prentice Hall. ISBN 978-0-13-604259-4.\n\n\n== Further reading ==\nDowney, Allen (July 2024). Think Python: How to Think Like a Computer Scientist (3rd ed.). O'Reilly Media. ISBN 978-1098155438.\nLutz, Mark (2013). Learning Python (5th ed.). O'Reilly Media. ISBN 978-0-596-15806-4.\nSummerfield, Mark (2009). Programming in Python 3 (2nd ed.). Addison-Wesley Professional. ISBN 978-0-321-68056-3.\nRamalho, Luciano (May 2022). Fluent Python",
        "source": "python_programming_language.txt"
    },
    {
        "text": "8056-3.\nRamalho, Luciano (May 2022). Fluent Python. O'Reilly Media. ISBN 978-1-4920-5632-4.\n\n\n== External links ==\n\nOfficial website \nThe Python Tutorial",
        "source": "python_programming_language.txt"
    },
    {
        "text": "In deep learning, transformer is an architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key tokens to be amplified and less important tokens to be dimini",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "e amplified and less important tokens to be diminished. \nTransformers have the advantage of having no recurrent units, therefore requiring less training time than earlier recurrent neural architectures (RNNs) such as long short-term memory (LSTM). Later variations have been widely adopted for training large language models (LLMs) on large (language) datasets.\n\nThe modern version of the transformer was proposed in the 2017 paper \"Attention Is All You Need\" by researchers at Google. Transformers w",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "You Need\" by researchers at Google. Transformers were first developed as an improvement over previous architectures for machine translation, but have found many applications since. They are used in large-scale natural language processing, computer vision (vision transformers), reinforcement learning, audio, multimodal learning, robotics, and even playing chess. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (bidirectional en",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "ned transformers (GPTs) and BERT (bidirectional encoder representations from transformers).\n\n\n== History ==\n\n\n=== Predecessors ===\nFor many years, sequence modelling and generation was done by using plain recurrent neural networks (RNNs). A well-cited early example was the Elman network (1990). In theory, the information from one token can propagate arbitrarily far down the sequence, but in practice the vanishing-gradient problem leaves the model's state at the end of a long sentence without pre",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "'s state at the end of a long sentence without precise, extractable information about preceding tokens.\nA key breakthrough was LSTM (1995), a RNN which used various innovations to overcome the vanishing gradient problem, allowing efficient learning of long-sequence modelling. One key innovation was the use of an attention mechanism which used neurons that multiply the outputs of other neurons, so-called multiplicative units. Neural networks using multiplicative units were later called sigma-pi n",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "multiplicative units were later called sigma-pi networks or higher-order networks. LSTM became the standard architecture for long sequence modelling until the 2017 publication of Transformers.\nHowever, LSTM still used sequential processing, like most other RNNs. Specifically, RNNs operate one token at a time from first to last; they cannot operate in parallel over all tokens in a sequence.\nModern Transformers overcome this problem, but unlike RNNs, they require computation time that is quadrati",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "Ns, they require computation time that is quadratic in the size of the context window. The linearly scaling fast weight controller (1992) learns to compute a weight matrix for further processing depending on the input. One of its two networks has \"fast weights\" or \"dynamic links\" (1981). A slow neural network learns by gradient descent to generate keys and values for computing the weight changes of the fast neural network which computes answers to queries. This was later shown to be equivalent t",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "o queries. This was later shown to be equivalent to the unnormalized linear Transformer.\n\n\n=== Attention with seq2seq ===\n\nThe idea of encoder-decoder sequence transduction had been developed in the early 2010s; commonly cited as the originators that produced seq2seq are two concurrently published papers from 2014.\nA 380M-parameter model for machine translation uses two long short-term memories (LSTM). Its architecture consists of two parts. The encoder is an LSTM that takes in a sequence of tok",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "encoder is an LSTM that takes in a sequence of tokens and turns it into a vector. The decoder is another LSTM that converts the vector into a sequence of tokens. Similarly, another 130M-parameter model used gated recurrent units (GRU) instead of LSTM. Later research showed that GRUs are neither better nor worse than LSTMs for seq2seq.\nThese early seq2seq models had no attention mechanism, and the state vector is accessible only after the last word of the source text was processed. Although in th",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "d of the source text was processed. Although in theory such a vector retains the information about the whole original sentence, in practice the information is poorly preserved. This is because the input is processed sequentially by one recurrent network into a fixed-size output vector, which is then processed by another recurrent network into an output. If the input is long, then the output vector would not be able to contain all relevant information, degrading the output. As evidence, reversing",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "tion, degrading the output. As evidence, reversing the input sentence improved seq2seq translation.\nThe RNNsearch model introduced an attention mechanism to seq2seq for machine translation to solve the bottleneck problem (of the fixed-size output vector), allowing the model to process long-distance dependencies more easily. The name is because it \"emulates searching through a source sentence during decoding a translation\".\nThe relative performances were compared between global (that of RNNsearch",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "es were compared between global (that of RNNsearch) and local (sliding window) attention model architectures for machine translation, finding that mixed attention had higher quality than global attention, while local attention reduced translation time.\nIn 2016, Google Translate was revamped to Google Neural Machine Translation, which replaced the previous model based on statistical machine translation. The new model was a seq2seq model where the encoder and the decoder were both 8 layers of bidi",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "encoder and the decoder were both 8 layers of bidirectional LSTM. It took nine months to develop, and it outperformed the statistical approach, which took ten years to develop.\n\n\n=== Parallelizing attention ===\n\nSeq2seq models with attention (including self-attention) still suffered from the same issue with recurrent networks, which is that they are hard to parallelize, which prevented them from being accelerated on GPUs. In 2016, decomposable attention applied a self-attention mechanism to feed",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "tention applied a self-attention mechanism to feedforward networks, which are easy to parallelize, and achieved SOTA result in textual entailment with an order of magnitude fewer parameters than LSTMs. One of its authors, Jakob Uszkoreit, suspected that attention without recurrence would be sufficient for language translation, thus the title \"attention is all you need\". That hypothesis was against conventional wisdom at the time, and even his father Hans Uszkoreit, a well-known computational lin",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "her Hans Uszkoreit, a well-known computational linguist, was skeptical. In the same year, self-attention (called intra-attention or intra-sentence attention) was proposed for LSTMs.\nIn 2017, the original (100M-sized) encoder-decoder transformer model was proposed in the \"Attention is all you need\" paper. At the time, the focus of the research was on improving seq2seq for machine translation, by removing its recurrence to process all tokens in parallel, but preserving its dot-product attention me",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "allel, but preserving its dot-product attention mechanism to keep its text processing performance. This led to the introduction of a multi-head attention model that was easier to parallelize due to the use of independent heads and the lack of recurrence. Its parallelizability was an important factor to its widespread use in large neural networks.\n\n\n=== AI boom era ===\nAlready in spring 2017, even before the \"Attention is all you need\" preprint was published, one of the co-authors applied the \"de",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "s published, one of the co-authors applied the \"decoder-only\" variation of the architecture to generate fictitious Wikipedia articles. Transformer architecture is now used alongside many generative models that contribute to the ongoing AI boom.\nIn language modelling, ELMo (2018) was a bi-directional LSTM that produces contextualized word embeddings, improving upon the line of research from bag of words and word2vec. It was followed by BERT (2018), an encoder-only Transformer model. In 2019 Octob",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ", an encoder-only Transformer model. In 2019 October, Google started using BERT to process search queries. In 2020, Google Translate replaced the previous RNN-encoder–RNN-decoder model by a Transformer-encoder–RNN-decoder model.\nStarting in 2018, the OpenAI GPT series of decoder-only Transformers became state of the art in natural language generation. In 2022, a chatbot based on GPT-3, ChatGPT, became unexpectedly popular, triggering a boom around large language models.\nSince 2020, Transformers",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "d large language models.\nSince 2020, Transformers have been applied in modalities beyond text, including the vision transformer, speech recognition, robotics, and multimodal. The vision transformer, in turn, stimulated new developments in convolutional neural networks. Image and video generators like DALL-E (2021), Stable Diffusion 3 (2024), and Sora (2024), use Transformers to analyse input data (like text prompts) by breaking it down into \"tokens\" and then calculating the relevance between eac",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "ns\" and then calculating the relevance between each token using self-attention, which helps the model understand the context and relationships within the data.\n\n\n== Training ==\n\n\n=== Methods for stabilizing training ===\nThe plain transformer architecture had difficulty converging. In the original paper the authors recommended using learning rate warmup. That is, the learning rate should linearly scale up from 0 to maximal value for the first part of the training (usually recommended to be 2% of",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "of the training (usually recommended to be 2% of the total number of training steps), before decaying again.\nA 2020 paper found that using layer normalization before (instead of after) multiheaded attention and feedforward layers stabilizes training, not requiring learning rate warmup.\n\n\n=== Pretrain-finetune ===\nTransformers typically are first pretrained by self-supervised learning on a large generic dataset, followed by supervised fine-tuning on a small task-specific dataset. The pretrain da",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "on a small task-specific dataset. The pretrain dataset is typically an unlabeled large corpus, such as The Pile. Tasks for pretraining and fine-tuning commonly include:\n\nlanguage modeling\nnext-sentence prediction\nquestion answering\nreading comprehension\nsentiment analysis\nparaphrasing\nThe T5 transformer report documents a large number of natural language pretraining tasks. Some examples are:\n\nrestoring or repairing incomplete or corrupted text. For example, the input, \"Thank you ~~ me to your p",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "For example, the input, \"Thank you ~~ me to your party ~~ week\", might generate the output, \"Thank you for inviting me to your party last week\".\ntranslation between natural languages (machine translation)\njudging the pragmatic acceptability of natural language. For example, the following sentence might be judged \"not acceptable\", because even though it is syntactically well-formed, it is improbable in ordinary human usage: The course is jumping well.\nNote that while each of these tasks is trivia",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "ell.\nNote that while each of these tasks is trivial or obvious for human native speakers of the language (or languages), they have typically proved challenging for previous generations of machine learning architecture.\n\n\n=== Tasks ===\n\nIn general, there are 3 classes of language modelling tasks: \"masked\", \"autoregressive\", and \"prefixLM\". These classes are independent of a specific modeling architecture such as Transformer, but they are often discussed in the context of Transformer.\nIn a masked",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "cussed in the context of Transformer.\nIn a masked task, one or more of the tokens is masked out, and the model would produce a probability distribution predicting what the masked-out tokens are based on the context. The loss function for the task is typically sum of log-perplexities for the masked-out tokens: \n  \n    \n      \n        \n          Loss\n        \n        =\n        −\n        \n          ∑\n          \n            t\n            ∈\n            \n              masked tokens",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "masked tokens\n            \n          \n        \n        ln\n        ⁡\n        (\n        \n          probability of \n        \n        t\n        \n           conditional on its context\n        \n        )\n      \n    \n    {\\displaystyle {\\text{Loss}}=-\\sum _{t\\in {\\text{masked tokens}}}\\ln({\\text{probability of }}t{\\text{ conditional on its context}})}\n  \nand the model is trained to minimize this loss function. The BERT series of models are trained for masked token prediction and anothe",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "are trained for masked token prediction and another task.\nIn an autoregressive task, the entire sequence is masked at first, and the model produces a probability distribution for the first token. Then the first token is revealed and the model predicts the second token, and so on. The loss function for the task is still typically the same. The GPT series of models are trained by autoregressive tasks.\nIn a prefixLM task, the sequence is divided into two parts. The first part is presented as contex",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "o two parts. The first part is presented as context, and the model predicts the first token of the second part. Then that would be revealed, and the model predicts the second token, and so on. The loss function for the task is still typically the same. The T5 series of models are trained by prefixLM tasks.\nNote that \"masked\" as in \"masked language modelling\" is not \"masked\" as in \"masked attention\", and \"prefixLM\" (prefix language modeling) is not \"prefixLM\" (prefix language model).\n\n\n== Archite",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "t \"prefixLM\" (prefix language model).\n\n\n== Architecture ==\nAll transformers have the same primary components:\n\nTokenizers, which convert text into tokens.\nEmbedding layer, which converts tokens and positions of the tokens into vector representations.\nTransformer layers, which carry out repeated transformations on the vector representations, extracting more and more linguistic information. These consist of alternating attention and feedforward layers. There are two major types of transformer laye",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "ers. There are two major types of transformer layers: encoder layers and decoder layers, with further variants.\nUn-embedding layer, which converts the final vector representations back to a probability distribution over the tokens.\nThe following description follows exactly the Transformer as described in the original paper. There are variants, described in the following section.\nBy convention, we write all vectors as row vectors. This, for example, means that pushing a vector through a linear la",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "e, means that pushing a vector through a linear layer means multiplying it by a weight matrix on the right, as \n  \n    \n      \n        x\n        W\n      \n    \n    {\\displaystyle xW}\n  \n.\n\n\n=== Tokenization ===\n\nAs the Transformer architecture natively processes numerical data, not text, there must be a translation between text and tokens. A token is an integer that represents a character, or a short segment of characters. On the input side, the input text is parsed into a token sequence. Similar",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "nput text is parsed into a token sequence. Similarly, on the output side, the output tokens are parsed back to text. The module doing the conversion between texts and token sequences is a tokenizer.\nThe set of all tokens is the vocabulary of the tokenizer, and its size is the vocabulary size \n  \n    \n      \n        \n          n\n          \n            vocabulary\n          \n        \n      \n    \n    {\\displaystyle n_{\\text{vocabulary}}}\n  \n. When faced with tokens outside the vocabulary, typically",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "ced with tokens outside the vocabulary, typically a special token is used, written as \"[UNK]\" for \"unknown\".\nSome commonly used tokenizers are byte pair encoding, WordPiece, and SentencePiece.\n\n\n=== Embedding ===\n\nEach token is converted into an embedding vector via a lookup table. Equivalently stated, it multiplies a one-hot representation of the token by an embedding matrix \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n. For example, if the input token is",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "ample, if the input token is \n  \n    \n      \n        3\n      \n    \n    {\\displaystyle 3}\n  \n, then the one-hot representation is \n  \n    \n      \n        [\n        0\n        ,\n        0\n        ,\n        0\n        ,\n        1\n        ,\n        0\n        ,\n        0\n        ,\n        …\n        ]\n      \n    \n    {\\displaystyle [0,0,0,1,0,0,\\dots ]}\n  \n, and its embedding vector is\n  \n    \n      \n        \n          E\n          m\n          b\n          e\n          d\n        \n        (\n        3",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "e\n          d\n        \n        (\n        3\n        )\n        =\n        [\n        0\n        ,\n        0\n        ,\n        0\n        ,\n        1\n        ,\n        0\n        ,\n        0\n        ,\n        …\n        ]\n        M\n      \n    \n    {\\displaystyle \\mathrm {Embed} (3)=[0,0,0,1,0,0,\\dots ]M}\n  \nThe token embedding vectors are added to their respective positional encoding vectors (see below), producing the sequence of input vectors.\nThe number of dimensions in an embedding vector is called h",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "r of dimensions in an embedding vector is called hidden size or embedding size and written as \n  \n    \n      \n        \n          d\n          \n            emb\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{emb}}}\n  \n. This size is written as \n  \n    \n      \n        \n          d\n          \n            model\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{model}}}\n  \n in the original Transformer paper.\n\n\n=== Un-embedding ===\nAn un-embedding layer is almost the reverse of an",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "An un-embedding layer is almost the reverse of an embedding layer. Whereas an embedding layer converts a token into a vector, an un-embedding layer converts a vector into a probability distribution over tokens.\nThe un-embedding layer is a linear-softmax layer:\n  \n    \n      \n        \n          U\n          n\n          E\n          m\n          b\n          e\n          d\n        \n        (\n        x\n        )\n        =\n        \n          s\n          o\n          f\n          t\n          m\n          a",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "o\n          f\n          t\n          m\n          a\n          x\n        \n        (\n        x\n        W\n        +\n        b\n        )\n      \n    \n    {\\displaystyle \\mathrm {UnEmbed} (x)=\\mathrm {softmax} (xW+b)}\n  \nThe matrix has shape \n  \n    \n      \n        (\n        \n          d\n          \n            emb\n          \n        \n        ,\n        \n          n\n          \n            vocabulary\n          \n        \n        )\n      \n    \n    {\\displaystyle (d_{\\text{emb}},n_{\\text{vocabulary}})}\n  \n. T",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "yle (d_{\\text{emb}},n_{\\text{vocabulary}})}\n  \n. The embedding matrix \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n and the un-embedding matrix \n  \n    \n      \n        W\n      \n    \n    {\\displaystyle W}\n  \n are sometimes required to be transposes of each other, a practice called weight tying.\n\n\n=== Positional encoding ===\n\nA positional encoding is a fixed-size vector representation of the relative positions of tokens within a sequence: it provides the transformer model with in",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "equence: it provides the transformer model with information about where the words are in the input sequence. This induces a bias towards the order of the input sequence, so that, for example, the input sequence \"man bites dog\" is processed differently from \"dog bites man\".\nThe positional encoding is defined as a function of type \n  \n    \n      \n        f\n        :\n        \n          R\n        \n        →\n        \n          \n            R\n          \n          \n            d",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "d\n          \n        \n        ;\n        d\n        ∈\n        \n          Z\n        \n        ,\n        d\n        >\n        0\n      \n    \n    {\\displaystyle f:\\mathbb {R} \\to \\mathbb {R} ^{d};d\\in \\mathbb {Z} ,d>0}\n  \n, where \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n  \n is a positive even integer. The full positional encoding defined in the original paper is:\n  \n    \n      \n        (\n        f\n        (\n        t\n        \n          )",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "t\n        \n          )\n          \n            2\n            k\n          \n        \n        ,\n        f\n        (\n        t\n        \n          )\n          \n            2\n            k\n            +\n            1\n          \n        \n        )\n        =\n        (\n        sin\n        ⁡\n        (\n        θ\n        )\n        ,\n        cos\n        ⁡\n        (\n        θ\n        )\n        )\n        \n        ∀\n        k\n        ∈\n        {\n        0\n        ,\n        1\n        ,\n        …\n        ,",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ",\n        1\n        ,\n        …\n        ,\n        d\n        \n          /\n        \n        2\n        −\n        1\n        }\n      \n    \n    {\\displaystyle (f(t)_{2k},f(t)_{2k+1})=(\\sin(\\theta ),\\cos(\\theta ))\\quad \\forall k\\in \\{0,1,\\ldots ,d/2-1\\}}\n  \nwhere \n  \n    \n      \n        θ\n        =\n        \n          \n            t\n            \n              r\n              \n                k\n              \n            \n          \n        \n        ,\n        r\n        =\n        \n          N",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ",\n        r\n        =\n        \n          N\n          \n            2\n            \n              /\n            \n            d\n          \n        \n      \n    \n    {\\displaystyle \\theta ={\\frac {t}{r^{k}}},r=N^{2/d}}\n  \n.\nHere, \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n is a free parameter that should be significantly larger than the biggest \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n that would be input into the positional encoding function. The original pa",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "the positional encoding function. The original paper uses \n  \n    \n      \n        N\n        =\n        10000\n      \n    \n    {\\displaystyle N=10000}\n  \n.\nThe function is in a simpler form when written as a complex function of type \n  \n    \n      \n        f\n        :\n        \n          R\n        \n        →\n        \n          \n            C\n          \n          \n            d\n            \n              /\n            \n            2\n          \n        \n      \n    \n    {\\displaystyle f:\\mathbb {R} \\t",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "{\\displaystyle f:\\mathbb {R} \\to \\mathbb {C} ^{d/2}}\n  \n\n  \n    \n      \n        f\n        (\n        t\n        )\n        =\n        \n          \n            (\n            \n              e\n              \n                i\n                t\n                \n                  /\n                \n                \n                  r\n                  \n                    k\n                  \n                \n              \n            \n            )\n          \n          \n            k",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ")\n          \n          \n            k\n            =\n            0\n            ,\n            1\n            ,\n            …\n            ,\n            \n              \n                d\n                2\n              \n            \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle f(t)=\\left(e^{it/r^{k}}\\right)_{k=0,1,\\ldots ,{\\frac {d}{2}}-1}}\n  \nwhere \n  \n    \n      \n        r\n        =\n        \n          N\n          \n            2",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "2\n            \n              /\n            \n            d\n          \n        \n      \n    \n    {\\displaystyle r=N^{2/d}}\n  \n.\nThe main reason for using this positional encoding function is that using it, shifts are linear transformations:\n  \n    \n      \n        f\n        (\n        t\n        +\n        Δ\n        t\n        )\n        =\n        \n          d\n          i\n          a\n          g\n        \n        (\n        f\n        (\n        Δ\n        t\n        )\n        )",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "(\n        Δ\n        t\n        )\n        )\n        f\n        (\n        t\n        )\n      \n    \n    {\\displaystyle f(t+\\Delta t)=\\mathrm {diag} (f(\\Delta t))f(t)}\n  \nwhere \n  \n    \n      \n        Δ\n        t\n        ∈\n        \n          R\n        \n      \n    \n    {\\displaystyle \\Delta t\\in \\mathbb {R} }\n  \n is the distance one wishes to shift. This allows the transformer to take any encoded position, and find the encoding of the position n-steps-ahead or n-steps-behind, by a matrix multiplication",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "head or n-steps-behind, by a matrix multiplication.\nBy taking a linear sum, any convolution can also be implemented as linear transformations:\n  \n    \n      \n        \n          ∑\n          \n            j\n          \n        \n        \n          c\n          \n            j\n          \n        \n        f\n        (\n        t\n        +\n        Δ\n        \n          t\n          \n            j\n          \n        \n        )\n        =\n        \n          (\n          \n            \n              ∑",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "∑\n              \n                j\n              \n            \n            \n              c\n              \n                j\n              \n            \n            \n            \n              d\n              i\n              a\n              g\n            \n            (\n            f\n            (\n            Δ\n            \n              t\n              \n                j\n              \n            \n            )\n            )\n          \n          )",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ")\n          \n          )\n        \n        f\n        (\n        t\n        )\n      \n    \n    {\\displaystyle \\sum _{j}c_{j}f(t+\\Delta t_{j})=\\left(\\sum _{j}c_{j}\\,\\mathrm {diag} (f(\\Delta t_{j}))\\right)f(t)}\n  \nfor any constants \n  \n    \n      \n        \n          c\n          \n            j\n          \n        \n      \n    \n    {\\displaystyle c_{j}}\n  \n. This allows the transformer to take any encoded position and find a linear sum of the encoded locations of its neighbors. This sum of enc",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "ncoded locations of its neighbors. This sum of encoded positions, when fed into the attention mechanism, would create attention weights on its neighbors, much like what happens in a convolutional neural network language model. In the author's words, \"we hypothesized it would allow the model to easily learn to attend by relative position.\"\nIn typical implementations, all operations are done over the real numbers, not the complex numbers, but since complex multiplication can be implemented as real",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "complex multiplication can be implemented as real 2-by-2 matrix multiplication, this is a mere notational difference.\n\n\n=== Encoder-decoder (overview) ===\n\nLike earlier seq2seq models, the original transformer model used an encoder-decoder architecture. The encoder consists of encoding layers that process all the input tokens together one layer after another, while the decoder consists of decoding layers that iteratively process the encoder's output and the decoder's output tokens so far.\nThe p",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "tput and the decoder's output tokens so far.\nThe purpose of each encoder layer is to create contextualized representations of the tokens, where each representation corresponds to a token that \"mixes\" information from other input tokens via self-attention mechanism. Each decoder layer contains two attention sublayers: (1) cross-attention for incorporating the output of encoder (contextualized input token representations), and (2) self-attention for \"mixing\" information among the input tokens to t",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "r \"mixing\" information among the input tokens to the decoder (i.e. the tokens generated so far during inference time).\nBoth the encoder and decoder layers have a feed-forward neural network for additional processing of their outputs and contain residual connections and layer normalization steps. These feed-forward layers contain most of the parameters in a Transformer model.\n\n\n=== Feedforward network ===\n\nThe feedforward network (FFN) modules in a Transformer are 2-layered multilayer perceptrons",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "a Transformer are 2-layered multilayer perceptrons:\n  \n    \n      \n        \n          F\n          F\n          N\n        \n        (\n        x\n        )\n        =\n        ϕ\n        (\n        x\n        \n          W\n          \n            (\n            1\n            )\n          \n        \n        +\n        \n          b\n          \n            (\n            1\n            )\n          \n        \n        )\n        \n          W\n          \n            (\n            2\n            )",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "2\n            )\n          \n        \n        +\n        \n          b\n          \n            (\n            2\n            )\n          \n        \n      \n    \n    {\\displaystyle \\mathrm {FFN} (x)=\\phi (xW^{(1)}+b^{(1)})W^{(2)}+b^{(2)}}\n  \nwhere \n  \n    \n      \n        \n          W\n          \n            (\n            1\n            )\n          \n        \n      \n    \n    {\\displaystyle W^{(1)}}\n  \n and \n  \n    \n      \n        \n          W\n          \n            (\n            2\n            )",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "(\n            2\n            )\n          \n        \n      \n    \n    {\\displaystyle W^{(2)}}\n  \n are weight matrices and \n  \n    \n      \n        \n          b\n          \n            (\n            1\n            )\n          \n        \n      \n    \n    {\\displaystyle b^{(1)}}\n  \n and  \n  \n    \n      \n        \n          b\n          \n            (\n            2\n            )\n          \n        \n      \n    \n    {\\displaystyle b^{(2)}}\n  \n are bias vectors, and \n  \n    \n      \n        ϕ",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "as vectors, and \n  \n    \n      \n        ϕ\n      \n    \n    {\\displaystyle \\phi }\n  \n is its activation function. The original Transformer used ReLU activation.\nThe number of neurons in the middle layer is called intermediate size (GPT), filter size (BERT), or feedforward size (BERT). It is typically larger than the embedding size. For example, in both GPT-2 series and BERT series, the intermediate size of a model is 4 times its embedding size: \n  \n    \n      \n        \n          d",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "d\n          \n            ffn\n          \n        \n        =\n        4\n        \n          d\n          \n            emb\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{ffn}}=4d_{\\text{emb}}}\n  \n.\n\n\n=== Scaled dot-product attention ===\n\n\n==== Attention head ====\n\nThe attention mechanism used in the Transformer architecture are scaled dot-product attention units. For each unit, the transformer model learns three weight matrices: the query weights",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "hree weight matrices: the query weights \n  \n    \n      \n        \n          W\n          \n            Q\n          \n        \n      \n    \n    {\\displaystyle W^{Q}}\n  \n, the key weights \n  \n    \n      \n        \n          W\n          \n            K\n          \n        \n      \n    \n    {\\displaystyle W^{K}}\n  \n, and the value weights \n  \n    \n      \n        \n          W\n          \n            V\n          \n        \n      \n    \n    {\\displaystyle W^{V}}\n  \n.\nThe module takes three sequences, a query seque",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ".\nThe module takes three sequences, a query sequence, a key sequence, and a value sequence. The query sequence is a sequence of length \n  \n    \n      \n        \n          ℓ\n          \n            seq, query\n          \n        \n      \n    \n    {\\displaystyle \\ell _{\\text{seq, query}}}\n  \n, and each entry is a vector of dimension \n  \n    \n      \n        \n          d\n          \n            emb, query\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{emb, query}}}\n  \n. Similarly for the ke",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "e d_{\\text{emb, query}}}\n  \n. Similarly for the key and value sequences.\nFor each vector \n  \n    \n      \n        \n          x\n          \n            i\n            ,\n            \n              query\n            \n          \n        \n      \n    \n    {\\displaystyle x_{i,{\\text{query}}}}\n  \n in the query sequence, it is multiplied by a matrix \n  \n    \n      \n        \n          W\n          \n            Q\n          \n        \n      \n    \n    {\\displaystyle W^{Q}}\n  \n to produce a query vector",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "le W^{Q}}\n  \n to produce a query vector \n  \n    \n      \n        \n          q\n          \n            i\n          \n        \n        =\n        \n          x\n          \n            i\n            ,\n            \n              query\n            \n          \n        \n        \n          W\n          \n            Q\n          \n        \n      \n    \n    {\\displaystyle q_{i}=x_{i,{\\text{query}}}W^{Q}}\n  \n. The matrix of all query vectors is the query matrix:\n  \n    \n      \n        Q\n        =",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "Q\n        =\n        \n          X\n          \n            query\n          \n        \n        \n          W\n          \n            Q\n          \n        \n      \n    \n    {\\displaystyle Q=X_{\\text{query}}W^{Q}}\n  \nSimilarly, we construct the key matrix \n  \n    \n      \n        K\n        =\n        \n          X\n          \n            key\n          \n        \n        \n          W\n          \n            K\n          \n        \n      \n    \n    {\\displaystyle K=X_{\\text{key}}W^{K}}\n  \n and the",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "{\\displaystyle K=X_{\\text{key}}W^{K}}\n  \n and the value matrix \n  \n    \n      \n        V\n        =\n        \n          X\n          \n            value\n          \n        \n        \n          W\n          \n            V\n          \n        \n      \n    \n    {\\displaystyle V=X_{\\text{value}}W^{V}}\n  \n.\nIt is usually the case that all \n  \n    \n      \n        \n          W\n          \n            Q\n          \n        \n        ,\n        \n          W\n          \n            K\n          \n        \n        ,",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "K\n          \n        \n        ,\n        \n          W\n          \n            V\n          \n        \n      \n    \n    {\\displaystyle W^{Q},W^{K},W^{V}}\n  \n are square matrices, meaning \n  \n    \n      \n        \n          d\n          \n            emb, query\n          \n        \n        =\n        \n          d\n          \n            query\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{emb, query}}=d_{\\text{query}}}\n  \n, etc.\nAttention weights are calculated using the query and",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "tention weights are calculated using the query and key vectors: the attention weight \n  \n    \n      \n        \n          a\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle a_{ij}}\n  \n from token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n to token \n  \n    \n      \n        j\n      \n    \n    {\\displaystyle j}\n  \n is the dot product between \n  \n    \n      \n        \n          q\n          \n            i\n          \n        \n      \n    \n    {\\d",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "i\n          \n        \n      \n    \n    {\\displaystyle q_{i}}\n  \n and \n  \n    \n      \n        \n          k\n          \n            j\n          \n        \n      \n    \n    {\\displaystyle k_{j}}\n  \n. The attention weights are divided by the square root of the dimension of the key vectors, \n  \n    \n      \n        \n          \n            \n              d\n              \n                k\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\sqrt {d_{k}}}}\n  \n, which sta",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "{\\displaystyle {\\sqrt {d_{k}}}}\n  \n, which stabilizes gradients during training, and passed through a softmax which normalizes the weights. The fact that \n  \n    \n      \n        \n          W\n          \n            Q\n          \n        \n      \n    \n    {\\displaystyle W^{Q}}\n  \n and \n  \n    \n      \n        \n          W\n          \n            K\n          \n        \n      \n    \n    {\\displaystyle W^{K}}\n  \n are different matrices allows attention to be non-symmetric: if token",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "to be non-symmetric: if token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n attends to token \n  \n    \n      \n        j\n      \n    \n    {\\displaystyle j}\n  \n (i.e. \n  \n    \n      \n        \n          q\n          \n            i\n          \n        \n        ⋅\n        \n          k\n          \n            j\n          \n        \n      \n    \n    {\\displaystyle q_{i}\\cdot k_{j}}\n  \n is large), this does not necessarily mean that token \n  \n    \n      \n        j\n      \n    \n    {\\displaystyl",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "j\n      \n    \n    {\\displaystyle j}\n  \n will attend to token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n (i.e. \n  \n    \n      \n        \n          q\n          \n            j\n          \n        \n        ⋅\n        \n          k\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle q_{j}\\cdot k_{i}}\n  \n could be small). The output of the attention unit for token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n is the weighted",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "{\\displaystyle i}\n  \n is the weighted sum of the value vectors of all tokens, weighted by \n  \n    \n      \n        \n          a\n          \n            i\n            j\n          \n        \n      \n    \n    {\\displaystyle a_{ij}}\n  \n, the attention from token \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n to each token.\nThe attention calculation for all tokens can be expressed as one large matrix calculation using the softmax function, which is useful for training due to",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "tmax function, which is useful for training due to computational matrix operation optimizations that quickly compute matrix operations. The matrices \n  \n    \n      \n        Q\n      \n    \n    {\\displaystyle Q}\n  \n, \n  \n    \n      \n        K\n      \n    \n    {\\displaystyle K}\n  \n and \n  \n    \n      \n        V\n      \n    \n    {\\displaystyle V}\n  \n are defined as the matrices where the \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \nth rows are vectors",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "rows are vectors \n  \n    \n      \n        \n          q\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle q_{i}}\n  \n, \n  \n    \n      \n        \n          k\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle k_{i}}\n  \n, and \n  \n    \n      \n        \n          v\n          \n            i\n          \n        \n      \n    \n    {\\displaystyle v_{i}}\n  \n respectively. Then we can represent the attention as",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "Attention\n                \n                (\n                Q\n                ,\n                K\n                ,\n                V\n                )\n                =\n                \n                  softmax\n                \n                \n                  (\n                  \n                    \n                      \n                        Q",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "Q\n                        \n                          K\n                          \n                            \n                              T\n                            \n                          \n                        \n                      \n                      \n                        \n                          d\n                          \n                            k",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ")\n                \n                V\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\end{aligned}}}\n  \n\nwhere the softmax is applied over each of the rows of the matrix.\nThe number of dimensions in a query vector is query size \n  \n    \n      \n        \n          d\n          \n            que",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "d\n          \n            query\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{query}}}\n  \n and similarly for the key size \n  \n    \n      \n        \n          d\n          \n            key\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{key}}}\n  \n and value size \n  \n    \n      \n        \n          d\n          \n            value\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{value}}}\n  \n. The output dimension of an attention head is its head",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "output dimension of an attention head is its head dimension \n  \n    \n      \n        \n          d\n          \n            head\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{head}}}\n  \n. The attention mechanism requires the following three equalities to hold:\n  \n    \n      \n        \n          ℓ\n          \n            seq, key\n          \n        \n        =\n        \n          ℓ\n          \n            seq, value\n          \n        \n        ,\n        \n        \n          d",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ",\n        \n        \n          d\n          \n            query\n          \n        \n        =\n        \n          d\n          \n            key\n          \n        \n        ,\n        \n        \n          d\n          \n            value\n          \n        \n        =\n        \n          d\n          \n            head\n          \n        \n      \n    \n    {\\displaystyle \\ell _{\\text{seq, key}}=\\ell _{\\text{seq, value}},\\;d_{\\text{query}}=d_{\\text{key}},\\;d_{\\text{value}}=d_{\\text{head}}}\n  \nbut is otherwise",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "\\text{value}}=d_{\\text{head}}}\n  \nbut is otherwise unconstrained.\nIf the attention head is used in a self-attention fashion, then \n  \n    \n      \n        \n          X\n          \n            query\n          \n        \n        =\n        \n          X\n          \n            key\n          \n        \n        =\n        \n          X\n          \n            value\n          \n        \n      \n    \n    {\\displaystyle X_{\\text{query}}=X_{\\text{key}}=X_{\\text{value}}}\n  \n. If the attention head is used in a cross",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "e}}}\n  \n. If the attention head is used in a cross-attention fashion, then usually \n  \n    \n      \n        \n          X\n          \n            query\n          \n        \n        ≠\n        \n          X\n          \n            key\n          \n        \n        =\n        \n          X\n          \n            value\n          \n        \n      \n    \n    {\\displaystyle X_{\\text{query}}\\neq X_{\\text{key}}=X_{\\text{value}}}\n  \n. It is theoretically possible for all three to be different, but that is rarely the",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "all three to be different, but that is rarely the case in practice.\n\n\n==== Multiheaded attention ====\n\nOne set of \n  \n    \n      \n        \n          (\n          \n            \n              W\n              \n                Q\n              \n            \n            ,\n            \n              W\n              \n                K\n              \n            \n            ,\n            \n              W\n              \n                V\n              \n            \n          \n          )",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ")\n        \n      \n    \n    {\\displaystyle \\left(W^{Q},W^{K},W^{V}\\right)}\n  \n matrices is called an attention head, and each layer in a transformer model has multiple attention heads. While each attention head attends to the tokens that are relevant to each token, multiple attention heads allow the model to do this for different definitions of \"relevance\". Specifically, the query and key projection matrices, \n  \n    \n      \n        \n          W",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "W\n          \n            Q\n          \n        \n      \n    \n    {\\displaystyle W^{Q}}\n  \n and \n  \n    \n      \n        \n          W\n          \n            K\n          \n        \n      \n    \n    {\\displaystyle W^{K}}\n  \n , which are involved in the attention score computation, defines the \"relevance\". Meanwhile, the value projection matrix \n  \n    \n      \n        \n          W\n          \n            V\n          \n        \n      \n    \n    {\\displaystyle W^{V}}\n  \n, in combin",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "{\\displaystyle W^{V}}\n  \n, in combination with the part of the output projection matrix \n  \n    \n      \n        \n          W\n          \n            O\n          \n        \n      \n    \n    {\\displaystyle W^{O}}\n  \n, determines how the attended tokens influence what information is passed to subsequent layers and ultimately the output logits. In addition, the scope of attention, or the range of token relationships captured by each attention head, can expand as tokens pass through succes",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "ion head, can expand as tokens pass through successive layers. This allows the model to capture more complex and long-range dependencies in deeper layers. Many transformer attention heads encode relevance relations that are meaningful to humans. For example, some attention heads can attend mostly to the next word, while others mainly attend from verbs to their direct objects. The computations for each attention head can be performed in parallel, which allows for fast processing. The outputs for",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "which allows for fast processing. The outputs for the attention layer are concatenated to pass into the feed-forward neural network layers.\nConcretely, let the multiple attention heads be indexed by \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n, then we have\n  \n    \n      \n        \n          MultiheadedAttention\n        \n        (\n        Q\n        ,\n        K\n        ,\n        V\n        )\n        =\n        \n          \n            Concat\n          \n          \n            i",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "Concat\n          \n          \n            i\n            ∈\n            [\n            \n              n\n              \n                heads\n              \n            \n            ]\n          \n        \n        (\n        \n          Attention\n        \n        (\n        X\n        \n          W\n          \n            i\n          \n          \n            Q\n          \n        \n        ,\n        X\n        \n          W\n          \n            i\n          \n          \n            K",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "K\n          \n        \n        ,\n        X\n        \n          W\n          \n            i\n          \n          \n            V\n          \n        \n        )\n        )\n        \n          W\n          \n            O\n          \n        \n      \n    \n    {\\displaystyle {\\text{MultiheadedAttention}}(Q,K,V)={\\text{Concat}}_{i\\in [n_{\\text{heads}}]}({\\text{Attention}}(XW_{i}^{Q},XW_{i}^{K},XW_{i}^{V}))W^{O}}\n  \n where the matrix \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "X\n      \n    \n    {\\displaystyle X}\n  \n is the concatenation of word embeddings, and the matrices \n  \n    \n      \n        \n          W\n          \n            i\n          \n          \n            Q\n          \n        \n        ,\n        \n          W\n          \n            i\n          \n          \n            K\n          \n        \n        ,\n        \n          W\n          \n            i\n          \n          \n            V\n          \n        \n      \n    \n    {\\displaystyle W_{i}^{Q},W_",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "{\\displaystyle W_{i}^{Q},W_{i}^{K},W_{i}^{V}}\n  \n are \"projection matrices\" owned by individual attention head \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n, and \n  \n    \n      \n        \n          W\n          \n            O\n          \n        \n      \n    \n    {\\displaystyle W^{O}}\n  \n is a final projection matrix owned by the whole multi-headed attention head.\nIt is theoretically possible for each attention head to have a different head dimension",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "n head to have a different head dimension \n  \n    \n      \n        \n          d\n          \n            head\n          \n        \n      \n    \n    {\\displaystyle d_{\\text{head}}}\n  \n, but that is rarely the case in practice.\nAs an example, in the smallest GPT-2 model, there are only self-attention mechanisms. It has the following dimensions:\n  \n    \n      \n        \n          d\n          \n            emb\n          \n        \n        =\n        768\n        ,\n        \n          n\n          \n            h",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ",\n        \n          n\n          \n            head\n          \n        \n        =\n        12\n        ,\n        \n          d\n          \n            head\n          \n        \n        =\n        64\n      \n    \n    {\\displaystyle d_{\\text{emb}}=768,n_{\\text{head}}=12,d_{\\text{head}}=64}\n  \nSince \n  \n    \n      \n        12\n        ×\n        64\n        =\n        768\n      \n    \n    {\\displaystyle 12\\times 64=768}\n  \n, its output projection matrix \n  \n    \n      \n        \n          W",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "W\n          \n            O\n          \n        \n        ∈\n        \n          \n            R\n          \n          \n            (\n            12\n            ×\n            64\n            )\n            ×\n            768\n          \n        \n      \n    \n    {\\displaystyle W^{O}\\in \\mathbb {R} ^{(12\\times 64)\\times 768}}\n  \n is a square matrix.\n\n\n==== Masked attention ====\nThe Transformer architecture is constructed to calculate output tokens iteratively. Assuming",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "late output tokens iteratively. Assuming \n  \n    \n      \n        t\n        =\n        0\n      \n    \n    {\\displaystyle t=0}\n  \n refers to the calculation of the first output token \n  \n    \n      \n        i\n        =\n        0\n      \n    \n    {\\displaystyle i=0}\n  \n, for step \n  \n    \n      \n        t\n        >\n        0\n      \n    \n    {\\displaystyle t>0}\n  \n, the output token \n  \n    \n      \n        i\n        =\n        0\n      \n    \n    {\\displaystyle i=0}\n  \n shall remain constant. This ensures",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "style i=0}\n  \n shall remain constant. This ensures properties of the model similar to autoregressive models. Therefore, at every time step \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n, the calculation for all outputs \n  \n    \n      \n        i\n      \n    \n    {\\displaystyle i}\n  \n should not have access to tokens at position \n  \n    \n      \n        j\n      \n    \n    {\\displaystyle j}\n  \n for \n  \n    \n      \n        j\n        >=\n        i\n      \n    \n    {\\displaystyle j>=i}",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "i\n      \n    \n    {\\displaystyle j>=i}\n  \n (as it naturally is the case for time step \n  \n    \n      \n        t\n        =\n        i\n      \n    \n    {\\displaystyle t=i}\n  \n, when tokens \n  \n    \n      \n        j\n        >\n        t\n      \n    \n    {\\displaystyle j>t}\n  \n are not yet calculated). This behavior may be accomplished before the softmax stage by adding a mask matrix \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n that is \n  \n    \n      \n        −\n        ∞",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "that is \n  \n    \n      \n        −\n        ∞\n      \n    \n    {\\displaystyle -\\infty }\n  \n at entries where the attention link must be cut, and \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n  \n at other places:\n  \n    \n      \n        \n          \n            \n              \n                \n                  MaskedAttention\n                \n                (\n                Q\n                ,\n                K\n                ,\n                V\n                )\n                =",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "V\n                )\n                =\n                \n                  softmax\n                \n                \n                  (\n                  \n                    M\n                    +\n                    \n                      \n                        \n                          Q\n                          \n                            K\n                            \n                              \n                                T",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "T\n                              \n                            \n                          \n                        \n                        \n                          \n                            d\n                            \n                              k\n                            \n                          \n                        \n                      \n                    \n                  \n                  )\n                \n                V",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "V\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{MaskedAttention}}(Q,K,V)={\\text{softmax}}\\left(M+{\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\end{aligned}}}\n  \n The following matrix is commonly used in decoder self-attention modules, called \"causal masking\":\n  \n    \n      \n        \n          M\n          \n            causal\n          \n        \n        =\n        \n          \n            [",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "[\n            \n              \n                \n                  0\n                \n                \n                  −\n                  ∞\n                \n                \n                  −\n                  ∞\n                \n                \n                  …\n                \n                \n                  −\n                  ∞\n                \n              \n              \n                \n                  0\n                \n                \n                  0",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "0\n                \n                \n                  −\n                  ∞\n                \n                \n                  …\n                \n                \n                  −\n                  ∞\n                \n              \n              \n                \n                  0\n                \n                \n                  0\n                \n                \n                  0\n                \n                \n                  …",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "…\n                \n                \n                  −\n                  ∞\n                \n              \n              \n                \n                  ⋮\n                \n                \n                  ⋮\n                \n                \n                  ⋮\n                \n                \n                  ⋱\n                \n                \n                  ⋮\n                \n              \n              \n                \n                  0",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "0\n                \n                \n                  0\n                \n                \n                  0\n                \n                \n                  …\n                \n                \n                  0\n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle M_{\\text{causal}}={\\begin{bmatrix}0&-\\infty &-\\infty &\\dots &-\\infty \\\\0&0&-\\infty &\\dots &-\\infty \\\\0&0&0&\\dots &-\\infty \\\\\\vdot",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "fty &\\dots &-\\infty \\\\0&0&0&\\dots &-\\infty \\\\\\vdots &\\vdots &\\vdots &\\ddots &\\vdots \\\\0&0&0&\\dots &0\\end{bmatrix}}}\n  \n\nIn words, it means that each token can pay attention to itself, and every token before it, but not any after it. A non-masked attention module can be thought of as a masked attention module where the mask has all entries zero. As an example of an uncommon use of mask matrix, the XLNet considers all masks of the form \n  \n    \n      \n        P\n        \n          M",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "P\n        \n          M\n          \n            causal\n          \n        \n        \n          P\n          \n            −\n            1\n          \n        \n      \n    \n    {\\displaystyle PM_{\\text{causal}}P^{-1}}\n  \n, where \n  \n    \n      \n        P\n      \n    \n    {\\displaystyle P}\n  \n is a random permutation matrix.\n\n\n=== Encoder ===\n\nAn encoder consists of an embedding layer, followed by multiple encoder layers.\nEach encoder layer consists of two major components: a self-attention me",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "sists of two major components: a self-attention mechanism and a feed-forward layer. It takes an input as a sequence of input vectors, applies the self-attention mechanism, to produce an intermediate sequence of vectors, then applies the feed-forward layer for each vector individually. Schematically, we have:\n  \n    \n      \n        \n          \n            \n              \n                \n                  given input vectors",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "h\n                  \n                    0\n                  \n                \n                ,\n                \n                  h\n                  \n                    1\n                  \n                \n                ,\n                …\n              \n            \n            \n              \n                \n                  combine them into a matrix \n                \n                H",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "H\n              \n              \n                \n                =\n                \n                  \n                    [\n                    \n                      \n                        \n                          \n                            h\n                            \n                              0",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "h\n                            \n                              1\n                            \n                          \n                        \n                      \n                      \n                        \n                          ⋮\n                        \n                      \n                    \n                    ]",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "EncoderLayer\n                \n                (\n                H\n                )\n              \n              \n                \n                =\n                \n                  \n                    [\n                    \n                      \n                        \n                          \n                            FFN\n                          \n                          (",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "(\n                          \n                            MultiheadedAttention\n                          \n                          (\n                          H\n                          ,\n                          H\n                          ,\n                          H\n                          \n                            )\n                            \n                              0",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ")\n                        \n                      \n                      \n                        \n                          \n                            FFN\n                          \n                          (\n                          \n                            MultiheadedAttention\n                          \n                          (\n                          H\n                          ,\n                          H",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "H\n                          ,\n                          H\n                          \n                            )\n                            \n                              1\n                            \n                          \n                          )\n                        \n                      \n                      \n                        \n                          ⋮\n                        \n                      \n                    \n                    ]",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "]\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{given input vectors }}&h_{0},h_{1},\\dots \\\\{\\text{combine them into a matrix }}H&={\\begin{bmatrix}h_{0}\\\\h_{1}\\\\\\vdots \\end{bmatrix}}\\\\{\\text{EncoderLayer}}(H)&={\\begin{bmatrix}{\\text{FFN}}({\\text{MultiheadedAttention}}(H,H,H)_{0})\\\\{\\text{FFN}}({\\text{MultiheadedAttention}}(H,H,H)_{1})\\\\\\vdots \\end{bmatrix}}\\",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "dedAttention}}(H,H,H)_{1})\\\\\\vdots \\end{bmatrix}}\\\\\\end{aligned}}}\n  \n\nwhere \n  \n    \n      \n        \n          FFN\n        \n      \n    \n    {\\displaystyle {\\text{FFN}}}\n  \n stands for \"feed-forward network\". We can more succinctly write it as\n  \n    \n      \n        \n          EncoderLayer\n        \n        (\n        H\n        )\n        =\n        \n          FFN\n        \n        (\n        \n          MultiheadedAttention\n        \n        (\n        H\n        ,\n        H\n        ,\n        H\n        )",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ",\n        H\n        ,\n        H\n        )\n        )\n      \n    \n    {\\displaystyle {\\text{EncoderLayer}}(H)={\\text{FFN}}({\\text{MultiheadedAttention}}(H,H,H))}\n  \nwith the implicit convention that the \n  \n    \n      \n        \n          FFN\n        \n      \n    \n    {\\displaystyle {\\text{FFN}}}\n  \n is applied to each row of the matrix individually.\nThe encoder layers are stacked. The first encoder layer takes the sequence of input vectors from the embedding layer, producing a sequence of",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "from the embedding layer, producing a sequence of vectors. This sequence of vectors is processed by the second encoder, and so on. The output from the final encoder layer is then used by the decoder.\nAs the encoder processes the entire input all at once, every token can attend to every other token (all-to-all attention), so there is no need for causal masking.\n\n\n=== Decoder ===\n\nA decoder consists of an embedding layer, followed by multiple decoder layers, followed by an un-embedding layer.\nEach",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "er layers, followed by an un-embedding layer.\nEach decoder consists of three major components: a causally masked self-attention mechanism, a cross-attention mechanism, and a feed-forward neural network. The decoder functions in a similar fashion to the encoder, but an additional attention mechanism is inserted which instead draws relevant information from the encodings generated by the encoders. This mechanism can also be called the encoder-decoder attention.\nLike the first encoder, the first de",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "er attention.\nLike the first encoder, the first decoder takes positional information and embeddings of the output sequence as its input, rather than encodings. The transformer must not use the current or future output to predict an output, so the output sequence must be partially masked to prevent this reverse information flow. This allows for autoregressive text generation. For decoding, all-to-all attention is inappropriate, because a token cannot attend to tokens not yet generated. Thus, the",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "not attend to tokens not yet generated. Thus, the self-attention module in the decoder is causally masked.\nIn contrast, the cross-attention mechanism attends to the output vectors of the encoder, which is computed before the decoder starts decoding. Consequently, there is no need for masking in the cross-attention mechanism.\nSchematically, we have:\n  \n    \n      \n        \n          \n            \n              \n                \n                  H\n                  ′",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "′\n                \n              \n              \n                \n                =\n                \n                  MaskedMultiheadedAttention\n                \n                (\n                H\n                ,\n                H\n                ,\n                H\n                )\n              \n            \n            \n              \n                \n                  DecoderLayer\n                \n                (\n                H\n                )",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "H\n                )\n              \n              \n                \n                =\n                \n                  FFN\n                \n                (\n                \n                  MultiheadedAttention\n                \n                (\n                \n                  H\n                  ′\n                \n                ,\n                \n                  H\n                  \n                    E\n                  \n                \n                ,",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ",\n                \n                  H\n                  \n                    E\n                  \n                \n                )\n                )\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}H'&={\\text{MaskedMultiheadedAttention}}(H,H,H)\\\\{\\text{DecoderLayer}}(H)&={\\text{FFN}}({\\text{MultiheadedAttention}}(H',H^{E},H^{E}))\\end{aligned}}}\n  \nwhere \n  \n    \n      \n        \n          H",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "H\n          \n            E\n          \n        \n      \n    \n    {\\displaystyle H^{E}}\n  \n is the matrix with rows being the output vectors from the encoder.\nThe last decoder is followed by a final un-embedding layer. to produce the output probabilities over the vocabulary. Then, one of the tokens is sampled according to the probability, and the decoder can be run again to produce the next token, etc, autoregressively generating output text.\n\n\n=== Adapted architectures ===",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "ating output text.\n\n\n=== Adapted architectures ===\nMany large language models, since they do not need to predict a whole new sequence from an input sequence, only use the encoder or decoder of the original transformer architecture. Early GPT models are decoder-only models trained to predict the next token in a sequence. BERT, another language model, only makes use of an encoder, and is trained to predict a randomly masked token in a sequence.\n\n\n== Full transformer architecture ==\n\n\n=== Sublayers",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "= Full transformer architecture ==\n\n\n=== Sublayers ===\nEach encoder layer contains 2 sublayers: the self-attention and the feedforward network. Each decoder layer contains 3 sublayers: the causally masked self-attention, the cross-attention, and the feedforward network.\n\nThe final points of detail are the residual connections and layer normalization (LayerNorm, or LN), which while conceptually unnecessary, are necessary for numerical stability and convergence.\nThe residual connection, which is i",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "d convergence.\nThe residual connection, which is introduced to avoid vanishing gradient issues and stabilize the training process, can be expressed as follows: y = F(x) + x. The expression indicates that an output y is the sum of the transformation of input x (F(x)) and the input itself (x). Adding the input x can preserve the input information and avoid issues when the gradient of F(x) is close to zero.\nSimilarly to how the feedforward network modules are applied individually to each vector, th",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "odules are applied individually to each vector, the LayerNorm is also applied individually to each vector.\nThere are two common conventions in use: the post-LN and the pre-LN convention. In the post-LN convention, the output of each sublayer is \n  \n    \n      \n        \n          L\n          a\n          y\n          e\n          r\n          N\n          o\n          r\n          m\n        \n        (\n        x\n        +\n        \n          S\n          u\n          b\n          l\n          a\n          y",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "b\n          l\n          a\n          y\n          e\n          r\n        \n        (\n        x\n        )\n        )\n      \n    \n    {\\displaystyle \\mathrm {LayerNorm} (x+\\mathrm {Sublayer} (x))}\n  \nwhere \n  \n    \n      \n        \n          S\n          u\n          b\n          l\n          a\n          y\n          e\n          r\n        \n        (\n        x\n        )\n      \n    \n    {\\displaystyle \\mathrm {Sublayer} (x)}\n  \n is the function implemented by the sublayer itself.\nIn the pre-LN conven",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "ented by the sublayer itself.\nIn the pre-LN convention, the output of each sublayer is\n  \n    \n      \n        x\n        +\n        \n          S\n          u\n          b\n          l\n          a\n          y\n          e\n          r\n        \n        (\n        \n          L\n          a\n          y\n          e\n          r\n          N\n          o\n          r\n          m\n        \n        (\n        x\n        )\n        )\n      \n    \n    {\\displaystyle x+\\mathrm {Sublayer} (\\mathrm {LayerNorm} (x))}\n  \nThe or",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "rm {Sublayer} (\\mathrm {LayerNorm} (x))}\n  \nThe original 2017 Transformer used the post-LN convention. It was difficult to train and required careful hyperparameter tuning and a \"warm-up\" in learning rate, where it starts small and gradually increases. The pre-LN convention, proposed several times in 2018, was found to be easier to train, requiring no warm-up, leading to faster convergence.\n\n\n=== Pseudocode ===\nThe following is the pseudocode for a standard pre-LN encoder-decoder Transformer, ad",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "a standard pre-LN encoder-decoder Transformer, adapted from\n\ninput: Encoder input t_e\n       Decoder input t_d\noutput: Array of probability distributions, with shape (decoder vocabulary size x length(decoder output sequence))\n\n/* encoder */\nz_e ← encoder.tokenizer(t_e)\n\nfor each t in 1:length(z_e) do\n    z_e[t] ← encoder.embedding(z_e[t]) + encoder.positional_embedding(t)\n\nfor each l in 1:length(encoder.layers) do\n    layer ← encoder.layers[l]\n\n    /* first sublayer */\n    z_e_copy ← copy(z_e)",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "/* first sublayer */\n    z_e_copy ← copy(z_e)\n    for each t in 1:length(z_e) do\n        z_e[t] ← layer.layer_norm(z_e[t])\n    z_e ← layer.multiheaded_attention(z_e, z_e, z_e)\n    for each t in 1:length(z_e) do\n        z_e[t] ← z_e[t] + z_e_copy[t]\n\n    /* second sublayer */\n    z_e_copy ← copy(z_e)\n    for each t in 1:length(z_e) do\n        z_e[t] ← layer.layer_norm(z_e[t])\n    z_e ← layer.feedforward(z_e)\n    for each t in 1:length(z_e) do\n        z_e[t] ← z_e[t] + z_e_copy[t]\n\nfor each t",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "z_e[t] ← z_e[t] + z_e_copy[t]\n\nfor each t in 1:length(z_e) do\n    z_e[t] ← encoder.final_layer_norm(z_e[t])\n\n/* decoder */\nz_d ← decoder.tokenizer(t_d)\n\nfor each t in 1:length(z_d) do\n    z_d[t] ← decoder.embedding(z_d[t]) + decoder.positional_embedding(t)\n\nfor each l in 1:length(decoder.layers) do\n        layer ← decoder.layers[l]\n\n        /* first sublayer */\n        z_d_copy ← copy(z_d)\n        for each t in 1:length(z_d) do\n            z_d[t] ← layer.layer_norm(z_d[t])\n        z_d ←",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "z_d[t] ← layer.layer_norm(z_d[t])\n        z_d ← layer.masked_multiheaded_attention(z_d, z_d, z_d)\n        for each t in 1:length(z_d) do\n            z_d[t] ← z_d[t] + z_d_copy[t]\n\n        /* second sublayer */\n        z_d_copy ← copy(z_d)\n        for each t in 1:length(z_d) do\n            z_d[t] ← layer.layer_norm(z_d[t])\n        z_d ← layer.multiheaded_attention(z_d, z_e, z_e) \n        for each i in 1:length(z_d) do\n            z_d[t] ← z_d[t] + z_d_copy[t]\n\n        /* third sublayer */",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "+ z_d_copy[t]\n\n        /* third sublayer */\n        z_d_copy ← copy(z_d)\n        for each t in 1:length(z_d) do\n            z_d[t] ← layer.layer_norm(z_d[t])\n        z_d ← layer.feedforward(z_d)\n        for each t in 1:length(z_d) do\n            z_d[t] ← z_d[t] + z_d_copy[t]\n\nz_d ← decoder.final_layer_norm(z_d)\n\noutput_distributions ← []\nfor each t in 1:length(z_d) do\n    output_distributions.append(decoder.unembed(z_d[t]))\n\nreturn output_distributions\n\n\n=== Terminology ===\nThe Transformer arch",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "butions\n\n\n=== Terminology ===\nThe Transformer architecture, being modular, allows variations. Several common variations are described here.\nAn \"encoder-only\" Transformer applies the encoder to map an input text into a sequence of vectors that represent the input text. This is usually used for text embedding and representation learning for downstream applications. BERT is encoder-only. They are less often used currently, as they were found to be not significantly better than training an encoder-d",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "ot significantly better than training an encoder-decoder Transformer, then taking just the encoder.\nA \"decoder-only\" Transformer is not literally decoder-only, since without an encoder, the cross-attention mechanism has nothing to attend to. Thus, the decoder layers in a decoder-only Transformer is composed of just two sublayers: the causally masked self-attention, and the feedforward network. This is usually used for text generation and instruction following. The models in the GPT series and Ch",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "ion following. The models in the GPT series and Chinchilla series are decoder-only.\nAn \"encoder-decoder\" Transformer is generally the same as the original Transformer, with 2 sublayers per encoder layer and 3 sublayers per decoder layer, etc. They might have minor architectural improvements, such as alternative activation functions, changing the location of normalization, etc. This is also usually used for text generation and instruction following. The models in the T5 series are encoder-decoder",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "g. The models in the T5 series are encoder-decoder.\nA \"prefixLM\" (prefix language model) is a decoder-only architecture, but with prefix masking, which is different from causal masking. Specifically, it has mask of the form: Figure 3 \n  \n    \n      \n        \n          M\n          \n            prefixLM\n          \n        \n        =\n        \n          \n            [\n            \n              \n                \n                  \n                    0",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "0\n                  \n                \n                \n                  −\n                  ∞\n                \n              \n              \n                \n                  \n                    0\n                  \n                \n                \n                  \n                    M\n                    \n                      causal\n                    \n                  \n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle M_{\\t",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "{\\displaystyle M_{\\text{prefixLM}}={\\begin{bmatrix}\\mathbf {0} &-\\infty \\\\\\mathbf {0} &M_{\\text{causal}}\\end{bmatrix}}}\n  \nwhere the first columns correspond to the \"prefix\", and the subsequent columns correspond to the autoregressively generated text based on the prefix. They resemble encoder-decoder models, but has less \"sparsity\". Such models are rarely used, though they are cited as theoretical possibilities and benchmarked comparisons.\nThere are also mixed seq2",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "benchmarked comparisons.\nThere are also mixed seq2seq models. For example, in 2020, Google Translate replaced the previous RNN-encoder–RNN-decoder model by a Transformer-encoder–RNN-decoder model, on the argument that an RNN-decoder runs much faster than Transformer-decoder when run autoregressively.\n\n\n== Subsequent work ==\n\n\n=== Alternative activation functions ===\nThe original transformer uses ReLU activation function. Other activation functions were developed. The Llama series and PaLM used S",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "s were developed. The Llama series and PaLM used SwiGLU; both GPT-1 and BERT used GELU.\nAlternative activation functions are often used in combination with Gated Linear Units in the feedforward module.\n\n\n=== Alternative normalizations ===\nThe normalization used in the Transformer can be different from LayerNorm. One example is RMSNorm which is used in the Llama series. Other examples include CapsuleNorm ScaleNorm, or FixNorm.\n\n\n=== Alternative positional encodings ===\nTransformers may use other",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "sitional encodings ===\nTransformers may use other positional encoding methods than sinusoidal.\nThe original Transformer paper reported using a learned positional encoding, but finding it not superior to the sinusoidal one. Later, found that causal masking itself provides enough signal to a Transformer decoder that it can learn to implicitly perform absolute positional encoding without the positional encoding module.\n\n\n==== RoPE ====\nRoPE (rotary positional embedding), is best explained by consid",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "positional embedding), is best explained by considering a list of 2-dimensional vectors \n  \n    \n      \n        [\n        (\n        \n          x\n          \n            1\n          \n          \n            (\n            1\n            )\n          \n        \n        ,\n        \n          x\n          \n            1\n          \n          \n            (\n            2\n            )\n          \n        \n        )\n        ,\n        (\n        \n          x\n          \n            2",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "2\n          \n          \n            (\n            1\n            )\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n          \n            (\n            2\n            )\n          \n        \n        )\n        ,\n        (\n        \n          x\n          \n            3\n          \n          \n            (\n            1\n            )\n          \n        \n        ,\n        \n          x\n          \n            3\n          \n          \n            (",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "3\n          \n          \n            (\n            2\n            )\n          \n        \n        )\n        ,\n        .\n        .\n        .\n        ]\n      \n    \n    {\\displaystyle [(x_{1}^{(1)},x_{1}^{(2)}),(x_{2}^{(1)},x_{2}^{(2)}),(x_{3}^{(1)},x_{3}^{(2)}),...]}\n  \n. Now pick some angle \n  \n    \n      \n        θ\n      \n    \n    {\\displaystyle \\theta }\n  \n. Then RoPE encoding is\n  \n    \n      \n        \n          RoPE\n        \n        \n          \n            (",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "(\n          \n        \n        \n          x\n          \n            m\n          \n          \n            (\n            1\n            )\n          \n        \n        ,\n        \n          x\n          \n            m\n          \n          \n            (\n            2\n            )\n          \n        \n        ,\n        m\n        \n          \n            )\n          \n        \n        =\n        \n          \n            (\n            \n              \n                \n                  cos",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "cos\n                  ⁡\n                  m\n                  θ\n                \n                \n                  −\n                  sin\n                  ⁡\n                  m\n                  θ\n                \n              \n              \n                \n                  sin\n                  ⁡\n                  m\n                  θ\n                \n                \n                  cos\n                  ⁡\n                  m",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "⁡\n                  m\n                  θ\n                \n              \n            \n            )\n          \n        \n        \n          \n            (\n            \n              \n                \n                  \n                    x\n                    \n                      m\n                    \n                    \n                      (\n                      1\n                      )",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "x\n                    \n                      m\n                    \n                    \n                      (\n                      2\n                      )\n                    \n                  \n                \n              \n            \n            )\n          \n        \n        =\n        \n          \n            (",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "x\n                    \n                      m\n                    \n                    \n                      (\n                      1\n                      )\n                    \n                  \n                  cos\n                  ⁡\n                  m\n                  θ\n                  −\n                  \n                    x\n                    \n                      m",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "(\n                      2\n                      )\n                    \n                  \n                  sin\n                  ⁡\n                  m\n                  θ\n                \n              \n              \n                \n                  \n                    x\n                    \n                      m\n                    \n                    \n                      (\n                      2\n                      )",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "(\n                      2\n                      )\n                    \n                  \n                  cos\n                  ⁡\n                  m\n                  θ\n                  +\n                  \n                    x\n                    \n                      m\n                    \n                    \n                      (\n                      1\n                      )\n                    \n                  \n                  sin\n                  ⁡\n                  m",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "sin\n                  ⁡\n                  m\n                  θ\n                \n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle {\\text{RoPE}}{\\big (}x_{m}^{(1)},x_{m}^{(2)},m{\\big )}={\\begin{pmatrix}\\cos m\\theta &-\\sin m\\theta \\\\\\sin m\\theta &\\cos m\\theta \\end{pmatrix}}{\\begin{pmatrix}x_{m}^{(1)}\\\\x_{m}^{(2)}\\\\\\end{pmatrix}}={\\begin{pmatrix}x_{m}^{(1)}\\cos m\\theta -x_{m}^{(2)}\\sin m\\theta \\\\x_{m}^{(2)}\\cos m\\theta +x_{m}^{(1)}\\sin m\\theta \\\\\\end{pma",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ")}\\cos m\\theta +x_{m}^{(1)}\\sin m\\theta \\\\\\end{pmatrix}}}\n  \nEquivalently, if we write the 2-dimensional vectors as complex numbers \n  \n    \n      \n        \n          z\n          \n            m\n          \n        \n        :=\n        \n          x\n          \n            m\n          \n          \n            (\n            1\n            )\n          \n        \n        +\n        i\n        \n          x\n          \n            m\n          \n          \n            (\n            2\n            )",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "(\n            2\n            )\n          \n        \n      \n    \n    {\\displaystyle z_{m}:=x_{m}^{(1)}+ix_{m}^{(2)}}\n  \n, then RoPE encoding is just multiplication by an angle:\n  \n    \n      \n        \n          RoPE\n        \n        \n          \n            (\n          \n        \n        \n          z\n          \n            m\n          \n        \n        ,\n        m\n        \n          \n            )\n          \n        \n        =\n        \n          e\n          \n            i\n            m",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "e\n          \n            i\n            m\n            θ\n          \n        \n        \n          z\n          \n            m\n          \n        \n      \n    \n    {\\displaystyle {\\text{RoPE}}{\\big (}z_{m},m{\\big )}=e^{im\\theta }z_{m}}\n  \nFor a list of \n  \n    \n      \n        2\n        n\n      \n    \n    {\\displaystyle 2n}\n  \n-dimensional vectors, a RoPE encoder is defined by a sequence of angles \n  \n    \n      \n        \n          θ\n          \n            (\n            1\n            )",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "(\n            1\n            )\n          \n        \n        ,\n        .\n        .\n        .\n        ,\n        \n          θ\n          \n            (\n            n\n            )\n          \n        \n      \n    \n    {\\displaystyle \\theta ^{(1)},...,\\theta ^{(n)}}\n  \n. Then the RoPE encoding is applied to each pair of coordinates.\nThe benefit of RoPE is that the dot-product between two vectors depends on their relative location only:\n  \n    \n      \n        \n          RoPE",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "RoPE\n        \n        \n          \n            (\n          \n        \n        x\n        ,\n        m\n        \n          \n            \n              )\n            \n          \n          \n            T\n          \n        \n        \n          RoPE\n        \n        \n          \n            (\n          \n        \n        y\n        ,\n        n\n        \n          \n            )\n          \n        \n        =\n        \n          RoPE\n        \n        \n          \n            (",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "(\n          \n        \n        x\n        ,\n        m\n        +\n        k\n        \n          \n            \n              )\n            \n          \n          \n            T\n          \n        \n        \n          RoPE\n        \n        \n          \n            (\n          \n        \n        y\n        ,\n        n\n        +\n        k\n        \n          \n            )\n          \n        \n      \n    \n    {\\displaystyle {\\text{RoPE}}{\\big (}x,m{\\big )}^{T}{\\text{RoPE}}{\\big (}y,",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "PE}}{\\big (}x,m{\\big )}^{T}{\\text{RoPE}}{\\big (}y,n{\\big )}={\\text{RoPE}}{\\big (}x,m+k{\\big )}^{T}{\\text{RoPE}}{\\big (}y,n+k{\\big )}}\n  \n\nfor any integer \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n.\n\n\n==== ALiBi ====\nALiBi (Attention with Linear Biases) is not a replacement for the positional encoder on the original transformer. Instead, it is an additional positional encoder that is directly plugged into the attention mechanism. Specifically, the ALiBi attention mechanism is",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "sm. Specifically, the ALiBi attention mechanism is\n  \n    \n      \n        \n          \n            \n              \n                \n                  Attention\n                \n                (\n                Q\n                ,\n                K\n                ,\n                V\n                )\n                =\n                \n                  softmax\n                \n                \n                  (",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "Q\n                          \n                            K\n                            \n                              \n                                T\n                              \n                            \n                          \n                        \n                        \n                          \n                            d\n                            \n                              k",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "k\n                            \n                          \n                        \n                      \n                    \n                    +\n                    s\n                    B\n                  \n                  )\n                \n                V\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}+sB\\right)V",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "rac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}+sB\\right)V\\end{aligned}}}\n  \nHere, \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  \n is a real number (\"scalar\"), and \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n is the linear bias matrix defined by\n  \n    \n      \n        B\n        =\n        \n          \n            (\n            \n              \n                \n                  0\n                \n                \n                  1",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "1\n                \n                \n                  2\n                \n                \n                  3\n                \n                \n                  ⋯\n                \n              \n              \n                \n                  −\n                  1\n                \n                \n                  0\n                \n                \n                  1\n                \n                \n                  2\n                \n                \n                  ⋯",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "⋯\n                \n              \n              \n                \n                  −\n                  2\n                \n                \n                  −\n                  1\n                \n                \n                  0\n                \n                \n                  1\n                \n                \n                  ⋯\n                \n              \n              \n                \n                  −\n                  3",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "−\n                  3\n                \n                \n                  −\n                  2\n                \n                \n                  −\n                  1\n                \n                \n                  0\n                \n                \n                  ⋯\n                \n              \n              \n                \n                  ⋮\n                \n                \n                  ⋮\n                \n                \n                  ⋮",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "⋮\n                \n                \n                  ⋮\n                \n                \n                  ⋱\n                \n              \n            \n            )\n          \n        \n      \n    \n    {\\displaystyle B={\\begin{pmatrix}0&1&2&3&\\cdots \\\\-1&0&1&2&\\cdots \\\\-2&-1&0&1&\\cdots \\\\-3&-2&-1&0&\\cdots \\\\\\vdots &\\vdots &\\vdots &\\vdots &\\ddots \\\\\\end{pmatrix}}}\n  \nin other words, \n  \n    \n      \n        \n          B\n          \n            i\n            ,",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "B\n          \n            i\n            ,\n            j\n          \n        \n        =\n        j\n        −\n        i\n      \n    \n    {\\displaystyle B_{i,j}=j-i}\n  \n. The idea being that the linear bias matrix is a softened mask. Just as \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n  \n represent full attention paid, and \n  \n    \n      \n        −\n        ∞\n      \n    \n    {\\displaystyle -\\infty }\n  \n represents no attention paid, the linear bias matrix increases attention paid i",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "the linear bias matrix increases attention paid in one direction and decreases attention paid in the other direction.\nALiBi allows pretraining on short context windows, then fine-tuning on longer context windows. Since it is directly plugged into the attention mechanism, it can be combined with any positional encoder that is plugged into the \"bottom\" of the entire network (which is where the sinusoidal encoder on the original transformer, as well as RoPE and many others, are located).\n\n\n==== Re",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "l as RoPE and many others, are located).\n\n\n==== Relative Position Encodings ====\nRelative Position Encodings is similar to ALiBi, but more generic:\n  \n    \n      \n        \n          \n            \n              \n                \n                  Attention\n                \n                (\n                Q\n                ,\n                K\n                ,\n                V\n                )\n                =\n                \n                  softmax",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "softmax\n                \n                \n                  (\n                  \n                    \n                      \n                        \n                          Q\n                          \n                            K\n                            \n                              \n                                T",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "d\n                            \n                              k\n                            \n                          \n                        \n                      \n                    \n                    +\n                    B\n                  \n                  )\n                \n                V\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}{\\text{Attention}}(Q,K,V)=",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "aystyle {\\begin{aligned}{\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}+B\\right)V\\end{aligned}}}\n  \nwhere \n  \n    \n      \n        B\n      \n    \n    {\\displaystyle B}\n  \n is a Toeplitz matrix, that is, \n  \n    \n      \n        \n          B\n          \n            i\n            ,\n            j\n          \n        \n        =\n        \n          B\n          \n            \n              i\n              ′\n            \n            ,\n            \n              j",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ",\n            \n              j\n              ′\n            \n          \n        \n      \n    \n    {\\displaystyle B_{i,j}=B_{i',j'}}\n  \n whenever \n  \n    \n      \n        i\n        −\n        j\n        =\n        \n          i\n          ′\n        \n        −\n        \n          j\n          ′\n        \n      \n    \n    {\\displaystyle i-j=i'-j'}\n  \n. This is contrasted with the original sinusoidal positional encoding, which is an \"absolute positional encoding\".\n\n\n=== Efficient implementation",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "itional encoding\".\n\n\n=== Efficient implementation ===\nThe transformer model has been implemented in standard deep learning frameworks such as TensorFlow and PyTorch. Transformers is a library produced by Hugging Face that supplies transformer-based architectures and pretrained models.\n\n\n==== KV caching ====\nWhen an autoregressive transformer is used for inference, such as generating text, the query vector is different at each step, but the already-computed key and value vectors are always the sa",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "y-computed key and value vectors are always the same. The KV caching method saves the computed key and value vectors at each attention block, so that they are not recomputed at each new token. PagedAttention applies memory paging to KV caching.\nIf a transformer is used with a baked-in prompt, such as [\"You are a customer support agent...\"], then the key and value vectors can be computed for the prompt, and saved on disk. The saving in compute is significant when the model is used for many short",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "significant when the model is used for many short interactions, such as in online chatbots.\n\n\n==== FlashAttention ====\nFlashAttention is an algorithm that implements the transformer attention mechanism efficiently on a GPU. It is a communication-avoiding algorithm that performs matrix multiplications in blocks, such that each block fits within the cache of a GPU, and by careful management of the blocks it minimizes data copying between GPU caches (as data movement is slow). See the page on softm",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "(as data movement is slow). See the page on softmax for details.\nAn improved version, FlashAttention-2, was developed to cater to the rising demand for language models capable of handling longer context lengths. It offers enhancements in work partitioning and parallelism, enabling it to achieve up to 230 TFLOPs/s on A100 GPUs (FP16/BF16), a 2x speed increase over the original FlashAttention.\nKey advancements in FlashAttention-2 include the reduction of non-matmul FLOPs, improved parallelism ove",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "tion of non-matmul FLOPs, improved parallelism over the sequence length dimension, better work partitioning between GPU warps, and added support for head dimensions up to 256 and multi-query attention (MQA) and grouped-query attention (GQA).\nBenchmarks revealed FlashAttention-2 to be up to 2x faster than FlashAttention and up to 9x faster than a standard attention implementation in PyTorch. Future developments include optimization for new hardware like H100 GPUs and new data types like FP8.\n\n\n==",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "e like H100 GPUs and new data types like FP8.\n\n\n==== Multi-Query Attention ====\n\nMulti-Query Attention changes the multiheaded attention mechanism. Whereas normally,\n\n  \n    \n      \n        \n          MultiheadedAttention\n        \n        (\n        Q\n        ,\n        K\n        ,\n        V\n        )\n        =\n        \n          \n            Concat\n          \n          \n            i\n            ∈\n            [\n            \n              n\n              \n                heads",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "heads\n              \n            \n            ]\n          \n        \n        \n          (\n          \n            \n              Attention\n            \n            (\n            X\n            \n              W\n              \n                i\n              \n              \n                Q\n              \n            \n            ,\n            X\n            \n              W\n              \n                i\n              \n              \n                K",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "K\n              \n            \n            ,\n            X\n            \n              W\n              \n                i\n              \n              \n                V\n              \n            \n            )\n          \n          )\n        \n        \n          W\n          \n            O\n          \n        \n      \n    \n    {\\displaystyle {\\text{MultiheadedAttention}}(Q,K,V)={\\text{Concat}}_{i\\in [n_{\\text{heads}}]}\\left({\\text{Attention}}(XW_{i}^{Q},XW_{i}^{K},XW_{i}^{V}",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "\\text{Attention}}(XW_{i}^{Q},XW_{i}^{K},XW_{i}^{V})\\right)W^{O}}\n  \nwith Multi-Query Attention, there is just one \n  \n    \n      \n        \n          W\n          \n            K\n          \n        \n        ,\n        \n          W\n          \n            V\n          \n        \n      \n    \n    {\\displaystyle W^{K},W^{V}}\n  \n, thus:\n\n  \n    \n      \n        \n          MultiQueryAttention\n        \n        (\n        Q\n        ,\n        K\n        ,\n        V\n        )\n        =",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ")\n        =\n        \n          \n            Concat\n          \n          \n            i\n            ∈\n            [\n            \n              n\n              \n                heads\n              \n            \n            ]\n          \n        \n        \n          (\n          \n            \n              Attention\n            \n            (\n            X\n            \n              W\n              \n                i\n              \n              \n                Q",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "Q\n              \n            \n            ,\n            X\n            \n              W\n              \n                K\n              \n            \n            ,\n            X\n            \n              W\n              \n                V\n              \n            \n            )\n          \n          )\n        \n        \n          W\n          \n            O\n          \n        \n      \n    \n    {\\displaystyle {\\text{MultiQueryAttention}}(Q,K,V)={\\text{Concat}}_{i\\in [n_{\\text{hea",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "ntion}}(Q,K,V)={\\text{Concat}}_{i\\in [n_{\\text{heads}}]}\\left({\\text{Attention}}(XW_{i}^{Q},XW^{K},XW^{V})\\right)W^{O}}\n  \n\nThis has a neutral effect on model quality and training speed, but increases inference speed.\nMore generally, grouped-query attention (GQA) partitions attention heads into groups, each of which shares the key-value pair. MQA is GQA with one group, while standard multiheaded attention is GQA with the maximal number of groups.\n\nMultihead Latent Attention (MLA) is a low-rank a",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "Multihead Latent Attention (MLA) is a low-rank approximation to standard MHA. Specifically, each hidden vector, before entering the attention mechanism, is first projected to two low-dimensional spaces (\"latent space\"), one for query and one for key-value (KV vector). This design minimizes the KV cache, as only the low-dimensional KV vector needs to be cached.\n\n\n==== Speculative decoding ====\nSpeculative decoding is a method to accelerate token decoding. Similarly to speculative execution in C",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "decoding. Similarly to speculative execution in CPUs, future tokens are computed quickly, then verified. If the quickly computed tokens are incorrect, they are discarded and computed slowly.\nThe key factor in speculative decoding is that a Transformer decoder can verify faster than it can decode, in the following sense.\nSuppose we have two transformer models like GPT-3 and GPT-3-small, both with a context window size of 512. To generate an entire context window autoregressively with greedy deco",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "e context window autoregressively with greedy decoding with GPT-3, it must be run for 512 times, each time generating a token \n  \n    \n      \n        \n          x\n          \n            1\n          \n        \n        ,\n        \n          x\n          \n            2\n          \n        \n        ,\n        .\n        .\n        .\n        ,\n        \n          x\n          \n            512\n          \n        \n      \n    \n    {\\displaystyle x_{1},x_{2},...,x_{512}}\n  \n, taking time \n  \n    \n      \n        5",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "_{512}}\n  \n, taking time \n  \n    \n      \n        512\n        \n          T\n          \n            GPT-3\n          \n        \n      \n    \n    {\\displaystyle 512T_{\\text{GPT-3}}}\n  \n. However, if we had some educated guess for the values of these tokens, we could verify all of them in parallel, in one run of the model, by checking that each \n  \n    \n      \n        \n          x\n          \n            t\n          \n        \n      \n    \n    {\\displaystyle x_{t}}\n  \n is indeed the token with the largest",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "e x_{t}}\n  \n is indeed the token with the largest log-likelihood in the \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n-th output.\nIn speculative decoding, a smaller model or some other simple heuristic is used to generate a few speculative tokens that are subsequently verified by the larger model. For example, suppose we use GPT-3-small to generate four speculative tokens: \n  \n    \n      \n        \n          \n            \n              \n                x\n                ~",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "x\n                ~\n              \n            \n          \n          \n            1\n          \n        \n        ,\n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            2\n          \n        \n        ,\n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            3\n          \n        \n        ,",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "3\n          \n        \n        ,\n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            4\n          \n        \n      \n    \n    {\\displaystyle {\\tilde {x}}_{1},{\\tilde {x}}_{2},{\\tilde {x}}_{3},{\\tilde {x}}_{4}}\n  \n. This only takes \n  \n    \n      \n        4\n        \n          T\n          \n            GPT-3-small\n          \n        \n      \n    \n    {\\displaystyle 4T_{\\text{GPT-3-small}}}\n  \n. These",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "{\\displaystyle 4T_{\\text{GPT-3-small}}}\n  \n. These tokens are then run through the larger GPT-3 in one go. Suppose that \n  \n    \n      \n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            1\n          \n        \n      \n    \n    {\\displaystyle {\\tilde {x}}_{1}}\n  \n and \n  \n    \n      \n        \n          \n            \n              \n                x\n                ~",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "~\n              \n            \n          \n          \n            2\n          \n        \n      \n    \n    {\\displaystyle {\\tilde {x}}_{2}}\n  \n are verified by GPT-3 as what it would have picked, then those are kept, but \n  \n    \n      \n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            3\n          \n        \n      \n    \n    {\\displaystyle {\\tilde {x}}_{3}}\n  \n is not, so",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "}}_{3}}\n  \n is not, so \n  \n    \n      \n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            3\n          \n        \n        ,\n        \n          \n            \n              \n                x\n                ~\n              \n            \n          \n          \n            4\n          \n        \n      \n    \n    {\\displaystyle {\\tilde {x}}_{3},{\\tilde {x}}_{4}}\n  \n are discarded, and GPT-3 is run on those. Thi",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "are discarded, and GPT-3 is run on those. This would take \n  \n    \n      \n        4\n        \n          T\n          \n            GPT-3-small\n          \n        \n        +\n        3\n        \n          T\n          \n            GPT-3\n          \n        \n      \n    \n    {\\displaystyle 4T_{\\text{GPT-3-small}}+3T_{\\text{GPT-3}}}\n  \n, which might be shorter than \n  \n    \n      \n        4\n        \n          T\n          \n            GPT-3\n          \n        \n      \n    \n    {\\displaystyle 4T_{\\text{G",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "{\\displaystyle 4T_{\\text{GPT-3}}}\n  \n.\nFor non-greedy decoding, similar ideas apply, except the speculative tokens are accepted or rejected stochastically, in a way that guarantees the final output distribution is the same as if speculative decoding was not used.\n\nIn Multi-Token Prediction, a single forward pass creates a final embedding vector, which then is un-embedded into a token probability. However, that vector can then be further processed by another Transformer bl",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "hen be further processed by another Transformer block to predict the next token, and so on for arbitrarily many steps into the future. This trades off accuracy for speed, since each new token costs just one more Transformer block, rather than the entire stack.\n\n\n=== Sub-quadratic transformers ===\nTraining transformer-based architectures can be expensive, especially for long inputs. Many methods have been developed to attempt to address the issue. In the image domain, Swin Transformer is an effic",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "In the image domain, Swin Transformer is an efficient architecture that performs attention inside shifting windows. In the audio domain, SepTr decouples the attention in time and frequency domains. Long Range Arena (2020) is a standard benchmark for comparing the behavior of transformer architectures over long inputs.\n\n\n==== Alternative attention graphs ====\nThe standard attention graph is either all-to-all or causal, both of which scales as \n  \n    \n      \n        O\n        (",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "O\n        (\n        \n          N\n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle O(N^{2})}\n  \n where \n  \n    \n      \n        N\n      \n    \n    {\\displaystyle N}\n  \n is the number of tokens in a sequence.\nReformer (2020) reduces the computational load from \n  \n    \n      \n        O\n        (\n        \n          N\n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle O(N^{2})}\n  \n to \n  \n    \n      \n        O",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "aystyle O(N^{2})}\n  \n to \n  \n    \n      \n        O\n        (\n        N\n        ln\n        ⁡\n        N\n        )\n      \n    \n    {\\displaystyle O(N\\ln N)}\n  \n by using locality-sensitive hashing and reversible layers.\nSparse attention uses attention graphs that grows slower than \n  \n    \n      \n        O\n        (\n        \n          N\n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle O(N^{2})}\n  \n. For example, BigBird (2020) uses random small-world networks wh",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "BigBird (2020) uses random small-world networks which grows as \n  \n    \n      \n        O\n        (\n        N\n        )\n      \n    \n    {\\displaystyle O(N)}\n  \n.\nOrdinary transformers require a memory size that is quadratic in the size of the context window. Attention-free transformers reduce this to a linear dependence while still retaining the advantages of a transformer by linking the key to the value.\n\n\n==== Random Feature Attention ====\nRandom Feature Attention (2021) uses Fourier random fea",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "m Feature Attention (2021) uses Fourier random features:\n  \n    \n      \n        φ\n        (\n        x\n        )\n        =\n        \n          \n            1\n            \n              D\n            \n          \n        \n        [\n        cos\n        ⁡\n        ⟨\n        \n          w\n          \n            1\n          \n        \n        ,\n        x\n        ⟩\n        ,\n        sin\n        ⁡\n        ⟨\n        \n          w\n          \n            1\n          \n        \n        ,\n        x\n        ⟩",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ",\n        x\n        ⟩\n        ,\n        ⋯\n        cos\n        ⁡\n        ⟨\n        \n          w\n          \n            D\n          \n        \n        ,\n        x\n        ⟩\n        ,\n        sin\n        ⁡\n        ⟨\n        \n          w\n          \n            D\n          \n        \n        ,\n        x\n        ⟩\n        \n          ]\n          \n            T\n          \n        \n      \n    \n    {\\displaystyle \\varphi (x)={\\frac {1}{\\sqrt {D}}}[\\cos \\langle w_{1},x\\rangle ,\\sin \\lan",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "\\sqrt {D}}}[\\cos \\langle w_{1},x\\rangle ,\\sin \\langle w_{1},x\\rangle ,\\cdots \\cos \\langle w_{D},x\\rangle ,\\sin \\langle w_{D},x\\rangle ]^{T}}\n  \nwhere \n  \n    \n      \n        \n          w\n          \n            1\n          \n        \n        ,\n        .\n        .\n        .\n        ,\n        \n          w\n          \n            D\n          \n        \n      \n    \n    {\\displaystyle w_{1},...,w_{D}}\n  \n are independent samples from the normal distribution \n  \n    \n      \n        N\n        (\n        0",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "on \n  \n    \n      \n        N\n        (\n        0\n        ,\n        \n          σ\n          \n            2\n          \n        \n        I\n        )\n      \n    \n    {\\displaystyle N(0,\\sigma ^{2}I)}\n  \n. This choice of parameters satisfy \n  \n    \n      \n        \n          E\n        \n        [\n        ⟨\n        φ\n        (\n        x\n        )\n        ,\n        φ\n        (\n        y\n        )\n        ⟩\n        ]\n        =\n        \n          e\n          \n            −",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "−\n            \n              \n                \n                  ‖\n                  x\n                  −\n                  y\n                  \n                    ‖\n                    \n                      2\n                    \n                  \n                \n                \n                  2\n                  \n                    σ\n                    \n                      2",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "{\\displaystyle \\mathbb {E} [\\langle \\varphi (x),\\varphi (y)\\rangle ]=e^{-{\\frac {\\|x-y\\|^{2}}{2\\sigma ^{2}}}}}\n  \n, or \n  \n    \n      \n        \n          e\n          \n            ⟨\n            x\n            ,\n            y\n            ⟩\n            \n              /\n            \n            \n              σ\n              \n                2\n              \n            \n          \n        \n        =\n        \n          E",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "=\n        \n          E\n        \n        [\n        ⟨\n        \n          e\n          \n            ‖\n            x\n            \n              ‖\n              \n                2\n              \n            \n            \n              /\n            \n            2\n            \n              σ\n              \n                2\n              \n            \n          \n        \n        φ\n        (\n        x\n        )\n        ,\n        \n          e\n          \n            ‖",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "e\n          \n            ‖\n            y\n            \n              ‖\n              \n                2\n              \n            \n            \n              /\n            \n            2\n            \n              σ\n              \n                2\n              \n            \n          \n        \n        φ\n        (\n        y\n        )\n        ⟩\n        ]\n        ≈\n        ⟨\n        \n          e\n          \n            ‖\n            x\n            \n              ‖",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "‖\n              \n                2\n              \n            \n            \n              /\n            \n            2\n            \n              σ\n              \n                2\n              \n            \n          \n        \n        φ\n        (\n        x\n        )\n        ,\n        \n          e\n          \n            ‖\n            y\n            \n              ‖\n              \n                2\n              \n            \n            \n              /",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "/\n            \n            2\n            \n              σ\n              \n                2\n              \n            \n          \n        \n        φ\n        (\n        y\n        )\n        ⟩\n      \n    \n    {\\displaystyle e^{\\langle x,y\\rangle /\\sigma ^{2}}=\\mathbb {E} [\\langle e^{\\|x\\|^{2}/2\\sigma ^{2}}\\varphi (x),e^{\\|y\\|^{2}/2\\sigma ^{2}}\\varphi (y)\\rangle ]\\approx \\langle e^{\\|x\\|^{2}/2\\sigma ^{2}}\\varphi (x),e^{\\|y\\|^{2}/2\\sigma ^{2}}\\varphi (y)\\rangle }\n  \nCon",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "\\|y\\|^{2}/2\\sigma ^{2}}\\varphi (y)\\rangle }\n  \nConsequently, the one-headed attention, with one query, can be written as \n  \n    \n      \n        \n          Attention\n        \n        (\n        q\n        ,\n        K\n        ,\n        V\n        )\n        =\n        \n          softmax\n        \n        \n          (\n          \n            \n              \n                q\n                \n                  K\n                  \n                    \n                      T",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "T\n                    \n                  \n                \n              \n              \n                \n                  d\n                  \n                    k\n                  \n                \n              \n            \n          \n          )\n        \n        V\n        ≈\n        \n          \n            \n              φ\n              (\n              q\n              \n                )\n                \n                  T",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "T\n                \n              \n              \n                ∑\n                \n                  i\n                \n              \n              \n                e\n                \n                  ‖\n                  \n                    k\n                    \n                      i\n                    \n                  \n                  \n                    ‖\n                    \n                      2\n                    \n                  \n                  \n                    /",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "/\n                  \n                  2\n                  \n                    σ\n                    \n                      2\n                    \n                  \n                \n              \n              φ\n              (\n              \n                k\n                \n                  i\n                \n              \n              )\n              \n                v\n                \n                  i",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "i\n                \n                \n                  T\n                \n              \n            \n            \n              φ\n              (\n              q\n              \n                )\n                \n                  T\n                \n              \n              \n                ∑\n                \n                  i\n                \n              \n              \n                e\n                \n                  ‖\n                  \n                    k",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "k\n                    \n                      i\n                    \n                  \n                  \n                    ‖\n                    \n                      2\n                    \n                  \n                  \n                    /\n                  \n                  2\n                  \n                    σ\n                    \n                      2",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "φ\n              (\n              \n                k\n                \n                  i\n                \n              \n              )\n            \n          \n        \n      \n    \n    {\\displaystyle {\\text{Attention}}(q,K,V)={\\text{softmax}}\\left({\\frac {qK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\approx {\\frac {\\varphi (q)^{T}\\sum _{i}e^{\\|k_{i}\\|^{2}/2\\sigma ^{2}}\\varphi (k_{i})v_{i}^{T}}{\\varphi (q)^{T}\\sum _{i}e^{\\|k_{i}\\|^{2}/2\\sigma ^{2",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "arphi (q)^{T}\\sum _{i}e^{\\|k_{i}\\|^{2}/2\\sigma ^{2}}\\varphi (k_{i})}}}\n  \nwhere \n  \n    \n      \n        σ\n        =\n        \n          d\n          \n            K\n          \n          \n            1\n            \n              /\n            \n            4\n          \n        \n      \n    \n    {\\displaystyle \\sigma =d_{K}^{1/4}}\n  \n. Similarly for multiple queries, and for multiheaded attention.\nThis approximation can be computed in linear time, as we can compute the matrix \n  \n    \n      \n        φ",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "can compute the matrix \n  \n    \n      \n        φ\n        (\n        \n          k\n          \n            i\n          \n        \n        )\n        \n          v\n          \n            i\n          \n          \n            T\n          \n        \n      \n    \n    {\\displaystyle \\varphi (k_{i})v_{i}^{T}}\n  \n first, then multiply it with the query. In essence, we have managed to obtain a more precise version of \n  \n    \n      \n        \n          Attention\n        \n        (\n        Q\n        ,\n        K",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "(\n        Q\n        ,\n        K\n        ,\n        V\n        )\n        =\n        \n          softmax\n        \n        \n          (\n          \n            \n              \n                Q\n                \n                  K\n                  \n                    \n                      T\n                    \n                  \n                \n              \n              \n                \n                  d\n                  \n                    k",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "k\n                  \n                \n              \n            \n          \n          )\n        \n        V\n        ≈\n        Q\n        (\n        \n          K\n          \n            T\n          \n        \n        V\n        \n          /\n        \n        \n          \n            \n              d\n              \n                k\n              \n            \n          \n        \n        )\n      \n    \n    {\\displaystyle {\\text{Attention}}(Q,K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": ",K,V)={\\text{softmax}}\\left({\\frac {QK^{\\mathrm {T} }}{\\sqrt {d_{k}}}}\\right)V\\approx Q(K^{T}V/{\\sqrt {d_{k}}})}\n  \nPerformer (2022) uses the same Random Feature Attention, but \n  \n    \n      \n        \n          w\n          \n            1\n          \n        \n        ,\n        .\n        .\n        .\n        ,\n        \n          w\n          \n            D\n          \n        \n      \n    \n    {\\displaystyle w_{1},...,w_{D}}\n  \n are first independently sampled from the normal distribution",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "sampled from the normal distribution \n  \n    \n      \n        N\n        (\n        0\n        ,\n        \n          σ\n          \n            2\n          \n        \n        I\n        )\n      \n    \n    {\\displaystyle N(0,\\sigma ^{2}I)}\n  \n, then they are Gram-Schmidt processed.\n\n\n=== Multimodality ===\nTransformers can also be used/adapted for modalities (input or output) beyond just text, usually by finding a way to \"tokenize\" the modality.\nMultimodal models can either be trained from scratch, or by f",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "models can either be trained from scratch, or by finetuning. A 2022 study found that Transformers pretrained only on natural language can be finetuned on only 0.03% of parameters and become competitive with LSTMs on a variety of logical and visual tasks, demonstrating transfer learning. The LLaVA was a vision-language model composed of a language model (Vicuna-13B) and a vision model (ViT-L/14), connected by a linear layer. Only the linear layer is finetuned.\nVision transformers adapt the transf",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "is finetuned.\nVision transformers adapt the transformer to computer vision by breaking down input images as a series of patches, turning them into vectors, and treating them like tokens in a standard transformer.\nConformer and later Whisper follow the same pattern for speech recognition, first turning the speech signal into a spectrogram, which is then treated like an image, i.e. broken down into a series of patches, turned into vectors and treated like tokens in a standard transformer.\nPerceive",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "ed like tokens in a standard transformer.\nPerceivers are a variant of Transformers designed for multimodality.\nFor image generation, notable architectures are DALL-E 1 (2021), Parti (2022), Phenaki (2023), and Muse (2023). Unlike later models, DALL-E is not a diffusion model. Instead, it uses a decoder-only Transformer that autoregressively generates a text, followed by the token representation of an image, which is then converted by a variational autoencoder to an image. Parti is an encoder-dec",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "l autoencoder to an image. Parti is an encoder-decoder Transformer, where the encoder processes a text prompt, and the decoder generates a token representation of an image. Muse is an encoder-only Transformer that is trained to predict masked image tokens from unmasked image tokens. During generation, all input tokens are masked, and the highest-confidence predictions are included for the next iteration, until all tokens are predicted. Phenaki is a text-to-video model. It is a bidirectional mask",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "a text-to-video model. It is a bidirectional masked transformer conditioned on pre-computed text tokens. The generated tokens are then decoded to a video.\n\n\n== Applications ==\nThe transformer has had great success in natural language processing (NLP). Many large language models such as GPT-2, GPT-3, GPT-4, Gemini, AlbertAGPT, Claude, BERT, Grok, XLNet, RoBERTa and ChatGPT demonstrate the ability of transformers to perform a wide variety of NLP-related subtasks and their related real-world appli",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "elated subtasks and their related real-world applications, including:\n\nmachine translation\ntime series prediction\ndocument summarization\ndocument generation\nnamed entity recognition (NER)\nwriting computer code based on requirements expressed in natural language.\nspeech-to-text\nBeyond traditional NLP, the transformer architecture has had success in other applications, such as:\n\nbiological sequence analysis\nvideo understanding\nprotein folding (such as AlphaFold)\nevaluating chess board positions. U",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "as AlphaFold)\nevaluating chess board positions. Using static evaluation alone (that is, with no Minimax search) transformer achieved an Elo of 2895, putting it at grandmaster level.\n\n\n== See also ==\nseq2seq – Family of machine learning approaches\nPerceiver – Variant of Transformer designed for multimodal data\nVision transformer – Machine learning model for vision processing\nLarge language model – Type of machine learning model\nBERT (language model) – Series of language models developed by Googl",
        "source": "transformer_deep_learning_architecture.txt"
    },
    {
        "text": "el) – Series of language models developed by Google AI\nGenerative pre-trained transformer – Type of large language model\nT5 (language model) – Series of large language models developed by Google AI\n\n\n== Notes ==\n\n\n== References ==\n\n\n== Further reading ==",
        "source": "transformer_deep_learning_architecture.txt"
    }
]